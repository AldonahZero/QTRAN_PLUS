"""
Mem0 è®°å¿†ç®¡ç†é€‚é…å™¨ï¼šç”¨äºç¿»è¯‘é˜¶æ®µçš„è·¨ä¼šè¯çŸ¥è¯†ç´¯ç§¯

åŠŸèƒ½æ¦‚è¿°ï¼š
- è®°å½•æˆåŠŸçš„ç¿»è¯‘æ¡ˆä¾‹å’Œé”™è¯¯ä¿®æ­£æ¨¡å¼
- æ£€ç´¢ç›¸å…³å†å²çŸ¥è¯†å¢å¼º prompt
- æ”¯æŒè®°å¿†è¡°å‡å’Œè·¨æ•°æ®åº“å…±äº«

ä½¿ç”¨ç¤ºä¾‹ï¼š
    manager = TransferMemoryManager(user_id="qtran_redis_to_mongodb")
    manager.start_session(origin_db="redis", target_db="mongodb", molt="semantic")
    
    # å¢å¼º prompt
    enhanced_prompt = manager.build_enhanced_prompt(base_prompt, sql, "redis", "mongodb")
    
    # è®°å½•æˆåŠŸæ¡ˆä¾‹
    manager.record_successful_translation(origin_sql, target_sql, "redis", "mongodb", iterations=2)
"""

import os
import json
from typing import Dict, List, Optional, Any
import time
from datetime import datetime

# å¯é€‰å¼•å…¥ Mem0ï¼ˆä»…å½“å¯ç”¨æ—¶æ‰éœ€è¦ï¼‰
try:
    from mem0 import Memory
    MEM0_AVAILABLE = True
except ImportError:
    MEM0_AVAILABLE = False
    Memory = None


class TransferMemoryManager:
    """ç¿»è¯‘é˜¶æ®µçš„ Mem0 è®°å¿†ç®¡ç†å™¨"""
    
    def __init__(self, user_id: str = "qtran_transfer", enable_metrics: bool = True):
        """
        åˆå§‹åŒ–è®°å¿†ç®¡ç†å™¨
        
        Args:
            user_id: ç”¨æˆ·æ ‡è¯†ï¼Œç”¨äºéš”ç¦»ä¸åŒå®éªŒçš„è®°å¿†
            enable_metrics: æ˜¯å¦å¯ç”¨æ€§èƒ½æŒ‡æ ‡æ”¶é›†
        """
        if not MEM0_AVAILABLE:
            raise ImportError(
                "Mem0 is not installed. Please install it with: pip install mem0ai"
            )
        
        # é…ç½® Mem0
        config = {
            "vector_store": {
                "provider": "qdrant",
                "config": {
                    "host": os.environ.get("QDRANT_HOST", "localhost"),
                    "port": int(os.environ.get("QDRANT_PORT", 6333)),
                    "collection_name": "qtran_transfer_memory"
                }
            },
            "llm": {
                "provider": "openai",
                "config": {
                    "model": os.environ.get("OPENAI_MEMORY_MODEL", "gpt-4o-mini"),
                    "temperature": 0.2,
                }
            },
            "embedder": {
                "provider": "openai",
                "config": {
                    "model": "text-embedding-3-small"
                }
            }
        }
        
        try:
            self.memory = Memory.from_config(config)
        except Exception as e:
            print(f"âš ï¸ Failed to initialize Mem0 with Qdrant, falling back to in-memory mode: {e}")
            # å›é€€åˆ°å†…å­˜æ¨¡å¼ï¼ˆå¼€å‘/æµ‹è¯•ç”¨ï¼‰
            config["vector_store"] = {
                "provider": "chroma",
                "config": {
                    "collection_name": "qtran_transfer_memory",
                    "path": ".mem0_db"
                }
            }
            self.memory = Memory.from_config(config)
        
        self.user_id = user_id
        self.session_id = None
        self.enable_metrics = enable_metrics
        
        if enable_metrics:
            self.metrics = {
                "search_times": [],
                "add_times": [],
                "hits": []
            }
    
    def start_session(self, origin_db: str, target_db: str, molt: str) -> str:
        """
        å¼€å¯æ–°çš„ç¿»è¯‘ä¼šè¯
        
        Args:
            origin_db: æºæ•°æ®åº“
            target_db: ç›®æ ‡æ•°æ®åº“
            molt: æµ‹è¯•ç­–ç•¥(norec/tlp/semanticç­‰)
        
        Returns:
            session_id: ä¼šè¯æ ‡è¯†
        """
        import uuid
        self.session_id = f"{origin_db}_to_{target_db}_{molt}_{uuid.uuid4().hex[:8]}"
        
        # è®°å½•ä¼šè¯å¼€å§‹
        message = (
            f"Started translation session from {origin_db} to {target_db} "
            f"using {molt} strategy"
        )
        
        try:
            self.memory.add(
                message,
                user_id=self.user_id,
                metadata={
                    "type": "session_start",
                    "origin_db": origin_db,
                    "target_db": target_db,
                    "molt": molt,
                    "session_id": self.session_id,
                    "timestamp": datetime.now().isoformat()
                }
            )
        except Exception as e:
            print(f"âš ï¸ Failed to add session start memory: {e}")
        
        return self.session_id
    
    def record_successful_translation(
        self,
        origin_sql: str,
        target_sql: str,
        origin_db: str,
        target_db: str,
        iterations: int,
        features: List[str] = None
    ):
        """
        è®°å½•æˆåŠŸçš„ç¿»è¯‘æ¡ˆä¾‹
        
        Args:
            origin_sql: æº SQL
            target_sql: ç›®æ ‡ SQL
            origin_db: æºæ•°æ®åº“
            target_db: ç›®æ ‡æ•°æ®åº“
            iterations: è¿­ä»£æ¬¡æ•°
            features: æ¶‰åŠçš„ç‰¹å¾åˆ—è¡¨
        """
        start_time = time.time()
        
        # æˆªæ–­è¿‡é•¿çš„ SQL ä»¥é¿å…å­˜å‚¨è¿‡å¤§
        origin_snippet = origin_sql[:200] if len(origin_sql) > 200 else origin_sql
        target_snippet = target_sql[:200] if len(target_sql) > 200 else target_sql
        
        message = (
            f"Successfully translated SQL from {origin_db} to {target_db} "
            f"in {iterations} iterations. "
            f"Original: {origin_snippet}{'...' if len(origin_sql) > 200 else ''} "
            f"Translated: {target_snippet}{'...' if len(target_sql) > 200 else ''}"
        )
        
        if features:
            message += f" Features: {', '.join(features[:5])}"  # æœ€å¤šè®°å½•5ä¸ªç‰¹å¾
        
        try:
            self.memory.add(
                message,
                user_id=self.user_id,
                metadata={
                    "type": "successful_translation",
                    "origin_db": origin_db,
                    "target_db": target_db,
                    "iterations": iterations,
                    "features": features or [],
                    "session_id": self.session_id,
                    "timestamp": datetime.now().isoformat()
                }
            )
        except Exception as e:
            print(f"âš ï¸ Failed to record successful translation: {e}")
        
        if self.enable_metrics:
            self.metrics["add_times"].append(time.time() - start_time)
    
    def record_error_fix(
        self,
        error_message: str,
        fix_sql: str,
        origin_db: str,
        target_db: str,
        failed_sql: str = None
    ):
        """
        è®°å½•é”™è¯¯åŠå…¶ä¿®æ­£æ–¹æ¡ˆ
        
        Args:
            error_message: é”™è¯¯ä¿¡æ¯
            fix_sql: ä¿®æ­£åçš„ SQL
            origin_db: æºæ•°æ®åº“
            target_db: ç›®æ ‡æ•°æ®åº“
            failed_sql: å¤±è´¥çš„ SQL
        """
        start_time = time.time()
        
        # æˆªæ–­é”™è¯¯ä¿¡æ¯å’Œ SQL
        error_snippet = error_message[:300] if len(error_message) > 300 else error_message
        fix_snippet = fix_sql[:200] if len(fix_sql) > 200 else fix_sql
        
        message = (
            f"Fixed error in {target_db}: {error_snippet}{'...' if len(error_message) > 300 else ''}. "
            f"Solution: {fix_snippet}{'...' if len(fix_sql) > 200 else ''}"
        )
        
        try:
            self.memory.add(
                message,
                user_id=self.user_id,
                metadata={
                    "type": "error_fix",
                    "origin_db": origin_db,
                    "target_db": target_db,
                    "error_message": error_message[:500],  # é™åˆ¶é•¿åº¦
                    "fix_sql": fix_sql[:500],
                    "session_id": self.session_id,
                    "timestamp": datetime.now().isoformat()
                }
            )
        except Exception as e:
            print(f"âš ï¸ Failed to record error fix: {e}")
        
        if self.enable_metrics:
            self.metrics["add_times"].append(time.time() - start_time)
    
    def get_relevant_memories(
        self,
        query_sql: str,
        origin_db: str,
        target_db: str,
        limit: int = 5
    ) -> List[Dict[str, Any]]:
        """
        æ£€ç´¢ç›¸å…³çš„å†å²è®°å¿†
        
        Args:
            query_sql: æŸ¥è¯¢ SQL
            origin_db: æºæ•°æ®åº“
            target_db: ç›®æ ‡æ•°æ®åº“
            limit: è¿”å›è®°å¿†æ•°é‡
        
        Returns:
            ç›¸å…³è®°å¿†åˆ—è¡¨
        """
        start_time = time.time()
        
        # æ„å»ºæŸ¥è¯¢å­—ç¬¦ä¸²
        query_snippet = query_sql[:300] if len(query_sql) > 300 else query_sql
        query = (
            f"Translation from {origin_db} to {target_db}. "
            f"SQL: {query_snippet}"
        )
        
        try:
            memories = self.memory.search(
                query=query,
                user_id=self.user_id,
                limit=limit
            )
            
            if self.enable_metrics:
                self.metrics["search_times"].append(time.time() - start_time)
                self.metrics["hits"].append(1 if memories else 0)
            
            return memories
        except Exception as e:
            print(f"âš ï¸ Failed to search memories: {e}")
            return []
    
    def get_knowledge_base_info(
        self,
        query: str,
        database: str,
        limit: int = 3
    ) -> List[Dict[str, Any]]:
        """
        ä»çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³ä¿¡æ¯
        
        Args:
            query: æŸ¥è¯¢å­—ç¬¦ä¸²ï¼ˆå¦‚æ“ä½œç¬¦ã€å‡½æ•°ã€æ•°æ®ç±»å‹åç§°ï¼‰
            database: æ•°æ®åº“åç§°
            limit: è¿”å›ç»“æœæ•°é‡
        
        Returns:
            ç›¸å…³çŸ¥è¯†åº“æ¡ç›®åˆ—è¡¨
        """
        start_time = time.time()
        
        # ä½¿ç”¨çŸ¥è¯†åº“ä¸“ç”¨çš„ user_id
        kb_user_id = f"qtran_kb_{database}"
        
        try:
            memories = self.memory.search(
                query=query,
                user_id=kb_user_id,
                limit=limit
            )
            
            if self.enable_metrics:
                self.metrics["search_times"].append(time.time() - start_time)
                self.metrics["hits"].append(1 if memories else 0)
            
            return memories
        except Exception as e:
            print(f"âš ï¸ Failed to search knowledge base: {e}")
            return []
    
    def build_enhanced_prompt(
        self,
        base_prompt: str,
        query_sql: str,
        origin_db: str,
        target_db: str,
        include_knowledge_base: bool = None  # None = è‡ªåŠ¨å†³å®š
    ) -> str:
        """
        ä½¿ç”¨å†å²è®°å¿†å’ŒçŸ¥è¯†åº“å¢å¼º prompt
        
        Args:
            base_prompt: åŸºç¡€ prompt
            query_sql: å¾…ç¿»è¯‘çš„ SQL
            origin_db: æºæ•°æ®åº“
            target_db: ç›®æ ‡æ•°æ®åº“
            include_knowledge_base: æ˜¯å¦åŒ…å«çŸ¥è¯†åº“ä¿¡æ¯ï¼ˆNone=è‡ªåŠ¨åˆ¤æ–­ï¼‰
        
        Returns:
            å¢å¼ºåçš„ prompt
        
        æ€§èƒ½æ¨¡å¼ï¼ˆé€šè¿‡ç¯å¢ƒå˜é‡ QTRAN_MEM0_MODE æ§åˆ¶ï¼‰ï¼š
        - fast: åªç”¨å†å²è®°å¿†ï¼Œé€Ÿåº¦æœ€å¿«
        - balanced: æ™ºèƒ½å†³å®šæ˜¯å¦ç”¨çŸ¥è¯†åº“ï¼ˆé»˜è®¤ï¼‰
        - quality: æ€»æ˜¯ä½¿ç”¨çŸ¥è¯†åº“ï¼Œè´¨é‡æœ€é«˜
        """
        # æ£€æŸ¥æ€§èƒ½æ¨¡å¼
        mode = os.environ.get("QTRAN_MEM0_MODE", "balanced")
        
        # 1. è·å–å†å²ç¿»è¯‘è®°å¿†ï¼ˆæ ¹æ®æ¨¡å¼è°ƒæ•´æ•°é‡ï¼‰
        memory_limit = 1 if mode == "fast" else 2
        memories = self.get_relevant_memories(query_sql, origin_db, target_db, limit=memory_limit)
        
        # 2. æ™ºèƒ½å†³å®šæ˜¯å¦ä½¿ç”¨çŸ¥è¯†åº“
        if include_knowledge_base is None:
            if mode == "fast":
                include_knowledge_base = False
            elif mode == "quality":
                include_knowledge_base = True
            else:  # balanced
                # è‡ªåŠ¨åˆ¤æ–­æŸ¥è¯¢å¤æ‚åº¦
                include_knowledge_base = self._is_complex_query(query_sql)
        
        # 3. è·å–çŸ¥è¯†åº“ä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        kb_info_origin = []
        kb_info_target = []
        
        if include_knowledge_base:
            # ä»æŸ¥è¯¢ SQL ä¸­æå–å…³é”®è¯æ¥æŸ¥è¯¢çŸ¥è¯†åº“
            query_keywords = self._extract_keywords_from_sql(query_sql)
            
            if query_keywords:
                # æ ¹æ®æ¨¡å¼è°ƒæ•´çŸ¥è¯†åº“æŸ¥è¯¢æ•°é‡
                kb_limit = 1 if mode == "balanced" else 2
                
                # æŸ¥è¯¢æºæ•°æ®åº“çŸ¥è¯†åº“
                kb_info_origin = self.get_knowledge_base_info(
                    query_keywords,
                    origin_db,
                    limit=kb_limit
                )
                
                # æŸ¥è¯¢ç›®æ ‡æ•°æ®åº“çŸ¥è¯†åº“
                kb_info_target = self.get_knowledge_base_info(
                    query_keywords,
                    target_db,
                    limit=kb_limit
                )
        
        # å¦‚æœæ²¡æœ‰ä»»ä½•å¢å¼ºä¿¡æ¯ï¼Œè¿”å›åŸå§‹ prompt
        if not memories and not kb_info_origin and not kb_info_target:
            return base_prompt
        
        # æ„å»ºå¢å¼ºä¸Šä¸‹æ–‡
        enhanced_context = ""
        
        # 4. æ·»åŠ å†å²ç¿»è¯‘è®°å¿†
        if memories:
            memory_context = "\n\n## ğŸ“š Relevant Historical Knowledge (from Mem0):\n"
            memory_context += "(These are successful patterns from previous translations)\n\n"
            
            for i, mem in enumerate(memories, 1):
                memory_text = mem.get('memory', '')
                metadata = mem.get('metadata', {})
                mem_type = metadata.get('type', 'unknown')
                
                # âš ï¸ å…³é”®ä¿®å¤ï¼šè½¬ä¹‰è®°å¿†æ–‡æœ¬ä¸­çš„å¤§æ‹¬å·ï¼Œé¿å…è¢« Python format() è¯¯è§£æ
                # MongoDB Shell è¯­æ³•å¦‚ { _id: "key" } ä¼šè¢«å½“ä½œå ä½ç¬¦
                memory_text_escaped = memory_text.replace('{', '{{').replace('}', '}}')
                
                memory_context += f"### Memory {i} [{mem_type}]:\n"
                memory_context += f"{memory_text_escaped}\n"
                
                # æ·»åŠ å…ƒæ•°æ®æç¤º
                if mem_type == 'successful_translation':
                    iterations = metadata.get('iterations', 'N/A')
                    memory_context += f"(Completed in {iterations} iterations)\n"
                elif mem_type == 'error_fix':
                    memory_context += f"(Common error fix pattern)\n"
                
                memory_context += "\n"
            
            enhanced_context += memory_context
        
        # 5. æ·»åŠ æºæ•°æ®åº“çŸ¥è¯†åº“ä¿¡æ¯
        if kb_info_origin:
            kb_context = f"\n\n## ğŸ“– {origin_db.upper()} Knowledge Base:\n"
            for i, kb_item in enumerate(kb_info_origin, 1):
                kb_text = kb_item.get('memory', '')
                kb_text_escaped = kb_text.replace('{', '{{').replace('}', '}}')
                kb_context += f"{kb_text_escaped}\n\n"
            enhanced_context += kb_context
        
        # 6. æ·»åŠ ç›®æ ‡æ•°æ®åº“çŸ¥è¯†åº“ä¿¡æ¯
        if kb_info_target:
            kb_context = f"\n\n## ğŸ“– {target_db.upper()} Knowledge Base:\n"
            for i, kb_item in enumerate(kb_info_target, 1):
                kb_text = kb_item.get('memory', '')
                kb_text_escaped = kb_text.replace('{', '{{').replace('}', '}}')
                kb_context += f"{kb_text_escaped}\n\n"
            enhanced_context += kb_context
        
        # åœ¨ç‰¹å¾çŸ¥è¯†éƒ¨åˆ†åæ’å…¥å¢å¼ºä¸Šä¸‹æ–‡
        # æŸ¥æ‰¾æ’å…¥ä½ç½®ï¼ˆåœ¨ feature_knowledge ä¹‹åï¼Œexamples ä¹‹å‰ï¼‰
        if "{feature_knowledge}" in base_prompt:
            enhanced_prompt = base_prompt.replace(
                "{feature_knowledge}",
                "{feature_knowledge}" + enhanced_context
            )
        else:
            # å¦‚æœæ²¡æœ‰ feature_knowledge å ä½ç¬¦ï¼Œåœ¨ examples å‰æ’å…¥
            if "{examples}" in base_prompt:
                enhanced_prompt = base_prompt.replace(
                    "{examples}",
                    enhanced_context + "\n{examples}"
                )
            else:
                # å¦åˆ™ç›´æ¥è¿½åŠ åˆ°æœ«å°¾
                enhanced_prompt = base_prompt + enhanced_context
        
        return enhanced_prompt
    
    def _extract_keywords_from_sql(self, sql: str) -> str:
        """
        ä» SQL ä¸­æå–å…³é”®è¯ç”¨äºçŸ¥è¯†åº“æŸ¥è¯¢
        
        Args:
            sql: SQL è¯­å¥
        
        Returns:
            æå–çš„å…³é”®è¯å­—ç¬¦ä¸²
        """
        import re
        
        # ç§»é™¤æ³¨é‡Š
        sql_clean = re.sub(r'--.*$', '', sql, flags=re.MULTILINE)
        sql_clean = re.sub(r'/\*.*?\*/', '', sql_clean, flags=re.DOTALL)
        
        # æå– SQL å…³é”®è¯å’Œæ ‡è¯†ç¬¦
        # å¸¸è§çš„ SQL å…³é”®è¯
        sql_keywords = set([
            'SELECT', 'INSERT', 'UPDATE', 'DELETE', 'CREATE', 'DROP', 'ALTER',
            'WHERE', 'FROM', 'JOIN', 'GROUP BY', 'ORDER BY', 'HAVING',
            'DISTINCT', 'COUNT', 'SUM', 'AVG', 'MAX', 'MIN',
            'INT', 'VARCHAR', 'CHAR', 'TEXT', 'DATE', 'DATETIME', 'TIMESTAMP',
            'FOREIGN KEY', 'PRIMARY KEY', 'UNIQUE', 'INDEX'
        ])
        
        # æå–æ‰€æœ‰å•è¯
        words = re.findall(r'\b[A-Za-z_][A-Za-z0-9_]*\b', sql_clean.upper())
        
        # è¿‡æ»¤å‡ºå¯èƒ½çš„å‡½æ•°åã€æ•°æ®ç±»å‹ã€æ“ä½œç¬¦
        keywords = []
        for word in words:
            if word in sql_keywords:
                keywords.append(word)
            elif len(word) >= 3:  # è‡³å°‘3ä¸ªå­—ç¬¦
                keywords.append(word)
        
        # è¿”å›å‰5ä¸ªå…³é”®è¯
        unique_keywords = list(dict.fromkeys(keywords))[:5]
        return ' '.join(unique_keywords) if unique_keywords else sql_clean[:100]
    
    def _is_complex_query(self, sql: str) -> bool:
        """
        åˆ¤æ–­SQLæŸ¥è¯¢æ˜¯å¦å¤æ‚ï¼ˆéœ€è¦çŸ¥è¯†åº“æ”¯æŒï¼‰
        
        Args:
            sql: SQL è¯­å¥
        
        Returns:
            True å¦‚æœæ˜¯å¤æ‚æŸ¥è¯¢ï¼ŒFalse å¦‚æœæ˜¯ç®€å•æŸ¥è¯¢
        """
        sql_upper = sql.upper()
        
        # ç®€å•æŸ¥è¯¢æ¨¡å¼ï¼ˆé€šå¸¸ä¸éœ€è¦çŸ¥è¯†åº“ï¼‰
        simple_patterns = [
            'SELECT * FROM',
            'SELECT COUNT(*) FROM',
            'INSERT INTO',
            'UPDATE',
            'DELETE FROM',
        ]
        
        # å¤æ‚æ“ä½œå…³é”®è¯ï¼ˆéœ€è¦çŸ¥è¯†åº“ï¼‰
        complex_keywords = [
            'UNION', 'INTERSECT', 'EXCEPT',  # é›†åˆæ“ä½œ
            'JOIN', 'LEFT JOIN', 'RIGHT JOIN', 'FULL JOIN',  # è¿æ¥
            'GROUP BY', 'HAVING',  # èšåˆ
            'COLLATE', 'CAST', 'CONVERT',  # ç±»å‹è½¬æ¢
            'SUBSTRING', 'CONCAT', 'COALESCE',  # å­—ç¬¦ä¸²å‡½æ•°
            'HEX(', 'MIN(', 'MAX(', 'AVG(', 'SUM(',  # èšåˆå‡½æ•°
            'CASE WHEN', 'NULLIF', 'IFNULL',  # æ¡ä»¶è¡¨è¾¾å¼
            'EXISTS', 'IN (SELECT', 'NOT IN (SELECT',  # å­æŸ¥è¯¢
            'WITH RECURSIVE', 'CTE',  # å…¬ç”¨è¡¨è¡¨è¾¾å¼
        ]
        
        # å¦‚æœåŒ…å«å¤æ‚å…³é”®è¯ï¼Œè¿”å› True
        if any(kw in sql_upper for kw in complex_keywords):
            return True
        
        # å¦‚æœæ˜¯ç®€å•æ¨¡å¼ä¸”ä¸åŒ…å«å¤æ‚æ“ä½œï¼Œè¿”å› False
        for pattern in simple_patterns:
            if pattern in sql_upper:
                return False
        
        # é»˜è®¤è®¤ä¸ºæ˜¯å¤æ‚æŸ¥è¯¢ï¼ˆä¿å®ˆç­–ç•¥ï¼‰
        return True
    
    def end_session(self, success: bool, final_result: str = None):
        """
        ç»“æŸç¿»è¯‘ä¼šè¯
        
        Args:
            success: æ˜¯å¦æˆåŠŸ
            final_result: æœ€ç»ˆç»“æœ
        """
        status = "successfully" if success else "unsuccessfully"
        
        result_snippet = ""
        if final_result:
            result_snippet = final_result[:150] if len(final_result) > 150 else final_result
            result_snippet = f". Final result: {result_snippet}{'...' if len(final_result) > 150 else ''}"
        
        message = f"Ended translation session {self.session_id} {status}{result_snippet}"
        
        try:
            self.memory.add(
                message,
                user_id=self.user_id,
                metadata={
                    "type": "session_end",
                    "session_id": self.session_id,
                    "success": success,
                    "timestamp": datetime.now().isoformat()
                }
            )
        except Exception as e:
            print(f"âš ï¸ Failed to add session end memory: {e}")
        
        self.session_id = None
    
    def get_metrics_report(self) -> str:
        """
        ç”Ÿæˆæ€§èƒ½æŒ‡æ ‡æŠ¥å‘Š
        
        Returns:
            æ ¼å¼åŒ–çš„æŒ‡æ ‡æŠ¥å‘Š
        """
        if not self.enable_metrics:
            return "Metrics collection is disabled"
        
        report = "\n=== Mem0 Performance Metrics ===\n"
        
        if self.metrics["search_times"]:
            avg_search = sum(self.metrics["search_times"]) / len(self.metrics["search_times"])
            report += f"â±ï¸  Average search time: {avg_search:.3f}s\n"
            report += f"ğŸ” Total searches: {len(self.metrics['search_times'])}\n"
        
        if self.metrics["add_times"]:
            avg_add = sum(self.metrics["add_times"]) / len(self.metrics["add_times"])
            report += f"â±ï¸  Average add time: {avg_add:.3f}s\n"
            report += f"ğŸ’¾ Total additions: {len(self.metrics['add_times'])}\n"
        
        if self.metrics["hits"]:
            hit_rate = sum(self.metrics["hits"]) / len(self.metrics["hits"])
            report += f"ğŸ¯ Memory hit rate: {hit_rate:.1%}\n"
        
        report += "================================\n"
        return report


class FallbackMemoryManager:
    """
    å½“ Mem0 ä¸å¯ç”¨æ—¶çš„é™çº§å®ç°ï¼ˆåŸºäºæ–‡ä»¶çš„ç®€å•è®°å¿†ï¼‰
    ä»…ç”¨äºå¼€å‘/æµ‹è¯•ï¼Œä¸æ¨èç”Ÿäº§ä½¿ç”¨
    """
    
    def __init__(self, user_id: str = "qtran_transfer", storage_dir: str = ".mem0_fallback"):
        self.user_id = user_id
        self.storage_dir = storage_dir
        self.session_id = None
        os.makedirs(storage_dir, exist_ok=True)
        print("âš ï¸ Using fallback memory manager (file-based)")
    
    def start_session(self, origin_db: str, target_db: str, molt: str) -> str:
        import uuid
        self.session_id = f"{origin_db}_to_{target_db}_{molt}_{uuid.uuid4().hex[:8]}"
        return self.session_id
    
    def record_successful_translation(self, origin_sql, target_sql, origin_db, target_db, iterations, features=None):
        # ç®€å•çš„æ–‡ä»¶è¿½åŠ 
        filepath = os.path.join(self.storage_dir, f"{self.user_id}_success.jsonl")
        with open(filepath, 'a', encoding='utf-8') as f:
            json.dump({
                "origin_sql": origin_sql[:200],
                "target_sql": target_sql[:200],
                "origin_db": origin_db,
                "target_db": target_db,
                "iterations": iterations,
                "features": features,
                "timestamp": datetime.now().isoformat()
            }, f)
            f.write('\n')
    
    def record_error_fix(self, error_message, fix_sql, origin_db, target_db, failed_sql=None):
        filepath = os.path.join(self.storage_dir, f"{self.user_id}_errors.jsonl")
        with open(filepath, 'a', encoding='utf-8') as f:
            json.dump({
                "error": error_message[:300],
                "fix_sql": fix_sql[:200],
                "origin_db": origin_db,
                "target_db": target_db,
                "timestamp": datetime.now().isoformat()
            }, f)
            f.write('\n')
    
    def get_relevant_memories(self, query_sql, origin_db, target_db, limit=5):
        # è¿”å›ç©ºåˆ—è¡¨ï¼ˆé™çº§æ¨¡å¼ä¸æ”¯æŒè¯­ä¹‰æœç´¢ï¼‰
        return []
    
    def build_enhanced_prompt(self, base_prompt, query_sql, origin_db, target_db):
        # é™çº§æ¨¡å¼ä¸å¢å¼º prompt
        return base_prompt
    
    def end_session(self, success, final_result=None):
        self.session_id = None
    
    def get_metrics_report(self):
        return "Fallback mode: metrics not available"

