"""
SQLancer è·¯å¾„ï¼šBug æŠ¥å‘Šè§£æ -> æ–¹è¨€ç‰¹å¾è¯†åˆ« -> LLM è½¬æ¢ -> å˜å¼‚ä¸æ£€æŸ¥

ä½œç”¨æ¦‚è¿°ï¼š
- è¯»å– SQLancer ç”Ÿæˆçš„ bug æŠ¥å‘Šï¼ŒæŠ½å– SQL å¹¶è¿›è¡Œæ½œåœ¨æ–¹è¨€ç‰¹å¾è¯†åˆ«ä¸æ˜ å°„ã€‚
*- è°ƒç”¨ transfer_llm å°† a_db çš„ SQL è½¬ä¸º b_db æ–¹è¨€ï¼Œå¹¶æ”¯æŒé”™è¯¯è¿­ä»£ä¿®æ­£ã€‚
- å°†æœ€ç»ˆå¯æ‰§è¡Œçš„ SELECT è¯­å¥äº¤ç»™ Mutate LLM ç”Ÿæˆå˜å¼‚å€™é€‰ï¼Œä¾›åç»­é¢„è¨€æœºæ£€æŸ¥ã€‚
- è´Ÿè´£ç»„ç»‡è¾“å…¥/è¾“å‡ºæ–‡ä»¶ä¸è¿‡ç¨‹æŒä¹…åŒ–ï¼ˆInput/Output ç›®å½•ï¼‰ã€‚

å…³è”æµç¨‹å‚è€ƒï¼šè§ abstract.mdã€Šè°ƒç”¨é“¾æ¦‚è§ˆã€‹ã€Šé˜¶æ®µä¸€ï¼šè½¬æ¢ã€‹ã€Šé˜¶æ®µäºŒï¼šå˜å¼‚ä¸æ£€æµ‹ã€‹ã€‚
"""

# !/usr/bin/env python
# -*- coding: utf-8 -*-
# @Time    : 2024/10/20 19:21
# @Author  : huanghe
# @File    : sqlancer_exp.py
# @Intro   :

from src.DialectRecognition.dialect_feature_recognizer import (
    potential_features_refiner_single_sql,
    sqlancer_potential_dialect_features_process_and_map,
)

# from src.TransferLLM.rag_based_feature_mapping import rag_feature_mapping_llm, rag_feature_mapping_count, rag_feature_mapping_process
from src.TransferLLM.TransferLLM import transfer_llm
from src.Tools.DatabaseConnect.database_connector import database_clear
from datetime import datetime
from src.MutationLlmModelValidator.MutateLLM import run_muatate_llm_single_sql
from src.Tools.OracleChecker.oracle_check import execSQL_result_convertor, Result, Check
from src.Tools.OracleChecker.tlp_checker import check_tlp_oracle, is_tlp_mutation
import os
import json
from json_repair import repair_json
from openai import OpenAI
from langchain.chat_models import ChatOpenAI
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory
from src.Tools.DatabaseConnect.database_connector import exec_sql_statement
from src.Tools.json_utils import make_json_safe


current_file_path = os.path.abspath(__file__)
current_dir = os.path.dirname(current_file_path)


def _extract_transferred_stmt(transfer_results):
    """Return the last transferred statement regardless of SQL or NoSQL branch.

    transfer_results: list of dicts produced by transfer_llm.
    Each dict may contain one of:
        - "TransferSQL" (SQL semantic path)
        - "TransferNoSQL" (NoSQL crash path)
    """
    if not transfer_results:
        return None
    last = transfer_results[-1]
    return last.get("TransferSQL") or last.get("TransferNoSQL")


"""
sqlancer_norec_mutate_id = os.environ['SQLANCER_MUTATE_MODEL_NOREC']
sqlancer_dqe_mutate_id = os.environ['SQLANCER_MUTATE_MODEL_DQE']
sqlancer_tlp_mutate_id = os.environ['SQLANCER_MUTATE_MODEL_TLP']
"""

"""
TLP_supported_dbs = ["sqlite", "mysql", "tidb", "duckdb"]
TLP_extended_dbs = ["mariadb", "postgres", "monetdb", "clickhouse"]

NoRec_supported_dbs = ["sqlite", "mariadb", "postgres"]
NoRec_extended_dbs = ["mysql", "tidb", "monetdb", "duckdb", "clickhouse"]
"""


# è·å–sqlancerçš„bug report,å¹¶è¿›è¡Œpotential dialect featureè¯†åˆ«
def load_sqlancer_bug_report(fuzzer, a_db, b_db, bug):
    """æŒ‰è¡Œæ‹†åˆ† SQLancer bug æŠ¥å‘Šä¸­çš„ SQLï¼Œé™„å¸¦å¿…è¦ä¸Šä¸‹æ–‡ï¼Œä½œä¸ºåç»­è½¬æ¢è¾“å…¥å•å…ƒã€‚"""
    # ä»¥åˆ—è¡¨å½¢å¼è¿”å›bugç»è¿‡å¤„ç†å¾—åˆ°çš„inputä¿¡æ¯
    bug_input = []
    # æœ‰å¤šæ¡æ•°æ®ï¼Œå­˜å‚¨åœ¨jsonlæ–‡ä»¶ä¸­ï¼Œæ¯ä¸€å¥sqlå­˜ä¸ºä¸€è¡Œ
    for sql in bug["sqls"]:
        # è¯†åˆ«potential feature,å°†æ‰€æœ‰çš„featureéƒ½ç²—ç•¥çš„è®¤ä¸ºæ˜¯dialect
        (
            SqlPotentialFunctionIndexes,
            SqlPotentialOperatorIndexes,
            SqlPotentialDialectFunction,
            SqlPotentialDialectOperator,
        ) = potential_features_refiner_single_sql(sql)
        # è·å–å¯¹åº”çš„mapping indexes
        SqlPotentialDialectFunctionMapping = (
            sqlancer_potential_dialect_features_process_and_map(
                a_db,
                b_db,
                SqlPotentialDialectFunction,
                "function",
                search_k=0,
                version_id=1,
            )
        )
        # æš‚ä¸è€ƒè™‘operator
        SqlPotentialDialectOperatorMapping = []
        # SqlPotentialDialectOperatorMapping = sqlancer_potential_dialect_features_process_and_map(a_db, b_db, SqlPotentialDialectOperator, "operator",search_k=0, version_id=1)
        new_content = {
            "index": bug["index"],
            "a_db": bug["a_db"],
            "b_db": bug["b_db"],
            "molt": bug["molt"],
            "sql": sql,
        }
        bug_input.append(new_content)
    return bug_input


def sqlancer_translate(
    input_filepath,
    tool="sqlancer",
    temperature=0.3,
    model="gpt-4o-mini",
    error_iteration=True,
    iteration_num=4,
    FewShot=False,
    with_knowledge=True,
):
    """
    SQLancer å…¨æµç¨‹é©±åŠ¨ï¼š
    - æ„å»º Input/Output ç›®å½•ï¼›
    - è§£æ bug æŠ¥å‘Šï¼Œæå–å¾…è½¬æ¢ SQLï¼›
    - è°ƒç”¨ transfer_llm æ‰§è¡Œè·¨æ–¹è¨€è½¬æ¢åŠé”™è¯¯è¿­ä»£ï¼›
    - è°ƒç”¨ Mutate LLM è·å–å˜å¼‚ç»“æœå¹¶æŒä¹…åŒ–ã€‚
    """
    # ========== Mem0 è®°å¿†ç®¡ç†åˆå§‹åŒ– ==========
    use_mem0 = os.environ.get("QTRAN_USE_MEM0", "false").lower() == "true"
    
    # ç¿»è¯‘é˜¶æ®µçš„ Mem0 ç®¡ç†å™¨
    mem0_manager = None
    if use_mem0:
        try:
            from src.TransferLLM.mem0_adapter import (
                TransferMemoryManager, FallbackMemoryManager
            )
            try:
                mem0_manager = TransferMemoryManager(
                    user_id="qtran_transfer_universal"
                )
                print(f"âœ… Translation Mem0 initialized")
            except ImportError:
                print("âš ï¸ Mem0 not available for translation, using fallback")
                mem0_manager = FallbackMemoryManager(
                    user_id="qtran_transfer_fallback"
                )
        except Exception as e:
            print(f"âš ï¸ Failed to initialize Translation Mem0: {e}")
            mem0_manager = None
    
    # å˜å¼‚é˜¶æ®µçš„ Mem0 ç®¡ç†å™¨
    mutation_mem0_manager = None
    if use_mem0:
        try:
            from src.MutationLlmModelValidator.mutation_mem0_adapter import (
                MutationMemoryManager, FallbackMutationMemoryManager
            )
            try:
                mutation_mem0_manager = MutationMemoryManager(
                    user_id="qtran_mutation_universal"
                )
                print(f"âœ… Mutation Mem0 initialized")
            except ImportError:
                print("âš ï¸ Mem0 not available for mutation, using fallback")
                mutation_mem0_manager = FallbackMutationMemoryManager(
                    user_id="qtran_mutation_fallback"
                )
        except Exception as e:
            print(f"âš ï¸ Failed to initialize Mutation Mem0: {e}")
            mutation_mem0_manager = None
    
    input_filename = os.path.basename(input_filepath).replace(".jsonl", "")
    input_dic = os.path.join(current_dir, "..", "..", "Input", input_filename)
    if not os.path.exists(input_dic):
        os.makedirs(input_dic, exist_ok=True)  # å¦‚æœæ–‡ä»¶å¤¹å·²å­˜åœ¨ï¼Œåˆ™ä¸ä¼šæŠ›å‡ºå¼‚å¸¸
    # æ–°å»ºæ‰€éœ€transfer outputæ–‡ä»¶å¤¹
    output_transfer_dic = os.path.join(
        current_dir, "..", "..", "Output", input_filename, "TransferLLM"
    )
    if not os.path.exists(output_transfer_dic):
        os.makedirs(
            output_transfer_dic, exist_ok=True
        )  # å¦‚æœæ–‡ä»¶å¤¹å·²å­˜åœ¨ï¼Œåˆ™ä¸ä¼šæŠ›å‡ºå¼‚å¸¸
    # æ–°å»ºæ‰€éœ€mutate outputæ–‡ä»¶å¤¹
    output_mutate_dic = os.path.join(
        current_dir, "..", "..", "Output", input_filename, "MutationLLM"
    )
    if not os.path.exists(output_mutate_dic):
        os.makedirs(
            output_mutate_dic, exist_ok=True
        )  # å¦‚æœæ–‡ä»¶å¤¹å·²å­˜åœ¨ï¼Œåˆ™ä¸ä¼šæŠ›å‡ºå¼‚å¸¸

    with open(input_filepath, "r", encoding="utf-8") as r:
        bugs = r.readlines()
    for line in bugs:
        bug = json.loads(line)
        a_db = bug["a_db"]
        b_db = bug["b_db"]
        fuzzer = bug["molt"]

        # Step1: rag_based_feature_mappingã€‚å…ˆåšä»¥ä¸‹mappingï¼ŒSQLite/mariadb/ï¼ˆPostgresæ˜¯0æš‚æ—¶ä¸å¼„ï¼‰mapping to mysql/tidb/monetdb/duckdb/clickhouse
        # rag_feature_mapping_llm(1,0,a_db, b_db, ["function"], ["Feature", "Description", "Examples", "Category"])
        # rag_feature_mapping_count(1,0, a_db, b_db, ["function"], ["Feature", "Description", "Examples", "Category"])
        # rag_feature_mapping_process(1,0, a_db, b_db, ["function"], ["Feature", "Description", "Examples", "Category"])

        # Step2: potential_features_refiner
        bug_input = []
        bug_input_filename = os.path.join(input_dic, str(bug["index"]) + ".jsonl")
        if not os.path.exists(bug_input_filename):
            bug_input = load_sqlancer_bug_report(fuzzer, a_db, b_db, bug)
            for info in bug_input:
                with open(bug_input_filename, "a", encoding="utf-8") as a:
                    json.dump(info, a)
                    a.write("\n")
        else:
            print("ğŸ“¥ " + bug_input_filename + " exists.")
            with open(bug_input_filename, "r", encoding="utf-8") as r:
                lines = r.readlines()
            for line in lines:
                bug_input.append(json.loads(line))

        # Step3: æ ¹æ®bug reportä¸­ä¿¡æ¯è¿›è¡Œtransferå¹¶å­˜å‚¨åˆ°outputæ–‡ä»¶å¤¹ä¸­
        transfer_outputs = []
        bug_output_transfer_filename = os.path.join(
            output_transfer_dic, str(bug["index"]) + ".jsonl"
        )
        if not os.path.exists(bug_output_transfer_filename):
            # transfer llm conversion
            chat = ChatOpenAI(temperature=temperature, model=model)
            memory = ConversationBufferMemory()  # å†…å­˜ï¼šå¯¹è¯ç¼“å†²åŒºå†…å­˜
            if error_iteration:
                conversation = ConversationChain(
                    llm=chat,
                    memory=memory,
                    verbose=False,  # ä¸ºtrueçš„æ—¶å€™æ˜¯å±•ç¤ºlangchainå®é™…åœ¨åšä»€ä¹ˆ
                )
            else:
                conversation = ConversationChain(
                    llm=chat, verbose=False  # ä¸ºtrueçš„æ—¶å€™æ˜¯å±•ç¤ºlangchainå®é™…åœ¨åšä»€ä¹ˆ
                )
            for info in bug_input:
                transfer_start_time = datetime.now()  # ä½¿ç”¨ ISO 8601 æ ¼å¼
                (
                    costs,
                    transfer_results,
                    exec_results,
                    exec_times,
                    error_messages,
                    origin_exec_result,
                    origin_exec_time,
                    origin_error_message,
                    exec_equalities,
                ) = transfer_llm(
                    tool=tool,
                    exp=fuzzer,
                    conversation=conversation,
                    error_iteration=error_iteration,
                    iteration_num=iteration_num,
                    FewShot=FewShot,
                    with_knowledge=with_knowledge,
                    origin_db=a_db,
                    target_db=b_db,
                    test_info=info,
                )
                transfer_end_time = datetime.now()  # ä½¿ç”¨ ISO 8601 æ ¼å¼
                info["SqlExecResult"] = origin_exec_result
                info["SqlExecError"] = origin_error_message
                info["TransferResult"] = transfer_results
                info["TransferCost"] = costs
                info["TransferTimeCost"] = (
                    transfer_end_time - transfer_start_time
                ).total_seconds()
                info["TransferSqlExecResult"] = exec_results
                info["TransferSqlExecError"] = error_messages
                info["TransferSqlExecEqualities"] = exec_equalities
                transfer_outputs.append(info)
            # sqlanceræ‰§è¡Œå®Œä¸€ç»„sqlåï¼Œå°†a_dbå’Œd_dbéƒ½è¿›è¡Œclear
            database_clear(tool, fuzzer, a_db)
            database_clear(tool, fuzzer, b_db)
            # å…¨éƒ¨æ‰§è¡Œå®Œå†è¿›è¡Œå­˜å‚¨
            with open(bug_output_transfer_filename, "a", encoding="utf-8") as a:
                for item in transfer_outputs:
                    json.dump(make_json_safe(item), a, ensure_ascii=False)
                    a.write("\n")
        else:
            print("ğŸ“¥ " + bug_output_transfer_filename + " exists.")
            with open(bug_output_transfer_filename, "r", encoding="utf-8") as r:
                lines = r.readlines()
            for line in lines:
                transfer_outputs.append(json.loads(line))

        # Step4:mutate llm,å°†transferåçš„æœ€åä¸€å¥selectè¯­å¥è¿›è¡Œmutateå¹¶è¿”å›ç»“æœ
        mutate_results = []
        bug_output_mutate_filename = os.path.join(
            output_mutate_dic, str(bug["index"]) + ".jsonl"
        )
        if not os.path.exists(bug_output_mutate_filename):
            for item in transfer_outputs:
                mutate_results.append(item)
            if len(mutate_results) and len(mutate_results[-1]["TransferResult"]):
                print("ğŸ”§ mutate_results: ", mutate_results[-1])
                mutate_sql = _extract_transferred_stmt(
                    mutate_results[-1]["TransferResult"]
                )
                if mutate_sql is None:
                    print(
                        "ğŸ”§ [WARN] No TransferSQL/TransferNoSQL found in last TransferResult; skipping mutate phase for this bug."
                    )
                    continue

                # æ™ºèƒ½æ£€æµ‹å®é™…æ‰§è¡Œçš„ç›®æ ‡æ•°æ®åº“ç±»å‹
                # æ£€æŸ¥ TransferSqlExecResult æ¥ç¡®å®šçœŸå®çš„ç›®æ ‡æ•°æ®åº“
                actual_target_db = b_db  # é»˜è®¤ä½¿ç”¨ b_db
                if (
                    "TransferSqlExecResult" in mutate_results[-1]
                    and mutate_results[-1]["TransferSqlExecResult"]
                ):
                    try:
                        exec_result_str = mutate_results[-1]["TransferSqlExecResult"][0]
                        if isinstance(exec_result_str, str):
                            exec_result_json = json.loads(exec_result_str)
                            detected_db_type = exec_result_json.get(
                                "dbType", ""
                            ).lower()
                            if detected_db_type in ["mongodb", "mongo"]:
                                actual_target_db = "mongodb"
                                print(
                                    "ğŸ“¥ "
                                    + f"[INFO] Detected actual target database: MongoDB (b_db was {b_db})"
                                )
                    except (json.JSONDecodeError, KeyError, IndexError) as e:
                        print(
                            f"[WARN] Failed to detect actual target database: {e}, using b_db={b_db}"
                        )

                # mutate llm client
                client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY", ""))
                mutate_start_time = datetime.now()  # ä½¿ç”¨ ISO 8601 æ ¼å¼
                if fuzzer.lower() == "norec":
                    # ä¼˜å…ˆç¯å¢ƒå˜é‡ï¼Œå…¶æ¬¡å›é€€åˆ°é€šç”¨æ¨¡å‹ï¼ˆç”¨äº agent å¤±è´¥æ—¶çš„å…œåº•ï¼‰
                    mutate_llm_model_ID = os.environ.get(
                        f"{fuzzer}_MUTATION_LLM_ID".upper(), "gpt-4o-mini"
                    )
                elif "tlp" in fuzzer.lower():
                    fuzzer_temp = "tlp"
                    mutate_llm_model_ID = os.environ.get(
                        f"{fuzzer_temp}_MUTATION_LLM_ID".upper(), "gpt-4o-mini"
                    )
                elif "semantic" in fuzzer.lower():
                    fuzzer_temp = "semantic"
                    mutate_llm_model_ID = os.environ.get(
                        f"{fuzzer_temp}_MUTATION_LLM_ID".upper(), "gpt-4o-mini"
                    )
                else:
                    mutate_llm_model_ID = os.environ.get(
                        "SEMANTIC_MUTATION_LLM_ID", "gpt-4o-mini"
                    )
                # ========== Mem0 å¼€å§‹å˜å¼‚ä¼šè¯ ==========
                if mutation_mem0_manager:
                    try:
                        mutation_mem0_manager.start_session(
                            db_type=actual_target_db,
                            oracle_type=bug["molt"],
                            sql_type="SELECT"  # å‡å®šå˜å¼‚çš„éƒ½æ˜¯ SELECT ç±»æŸ¥è¯¢
                        )
                    except Exception as e:
                        print(f"âš ï¸ Failed to start mutation session: {e}")
                
                # è°ƒç”¨å˜å¼‚
                mutate_content, cost = run_muatate_llm_single_sql(
                    tool,
                    client,
                    mutate_llm_model_ID,
                    fuzzer,
                    bug["molt"],
                    actual_target_db,  # ä½¿ç”¨æ£€æµ‹åˆ°çš„å®é™…ç›®æ ‡æ•°æ®åº“,è€Œé b_db
                    mutate_sql,
                    mem0_manager=mutation_mem0_manager  # ä¼ å…¥ Mem0 ç®¡ç†å™¨
                )
                mutate_end_time = datetime.now()  # ä½¿ç”¨ ISO 8601 æ ¼å¼
                mutate_results[-1]["MutateTimeCost"] = (
                    mutate_end_time - mutate_start_time
                ).total_seconds()
                mutate_results[-1]["MutateResult"] = str(mutate_content)
                mutate_results[-1]["MutateCost"] = cost
                # è¿›è¡Œå­˜å‚¨
                with open(bug_output_mutate_filename, "a", encoding="utf-8") as a:
                    for item in mutate_results:
                        json.dump(make_json_safe(item), a, ensure_ascii=False)
                        a.write("\n")
        else:
            print("ğŸ”§ " + bug_output_mutate_filename + " å·²å­˜åœ¨")
            # loadå‡ºæ¥
            with open(bug_output_mutate_filename, "r", encoding="utf-8") as r:
                lines = r.readlines()
            for line in lines:
                mutate_results.append(json.loads(line))

        # Step5: check oracle,æ‰§è¡Œmutateåsqlå¹¶è®°å½•æ‰§è¡Œç»“æœä»¥åŠoracle checkç»“æœ
        if "MutateSqlExecResult" not in mutate_results[-1]:
            ddls = []
            transfer_fail_flag = False
            for i in range(len(mutate_results) - 1):
                stmt_i = _extract_transferred_stmt(mutate_results[i]["TransferResult"])
                if stmt_i:
                    ddls.append(stmt_i)
                if mutate_results[i]["TransferSqlExecError"][-1] != "None":
                    transfer_fail_flag = True
            # å…ˆåˆ›é€ æ‰§è¡Œç¯å¢ƒ
            database_clear(tool, fuzzer, b_db)
            for ddl in ddls:
                exec_sql_statement(tool, fuzzer, b_db, ddl)

            before_mutate = _extract_transferred_stmt(
                mutate_results[-1]["TransferResult"]
            )
            if before_mutate is None:
                print(
                    "[ERROR] Cannot extract before_mutate statement; aborting mutate/oracle stage for this bug."
                )
                continue
            after_mutate = mutate_results[-1]["MutateResult"]

            before_result, before_exec_time, before_error_message = exec_sql_statement(
                tool, fuzzer, b_db, before_mutate
            )

            # å¦‚æœ MutateResult æ˜¯ JSON ä¸”åŒ…å« mutations åˆ—è¡¨ï¼Œåˆ™é€æ¡è§£æå¹¶æ‰§è¡Œæ¯ä¸ª cmdï¼ˆé€‚ç”¨äº NoSQL mutation å›æ”¾ï¼‰
            after_result = None
            after_exec_time = None
            after_error_message = None
            try:
                parsed_mutate = None
                if isinstance(mutate_results[-1].get("MutateResult"), str):
                    try:
                        # å…ˆå°è¯•ä½¿ç”¨ json-repair ä¿®å¤å¯èƒ½çš„ JSON æ ¼å¼é”™è¯¯
                        repaired_json = repair_json(mutate_results[-1]["MutateResult"])
                        parsed_mutate = json.loads(repaired_json)
                    except Exception:
                        # å¦‚æœä¿®å¤å¤±è´¥ï¼Œå°è¯•ç›´æ¥è§£æ
                        try:
                            parsed_mutate = json.loads(
                                mutate_results[-1]["MutateResult"]
                            )
                        except Exception:
                            parsed_mutate = None
                else:
                    parsed_mutate = mutate_results[-1].get("MutateResult")

                if isinstance(parsed_mutate, dict) and "mutations" in parsed_mutate:
                    cmds = []
                    for m in parsed_mutate.get("mutations", []):
                        # æ”¯æŒä¸¤ç§å­—æ®µå: "cmd" å’Œ "mutated_sql"
                        cmd = m.get("cmd") or m.get("mutated_sql")
                        if cmd:
                            # å¦‚æœ cmd æœ¬èº«æ˜¯å­—ç¬¦ä¸²ä¸”åŒ…å« JSONï¼Œä¹Ÿå°è¯•ä¿®å¤
                            if isinstance(cmd, str) and cmd.strip().startswith("{"):
                                try:
                                    repaired_cmd = repair_json(cmd)
                                    cmds.append(repaired_cmd)
                                except Exception:
                                    cmds.append(cmd)
                            else:
                                cmds.append(cmd)

                    mutate_exec_list = []
                    mutate_errors = []
                    total_time = 0.0
                    for cmd in cmds:
                        r, t, e = exec_sql_statement(tool, fuzzer, b_db, cmd)
                        mutate_exec_list.append(r)
                        mutate_errors.append(e)
                        try:
                            total_time += float(t)
                        except Exception:
                            pass

                    # ä¿å­˜é€æ¡æ‰§è¡Œçš„ç»“æœï¼ˆåºåˆ—åŒ–ä¸º JSON å­—ç¬¦ä¸²ä»¥ä¾¿æŒä¹…åŒ–ï¼‰
                    mutate_results[-1]["MutateSqlExecResult"] = json.dumps(
                        mutate_exec_list, ensure_ascii=False
                    )
                    mutate_results[-1]["MutateSqlExecTime"] = str(total_time)
                    # å¦‚æœæ‰€æœ‰å­å‘½ä»¤éƒ½æ²¡æœ‰æŠ¥é”™ï¼Œåˆ™æ ‡è®° Noneï¼ˆå­—ç¬¦ä¸²å½¢å¼ä¿æŒå…¼å®¹ï¼‰
                    any_err = [e for e in mutate_errors if e and str(e) != "None"]
                    mutate_results[-1]["MutateSqlExecError"] = (
                        str(any_err) if any_err else "None"
                    )

                    # é€‰æ‹©ç”¨äº oracle æ¯”è¾ƒçš„ after_resultï¼šä¼˜å…ˆå–ç¬¬ä¸€æ¬¡ kv_get çš„è¿”å›ï¼Œå…¶æ¬¡å–æœ€åä¸€ä¸ªå¯ç”¨ dict è¿”å›
                    for r in mutate_exec_list:
                        if isinstance(r, dict) and str(r.get("type", "")).startswith(
                            "kv_get"
                        ):
                            after_result = r
                            break
                    if after_result is None:
                        for r in reversed(mutate_exec_list):
                            if isinstance(r, dict):
                                after_result = r
                                break

                    if after_result is None:
                        # è‹¥é€æ¡æ‰§è¡Œæ²¡æœ‰å¯ç”¨ç»“æ„åŒ–ç»“æœï¼Œfallback ä¸ºå°è¯•æŠŠæ•´ä½“ MutateResult å½“ä½œå•æ¡å‘½ä»¤æ‰§è¡Œ
                        after_result, after_exec_time, after_error_message = (
                            exec_sql_statement(
                                tool,
                                fuzzer,
                                b_db,
                                mutate_results[-1].get("MutateResult"),
                            )
                        )
                    else:
                        after_exec_time = total_time
                        after_error_message = None
                else:
                    # ä¸æ˜¯ JSON mutationsï¼ŒæŒ‰æ—§é€»è¾‘ç›´æ¥æ‰§è¡Œæ•´ä¸ªå­—ç¬¦ä¸²
                    after_result, after_exec_time, after_error_message = (
                        exec_sql_statement(
                            tool, fuzzer, b_db, mutate_results[-1].get("MutateResult")
                        )
                    )
            except Exception as e:
                # å‡ºç°å¼‚å¸¸æ—¶å›é€€åˆ°åŸè¡Œä¸º
                after_result, after_exec_time, after_error_message = exec_sql_statement(
                    tool, fuzzer, b_db, mutate_results[-1].get("MutateResult")
                )

            # å¯¹äºsqlancerçš„tlpï¼Œè°“è¯çš„éšæœºæ€§æ¯”è¾ƒå¤§ï¼Œè¿™é‡Œå°†é‡å¤å‡ æ¬¡ï¼Œä»¥ç”Ÿæˆå¯æ‰§è¡Œçš„mutate sql
            if fuzzer.lower() == "tlp":
                client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY", ""))
                mutate_cnt = 1
                while mutate_cnt <= iteration_num:
                    if after_error_message != None:
                        mutate_llm_model_ID = os.environ[
                            f"{fuzzer}_MUTATION_LLM_ID".upper()
                        ]
                        (
                            mutate_results[-1]["MutateResult"],
                            mutate_results[-1]["MutateCost"],
                        ) = run_muatate_llm_single_sql(
                            tool,
                            client,
                            mutate_llm_model_ID,
                            fuzzer,
                            # Some bug reports may not include an 'oracle' field.
                            # Fall back to 'molt' (fuzzer type) or None to preserve behavior
                            # and avoid KeyError.
                            bug.get("oracle", bug.get("molt", None)),
                            b_db,
                            before_mutate,
                        )
                        after_mutate = mutate_results[-1]["MutateResult"]
                        after_result, after_exec_time, after_error_message = (
                            exec_sql_statement(tool, fuzzer, b_db, after_mutate)
                        )

                        # å°†æœ€åä¸€æ¬¡çš„ç»“æœå­˜å‚¨åˆ°å¯¹åº”çš„mutate outputæ–‡ä»¶ä¸­,å…ˆæ¸…ç©º
                        with open(
                            bug_output_mutate_filename, "w", encoding="utf-8"
                        ) as a:
                            pass
                        with open(
                            bug_output_mutate_filename, "a", encoding="utf-8"
                        ) as a:
                            for item in mutate_results:
                                json.dump(make_json_safe(item), a, ensure_ascii=False)
                                a.write("\n")
                        mutate_cnt += 1
                    else:
                        break
            # å…¨éƒ¨æ‰§è¡Œå®Œå†æ¬¡è¿›è¡Œclear
            database_clear(tool, fuzzer, b_db)
            # å¯¹ä¸åŒç±»å‹çš„ç›®æ ‡æ•°æ®åº“é‡‡ç”¨ä¸åŒçš„æŒä¹…åŒ–æ ¼å¼ï¼š
            # - å¯¹äºå…³ç³»å‹/SQL æ•°æ®åº“ï¼Œä¿ç•™åŸæ³¨é‡Šé‡Œçš„è¡Œä¸ºï¼ˆå­—ç¬¦ä¸²åŒ–ï¼‰ï¼Œä»¥ä¿æŒä¸ç°æœ‰ downstream å…¼å®¹æ€§
            # - å¯¹äº NoSQLï¼ˆå¦‚ MongoDB/Redis ç­‰ï¼‰ï¼Œä½¿ç”¨ json.dumps() æ¥ç¡®ä¿å­—æ®µä¸ºåˆæ³• JSONï¼ˆåŒå¼•å·ï¼‰ï¼Œå¹¶ä¿ç•™ç»“æ„åŒ–ä¿¡æ¯
            nosql_dbs = {"mongodb", "mongo", "redis", "etcd", "memcached", "cassandra"}
            try:
                if isinstance(b_db, str) and b_db.lower() in nosql_dbs:
                    # NoSQL: ä¿ç•™ç»“æ„åŒ–ç»“æœå¹¶ä½¿ç”¨åˆæ³• JSON åºåˆ—åŒ–
                    mutate_results[-1]["MutateSqlExecResult"] = json.dumps(
                        after_result, ensure_ascii=False
                    )
                    mutate_results[-1]["MutateSqlExecTime"] = str(after_exec_time)
                    # å¯¹ Error ä¹Ÿä½¿ç”¨ json.dumps()ï¼Œå°† None è½¬ä¸º null
                    mutate_results[-1]["MutateSqlExecError"] = json.dumps(
                        after_error_message, ensure_ascii=False
                    )
                else:
                    # SQL: ä½¿ç”¨å­—ç¬¦ä¸²åŒ–ä»¥å…¼å®¹æ—§é€»è¾‘ï¼ˆæ³¨é‡Šä¸­çš„å®ç°ï¼‰
                    mutate_results[-1]["MutateSqlExecResult"] = str(after_result)
                    mutate_results[-1]["MutateSqlExecTime"] = str(after_exec_time)
                    mutate_results[-1]["MutateSqlExecError"] = str(after_error_message)
            except Exception:
                # åœ¨æç«¯æƒ…å†µä¸‹å›é€€åˆ°é€šç”¨å­—ç¬¦ä¸²åŒ–ï¼Œé¿å…ç ´åæ–‡ä»¶å†™å…¥æµç¨‹
                mutate_results[-1]["MutateSqlExecResult"] = str(after_result)
                mutate_results[-1]["MutateSqlExecTime"] = str(after_exec_time)
                mutate_results[-1]["MutateSqlExecError"] = str(after_error_message)

            if before_error_message or after_error_message:
                # å¦‚æœæ˜¯mutateå‰å’Œåçš„è¯­å¥æœ‰æ‰§è¡Œfailçš„æƒ…å†µ
                oracle_check_res = {"end": False, "error": "exec fail"}
            else:
                # -------- TLP Oracle æ£€æŸ¥ -------- #
                # æ£€æŸ¥æ˜¯å¦ä¸º TLP å˜å¼‚(é€šè¿‡ oracle å­—æ®µåˆ¤æ–­)
                if is_tlp_mutation(mutate_results[-1]):
                    try:
                        # ä¸º TLP å‡†å¤‡å˜å¼‚ç»“æœåˆ—è¡¨
                        # mutate_results[-1] åŒ…å«äº†æ‰€æœ‰åˆ†åŒºçš„æ‰§è¡Œç»“æœ
                        tlp_results = []

                        # è§£æ mutations æ•°ç»„
                        mutate_result_str = mutate_results[-1].get("MutateResult", "{}")
                        if isinstance(mutate_result_str, str):
                            parsed_mutate = json.loads(mutate_result_str)
                        else:
                            parsed_mutate = mutate_result_str

                        mutations = parsed_mutate.get("mutations", [])

                        # è§£ææ‰§è¡Œç»“æœåˆ—è¡¨
                        exec_result_str = mutate_results[-1].get(
                            "MutateSqlExecResult", "[]"
                        )
                        if isinstance(exec_result_str, str):
                            exec_results = json.loads(exec_result_str)
                        else:
                            exec_results = exec_result_str

                        # ç»„è£…æ¯ä¸ªåˆ†åŒºçš„ç»“æœ
                        for i, (mutation, exec_result) in enumerate(
                            zip(mutations, exec_results)
                        ):
                            tlp_results.append(
                                {
                                    "MutateResult": json.dumps(
                                        {"mutations": [mutation]}
                                    ),
                                    "MutateSqlExecResult": exec_result,
                                }
                            )

                        # è°ƒç”¨ TLP æ£€æŸ¥å™¨
                        oracle_check_res = check_tlp_oracle(tlp_results)

                    except Exception as e:
                        oracle_check_res = {
                            "end": False,
                            "error": f"TLP oracle check failed: {str(e)}",
                            "bug_type": "tlp_check_error",
                        }
                else:
                    # -------- é TLP: ä½¿ç”¨åŸæœ‰çš„ Oracle æ£€æŸ¥é€»è¾‘ -------- #
                    converted_before_result = execSQL_result_convertor(before_result)
                    converted_after_result = execSQL_result_convertor(after_result)

                    # -------- KV ä¸“ç”¨ oracle -------- #
                    # è¯†åˆ«æ¡ä»¶ï¼šåŸå§‹ before_result/after_result ä¸º dict ä¸”å« 'type' ä¸”å‰ç¼€ kv_
                    is_kv_before = isinstance(before_result, dict) and str(
                        before_result.get("type", "")
                    ).startswith("kv_")
                    is_kv_after = isinstance(after_result, dict) and str(
                        after_result.get("type", "")
                    ).startswith("kv_")
                    if is_kv_before and is_kv_after:
                        # ç®€åŒ–ç­–ç•¥ï¼š
                        # 1) å¯¹ kv_getï¼šå€¼ç›¸ç­‰ (åŒ…å«å‡ä¸º None) åˆ™é€šè¿‡
                        # 2) å¯¹å†™æ“ä½œ (kv_set/kv_delete) -> after ä¸æŠ¥é”™å³å¯é€šè¿‡ï¼ˆä¸å¯æ¯”å€¼ï¼‰
                        # 3) kv_rangeï¼šåˆ—è¡¨å…ƒç´ é›†åˆä¸€è‡´ï¼ˆå¿½ç•¥é¡ºåºï¼‰
                        bt = before_result.get("type")
                        at = after_result.get("type")
                        bval = before_result.get("value")
                        aval = after_result.get("value")
                        passed = False
                        err = None
                        if bt == "kv_get" and at == "kv_get":
                            passed = bval == aval
                        elif bt in {"kv_set", "kv_delete"} and at in {
                            "kv_set",
                            "kv_delete",
                        }:
                            # è®¤ä¸ºå†™åå†æ¬¡å†™æˆ–åˆ é™¤è¯­ä¹‰ä¸åº”å¼•å…¥ç›´æ¥å·®å¼‚ï¼ˆç¼ºä¹æ›´å¼º oracleï¼Œæ­¤å¤„æ”¾å®½ï¼‰
                            passed = True
                        elif bt == "kv_range" and at == "kv_range":
                            try:
                                bset = {str(x) for x in (bval or [])}
                                aset = {str(x) for x in (aval or [])}
                                passed = bset == aset
                            except Exception:
                                passed = False
                        else:
                            # ç±»å‹ä¸åŒï¼Œä¿å®ˆåˆ¤å®šå¤±è´¥
                            passed = False
                            err = f"kv oracle type mismatch: {bt} vs {at}"
                        oracle_check_res = {"end": passed, "error": err}
                    else:
                        # -------- å…³ç³»å‹/é€šç”¨ oracle -------- #
                        before_result_object = Result(
                            converted_before_result["column_names"],
                            converted_before_result["column_types"],
                            converted_before_result["rows"],
                        )
                        after_result_object = Result(
                            converted_after_result["column_names"],
                            converted_after_result["column_types"],
                            converted_after_result["rows"],
                        )
                        oracle_check, error = Check(
                            before_result_object, after_result_object, True, True
                        )  # check result->another_resultæ˜¯å¦ç¬¦åˆis_upper
                        oracle_check_res = {"end": oracle_check, "error": error}
                        # åˆ¤æ–­æ˜¯å¦ä¸ºsqlancerçš„ç‰¹æ®Šæƒ…å†µï¼š0==None(è¡¨ç¤ºä¸ªæ•°æ—¶)
                        if converted_before_result["rows"] == [
                            ["0"]
                        ] and converted_after_result["rows"] == [["None"]]:
                            oracle_check_res = {"end": True, "error": None}

            # å¦‚æœddlsä¸­æœ‰transferå¤±è´¥çš„æƒ…å†µ
            if transfer_fail_flag:
                oracle_check_res = {"end": False, "error": "transfer fail"}
            mutate_results[-1]["OracleCheck"] = oracle_check_res
            
            # ========== Mem0 è®°å½• Bug æ¨¡å¼ ==========
            if mutation_mem0_manager and oracle_check_res:
                try:
                    # å¦‚æœ Oracle æ£€æŸ¥å¤±è´¥ä¸”ä¸æ˜¯æ‰§è¡Œé”™è¯¯ï¼Œè¯´æ˜å‘ç°äº†æ½œåœ¨ Bug
                    if oracle_check_res.get("end") == False and oracle_check_res.get("error") in [None, "None"]:
                        bug_type = oracle_check_res.get("bug_type", "oracle_violation")
                        
                        mutation_mem0_manager.record_bug_pattern(
                            original_sql=mutate_sql,
                            mutation_sql=str(mutate_results[-1].get("MutateResult", "")),
                            bug_type=bug_type,
                            oracle_type=bug["molt"],
                            db_type=actual_target_db,
                            oracle_details=oracle_check_res.get("details", {})
                        )
                        print(f"ğŸ› Bug pattern recorded to Mem0: {bug_type}")
                    
                    # è®°å½• Oracle å¤±è´¥æ¨¡å¼ï¼ˆåŒ…æ‹¬æ‰§è¡Œé”™è¯¯ï¼‰
                    elif oracle_check_res.get("end") == False:
                        mutation_mem0_manager.record_oracle_failure_pattern(
                            original_sql=mutate_sql,
                            mutation_sql=str(mutate_results[-1].get("MutateResult", "")),
                            failure_reason=str(oracle_check_res.get("error", "unknown")),
                            oracle_type=bug["molt"],
                            db_type=actual_target_db,
                            expected_result=before_result,
                            actual_result=after_result
                        )
                    
                    # ç»“æŸä¼šè¯
                    mutation_mem0_manager.end_session(
                        success=oracle_check_res.get("end", False),
                        summary=f"Oracle: {bug['molt']}, Result: {oracle_check_res.get('end', False)}"
                    )
                    
                    # æ‰“å°æ€§èƒ½æŒ‡æ ‡
                    if hasattr(mutation_mem0_manager, 'get_metrics_report'):
                        print(mutation_mem0_manager.get_metrics_report())
                        
                except Exception as e:
                    print(f"âš ï¸ Failed to record to Mutation Mem0: {e}")
            
            # ========== ğŸ”¥ MVP åå‘åé¦ˆæœºåˆ¶ï¼šç”Ÿæˆ Recommendation ==========
            if mem0_manager and oracle_check_res.get("end") == False:
                _generate_recommendation_from_oracle(
                    mem0_manager=mem0_manager,
                    oracle_result=oracle_check_res,
                    original_sql=mutate_sql,  # ä½¿ç”¨ mutate_sql è€Œä¸æ˜¯ info["sql"]
                    origin_db=a_db,
                    target_db=actual_target_db,  # ä½¿ç”¨æ£€æµ‹åˆ°çš„å®é™…ç›®æ ‡æ•°æ®åº“
                    oracle_type=bug.get("molt", "unknown")
                )
            
            with open(bug_output_mutate_filename, "w", encoding="utf-8") as a:
                pass
            with open(bug_output_mutate_filename, "a", encoding="utf-8") as a:
                for item in mutate_results:
                    json.dump(make_json_safe(item), a, ensure_ascii=False)
                    a.write("\n")
    print("ğŸ“¥ ------------------------")


def sqlancer_qtran_run(
    input_filepath,
    tool="sqlancer",
    temperature=0.3,
    model="gpt-4o-mini",
    error_iteration=True,
    iteration_num=4,
    FewShot=False,
    with_knowledge=True,
):
    sqlancer_translate(
        input_filepath=input_filepath,
        tool="sqlancer",
        temperature=temperature,
        model=model,
        error_iteration=True,
        iteration_num=iteration_num,
        FewShot=False,
        with_knowledge=False,
    )
    getSuspicious(input_filepath=input_filepath, tool="sqlancer")


def getSuspicious(input_filepath, tool):
    input_filename = os.path.basename(input_filepath).replace(".jsonl", "")
    output_mutate_dic = os.path.join(
        current_dir, "..", "..", "Output", input_filename, "MutationLLM"
    )
    if not os.path.exists(output_mutate_dic):
        os.makedirs(
            output_mutate_dic, exist_ok=True
        )  # å¦‚æœæ–‡ä»¶å¤¹å·²å­˜åœ¨ï¼Œåˆ™ä¸ä¼šæŠ›å‡ºå¼‚å¸¸

    suspicious_dic = os.path.join(
        current_dir, "..", "..", "Output", input_filename, "SuspiciousBugs"
    )
    if not os.path.exists(suspicious_dic):
        os.makedirs(suspicious_dic, exist_ok=True)  # å¦‚æœæ–‡ä»¶å¤¹å·²å­˜åœ¨ï¼Œåˆ™ä¸ä¼šæŠ›å‡ºå¼‚å¸¸

    filenames = os.listdir(output_mutate_dic)
    for file in filenames:
        if os.path.exists(os.path.join(suspicious_dic, file)):
            continue
        with open(os.path.join(output_mutate_dic, file), "r", encoding="utf-8") as r:
            lines = r.readlines()
        contents = []
        for line in lines:
            contents.append(json.loads(line))
        # end Falseï¼šä¸æ»¡è¶³ç­‰ä»· / ä¸å˜é‡
        # error Noneï¼šä¸”ä¸æ˜¯æ‰§è¡Œå¤±è´¥ï¼ˆexec fail / transfer failï¼‰
        # å³é€»è¾‘å±‚å·®å¼‚
        if (
            contents[-1]["OracleCheck"]["end"] == False
            and contents[-1]["OracleCheck"]["error"] == None
        ):
            original_sqls = []
            results_sqls = []
            for content in contents:
                extracted_stmt = _extract_transferred_stmt(content["TransferResult"])
                new_content = {
                    "index": content["index"],
                    "sql": content["sql"],
                    "TransferResult": [extracted_stmt] if extracted_stmt else [],
                }
                original_sqls.append(content["sql"] + "\n")
                if extracted_stmt:
                    results_sqls.append(extracted_stmt + "\n")
                if "MutateResult" in content:
                    new_content["TransferSqlExecResult"] = [
                        content["TransferSqlExecResult"][-1]
                    ]
                    new_content["MutateResult"] = content["MutateResult"]
                    new_content["MutateSqlExecResult"] = content["MutateSqlExecResult"]
                    results_sqls.append(content["MutateResult"] + "\n")
                with open(
                    os.path.join(suspicious_dic, file), "a", encoding="utf-8"
                ) as a:
                    json.dump(new_content, a)
                    a.write("\n")
            with open(
                os.path.join(suspicious_dic, file.replace("jsonl", "txt")),
                "w",
                encoding="utf-8",
            ) as file:
                file.writelines(original_sqls + ["\n", "\n"] + results_sqls)


def evaluate(
    tool,
    temperature,
    model,
    error_iteration,
    iteration_num,
    FewShot,
    with_knowledge,
    fuzzer,
    a_db,
    b_db,
):
    # æ€»æ•°ï¼štotal_cnt
    # executableæ€»æ•°ï¼šmutateå¯æ‰§è¡Œçš„æ•°ç›®
    # validï¼šmutateæ»¡è¶³oracleçš„æ•°ç›®
    # preciseï¼šmutateè¯­ä¹‰æ­£ç¡®çš„æ•°é‡
    total_cnt = 0
    executable_cnt = 0
    valid_cnt = 0
    precise_cnt = 0

    oracle_check_transfer_fail = {"end": False, "error": "transfer fail"}
    oracle_check_mutate_fail = {"end": False, "error": "exec fail"}
    oracle_check_mutate_success = {"end": True, "error": None}

    oracle_check_fail = {"end": False, "error": None}

    # output_mutate_dic = os.path.join(sqlancer_output_mutate_dic, fuzzer, (a_db + "_to_" + b_db).lower())
    # output_mutate_dic_ = os.path.join(sqlancer_output_mutate_dic_, fuzzer, (a_db + "_to_" + b_db).lower())
    output_mutate_dic = os.path.join(
        "sqlancer_output_mutate_dic", fuzzer, (a_db + "_to_" + b_db).lower()
    )
    output_mutate_dic_ = os.path.join(
        "sqlancer_output_mutate_dic_", fuzzer, (a_db + "_to_" + b_db).lower()
    )

    files = os.listdir(output_mutate_dic)
    for file in files:
        total_cnt += 1
        contents = []
        with open(os.path.join(output_mutate_dic, file), "r", encoding="utf-8") as r:
            lines = r.readlines()
        for line in lines:
            contents.append(json.loads(line))
        oracle_check = contents[-1]["OracleCheck"]
        mutate_sql = contents[-1]["MutateResult"]

        contents_ = []
        with open(os.path.join(output_mutate_dic_, file), "r", encoding="utf-8") as r:
            lines = r.readlines()
        for line in lines:
            contents_.append(json.loads(line))
        right_mutate_sql = contents_[-1]["MutateResult"]
        if oracle_check != oracle_check_transfer_fail:
            if oracle_check != oracle_check_mutate_fail:
                executable_cnt += 1
                if oracle_check == oracle_check_mutate_success:
                    valid_cnt += 1
                # åˆ¤æ–­no finetuningçš„ç”Ÿæˆçš„å¥å­å’Œfine tuningç”Ÿæˆçš„å¥å­æ˜¯å¦ç›¸åŒï¼Œç›¸åŒåˆ™è®¤ä¸ºæ˜¯æ­£ç¡®çš„
                if mutate_sql == right_mutate_sql:
                    precise_cnt += 1
                # print("before mutate:"+contents[-1]["Sql"])
                # print("after mutate:"+mutate_sql)
                # print("right mutate:"+right_mutate_sql)
                # print('------------------')
    print("total_cnt:" + str(total_cnt))
    print("executable_cnt:" + str(executable_cnt))
    print("valid_cnt:" + str(valid_cnt))
    print("precise_cnt:" + str(precise_cnt))


# ========== ğŸ”¥ MVP åå‘åé¦ˆæœºåˆ¶è¾…åŠ©å‡½æ•° ==========

def _generate_recommendation_from_oracle(
    mem0_manager,
    oracle_result: dict,
    original_sql: str,
    origin_db: str,
    target_db: str,
    oracle_type: str
):
    """
    æ ¹æ® Oracle æ£€æŸ¥ç»“æœç”Ÿæˆ Recommendation å’Œ CoverageHotspot
    
    Args:
        mem0_manager: Mem0 ç®¡ç†å™¨
        oracle_result: Oracle æ£€æŸ¥ç»“æœ
        original_sql: åŸå§‹SQL
        origin_db: æºæ•°æ®åº“
        target_db: ç›®æ ‡æ•°æ®åº“
        oracle_type: Oracle ç±»å‹ (tlp/norec/semantic)
    """
    # åªåœ¨å‘ç°æ½œåœ¨Bugæ—¶ç”Ÿæˆå»ºè®®
    if oracle_result.get("end") == False and oracle_result.get("error") in [None, "None", ""]:
        # æå–SQLç‰¹æ€§
        features = _extract_sql_features(original_sql)
        
        # è®¡ç®—ä¼˜å…ˆçº§ï¼ˆåŸºäºbugç±»å‹ï¼‰
        bug_type = oracle_result.get("bug_type", "unknown")
        if bug_type == "TLP_violation":
            priority = 9
            coverage_gain = 15.0  # TLP violation è®¤ä¸ºæ˜¯é«˜ä»·å€¼çš„è¦†ç›–
        elif bug_type == "NoREC_mismatch":
            priority = 8
            coverage_gain = 12.0
        else:
            priority = 7
            coverage_gain = 8.0
        
        try:
            # 1. ğŸ”¥ ç”Ÿæˆ CoverageHotspotï¼ˆOracleå¤±è´¥ = å‘ç°äº†æœ‰ä»·å€¼çš„ç‰¹æ€§ç»„åˆï¼‰
            if hasattr(mem0_manager, 'add_coverage_hotspot'):
                mem0_manager.add_coverage_hotspot(
                    features=features,
                    coverage_gain=coverage_gain,
                    origin_db=origin_db,
                    target_db=target_db,
                    mutation_sql=original_sql,
                    metadata={
                        "bug_type": bug_type,
                        "oracle_type": oracle_type,
                        "source": "oracle_violation"
                    }
                )
                print(f"ğŸ”¥ Generated hotspot: {', '.join(features)} (gain: {coverage_gain}%)")
            
            # 2. ç”Ÿæˆ Recommendation
            mem0_manager.add_recommendation(
                target_agent="translation",
                priority=priority,
                action="prioritize_features",
                features=features,
                reason=f"{oracle_type}_oracle_violation: {bug_type}",
                origin_db=origin_db,
                target_db=target_db,
                metadata={
                    "bug_type": bug_type,
                    "oracle_type": oracle_type,
                    "details": oracle_result.get("details", {}),
                    "coverage_gain": coverage_gain
                }
            )
            
            print(f"ğŸ”¥ Generated recommendation: prioritize {', '.join(features)} (Priority: {priority})")
        except Exception as e:
            print(f"âš ï¸ Failed to generate recommendation: {e}")


def _extract_sql_features(sql: str) -> list:
    """
    ä»SQLä¸­æå–å…³é”®ç‰¹æ€§
    
    Returns:
        ç‰¹æ€§åˆ—è¡¨ï¼Œå¦‚ ["HEX", "MIN", "COLLATE", "aggregate"]
    """
    features = []
    sql_upper = sql.upper()
    
    # å¸¸è§å‡½æ•°
    functions = [
        "HEX", "MIN", "MAX", "SUM", "AVG", "COUNT", "ABS", 
        "CONCAT", "SUBSTR", "SUBSTRING", "LENGTH", "UPPER", "LOWER",
        "ROUND", "FLOOR", "CEIL", "CAST", "COALESCE", "NULLIF"
    ]
    for func in functions:
        if f"{func}(" in sql_upper:
            features.append(func)
    
    # ç‰¹æ®Šå…³é”®å­—
    keywords = [
        "COLLATE", "UNION", "INTERSECT", "EXCEPT", "JOIN", 
        "GROUP BY", "HAVING", "ORDER BY", "LIMIT", "OFFSET",
        "DISTINCT", "WHERE", "CASE WHEN"
    ]
    for kw in keywords:
        if kw in sql_upper:
            features.append(kw.replace(" ", "_"))
    
    # èšåˆåˆ¤æ–­
    if any(agg in sql_upper for agg in ["MIN(", "MAX(", "SUM(", "AVG(", "COUNT("]):
        if "aggregate" not in features:
            features.append("aggregate")
    
    # JOIN ç±»å‹
    join_types = ["INNER JOIN", "LEFT JOIN", "RIGHT JOIN", "FULL JOIN", "CROSS JOIN"]
    for jt in join_types:
        if jt in sql_upper:
            features.append(jt.replace(" ", "_"))
            break  # åªæ·»åŠ ä¸€æ¬¡
    
    # MongoDB ç‰¹å®šæ“ä½œç¬¦ï¼ˆå¦‚æœSQLä¸­åŒ…å«ï¼‰
    mongodb_ops = ["$and", "$or", "$not", "$exists", "$type", "$gte", "$lte", "$in", "$nin"]
    for op in mongodb_ops:
        if op in sql:
            features.append(op)
    
    # å»é‡å¹¶é™åˆ¶æ•°é‡
    unique_features = list(dict.fromkeys(features))  # ä¿æŒé¡ºåºå»é‡
    return unique_features[:5]  # é™åˆ¶è¿”å›æœ€å¤š5ä¸ªç‰¹æ€§
