"""
QTRAN é¡¹ç›®å…¥å£ï¼šè§£æå‘½ä»¤è¡Œå‚æ•°å¹¶å¯åŠ¨ä¸¤é˜¶æ®µæµç¨‹

ä½œç”¨æ¦‚è¿°ï¼š
- ç¨‹åºå…¥å£ï¼Œè´Ÿè´£è§£æ --input_filenameã€--tool ç­‰å‚æ•°ã€‚
- è°ƒç”¨ qtran_runï¼Œæ ¹æ®é€‰æ‹©çš„æ¥æºå·¥å…·ï¼ˆsqlancer / pinoloï¼‰é©±åŠ¨"è½¬æ¢é˜¶æ®µ(Transfer)"ä¸åç»­æµç¨‹æ•°æ®å‡†å¤‡ã€‚
- åœ¨é¦–æ¬¡è¿è¡Œæ—¶ï¼ŒæŒ‰éœ€åˆ›å»ºå„æ•°æ®åº“ä¸å®éªŒç¯å¢ƒæ‰€éœ€å®¹å™¨/åº“å®ä¾‹ã€‚
- ğŸ†• é›†æˆè½»é‡çº§åè°ƒæœºåˆ¶ï¼šåŸºäºé»‘æ¿æ¨¡å¼åŠ¨æ€è°ƒæ•´å·¥ä½œæµç­–ç•¥ã€‚

å…³è”æµç¨‹å‚è€ƒï¼šè§ abstract.md ä¸­ã€Šæ ¸å¿ƒç›®æ ‡ã€‹ã€Šè°ƒç”¨é“¾æ¦‚è§ˆã€‹ã€Šé˜¶æ®µä¸€ï¼šè½¬æ¢ã€‹ç« èŠ‚ã€‚
"""

import sys
import os
import openai
import argparse
import json
from src.TransferLLM.translate_sqlancer import sqlancer_qtran_run
from src.TransferLLM.TransferLLM import pinolo_qtran_run
from src.Tools.DatabaseConnect.docker_create import docker_create_databases
from src.Coordinator import SimpleCoordinator

environment_variables = os.environ
os.environ["http_proxy"] = environment_variables.get("HTTP_PROXY", "")
os.environ["https_proxy"] = environment_variables.get("HTTPS_PROXY", "")
openai.api_key = os.environ.get("OPENAI_API_KEY", "")

current_file_path = os.path.abspath(__file__)
current_dir = os.path.dirname(current_file_path)


def scan_databases_from_input(input_filepath):
    """
    æ‰«æè¾“å…¥æ–‡ä»¶ï¼Œæå–æ‰€æœ‰æ¶‰åŠçš„ a_db å’Œ b_db æ•°æ®åº“ã€‚

    å‚æ•°ï¼š
    - input_filepath: JSONL è¾“å…¥æ–‡ä»¶è·¯å¾„

    è¿”å›ï¼š
    - set: åŒ…å«æ‰€æœ‰éœ€è¦åˆå§‹åŒ–çš„æ•°æ®åº“åç§°é›†åˆ
    """
    databases = set()
    try:
        with open(input_filepath, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    data = json.loads(line)
                    if "a_db" in data:
                        databases.add(data["a_db"].lower())
                    if "b_db" in data:
                        databases.add(data["b_db"].lower())
                except json.JSONDecodeError:
                    continue
    except FileNotFoundError:
        print(f"Warning: Input file not found: {input_filepath}")

    return databases


def qtran_run(
    input_filename,
    tool,
    temperature=0.3,
    model="gpt-4o-mini",
    error_iteration=True,
    iteration_num=4,
    FewShot=False,
    with_knowledge=True,
    enable_coordinator=True,
):
    """
    å¯åŠ¨ QTRAN ä¸»æµç¨‹ï¼ˆè½¬æ¢é˜¶æ®µå…¥å£ï¼‰ã€‚

    å‚æ•°ï¼š
    - input_filename: è¾“å…¥æ–‡ä»¶ï¼ˆjsonlï¼‰ï¼ŒåŒ…å« SQL æˆ– bug æŠ¥å‘Šç­‰ã€‚
    - tool: æ¥æºå·¥å…·ï¼Œ"sqlancer" æˆ– "pinolo"ã€‚
    - temperature/model: LLM ç›¸å…³è®¾ç½®ã€‚
    - error_iteration/iteration_num: æ˜¯å¦è¿›è¡Œé”™è¯¯è¿­ä»£åŠæœ€å¤§è¿­ä»£æ¬¡æ•°ã€‚
    - FewShot/with_knowledge: æ˜¯å¦å¯ç”¨ Few-Shot ç¤ºä¾‹ä¸ç‰¹å¾çŸ¥è¯†åº“æç¤ºã€‚
    - enable_coordinator: ğŸ†• æ˜¯å¦å¯ç”¨åè°ƒå™¨æœºåˆ¶ã€‚

    è¡Œä¸ºï¼š
    - åˆå§‹åŒ–å¹¶åˆ›å»ºä¸åŒ fuzzer å’Œæ•°æ®åº“çš„å®¹å™¨/æ•°æ®åº“å®ä¾‹ã€‚
    - ğŸ†• å¦‚æœå¯ç”¨åè°ƒå™¨ï¼Œæ ¹æ®é»‘æ¿çŠ¶æ€åŠ¨æ€è°ƒæ•´å·¥ä½œæµå‚æ•°ã€‚
    - åˆ†å‘åˆ°å¯¹åº”çš„ç¿»è¯‘æµç¨‹ï¼šsqlancer_qtran_run æˆ– pinolo_qtran_runã€‚
    """
    if tool.lower() not in ["pinolo", "sqlancer"]:
        print(tool + " hasn't been supported.")
        return

    # è§£æè¾“å…¥æ–‡ä»¶è·¯å¾„ï¼šæ”¯æŒç»å¯¹è·¯å¾„ã€å·¥ä½œç›®å½•ç›¸å¯¹è·¯å¾„ï¼Œä»¥åŠé¡¹ç›®æ ¹ç›®å½•ç›¸å¯¹è·¯å¾„
    def _resolve_input_path(path_like: str) -> str:
        # 1) ç»å¯¹è·¯å¾„
        if os.path.isabs(path_like) and os.path.exists(path_like):
            return path_like
        # 2) å½“å‰å·¥ä½œç›®å½•
        cwd_path = os.path.abspath(os.path.join(os.getcwd(), path_like))
        if os.path.exists(cwd_path):
            return cwd_path
        # 3) é¡¹ç›®æ ¹ç›®å½•ï¼ˆsrc çš„ä¸Šä¸€çº§ï¼‰
        project_root = os.path.dirname(current_dir)
        root_path = os.path.abspath(os.path.join(project_root, path_like))
        if os.path.exists(root_path):
            return root_path
        raise FileNotFoundError(
            f"Input file not found. Tried: '{path_like}', '{cwd_path}', '{root_path}'."
        )

    resolved_input = _resolve_input_path(input_filename)

    # ğŸ†• åè°ƒå™¨åˆå§‹åŒ–
    coordinator = None
    if enable_coordinator and os.environ.get("QTRAN_USE_MEM0", "false").lower() == "true":
        print("\n" + "="*60)
        print("ğŸ§  åˆå§‹åŒ–åè°ƒå™¨ï¼ˆCoordinatorï¼‰")
        print("="*60)
        coordinator = SimpleCoordinator(user_id="qtran_redis_to_mongodb")
        if coordinator.initialize_memory_manager():
            # è½®è¯¢é»‘æ¿çŠ¶æ€
            print("ğŸ“¡ è½®è¯¢é»‘æ¿çŠ¶æ€...")
            state = coordinator.poll_state()
            
            # å†³ç­–ç­–ç•¥
            print("ğŸ¤” åˆ†æåé¦ˆå¹¶å†³ç­–ç­–ç•¥...")
            strategy = coordinator.decide_strategy(state)
            
            # å‡†å¤‡åŸºç¡€å‚æ•°
            base_params = {
                "temperature": temperature,
                "iteration_num": iteration_num,
                "model": model,
                "error_iteration": error_iteration,
                "FewShot": FewShot,
                "with_knowledge": with_knowledge,
            }
            
            # åº”ç”¨ç­–ç•¥è°ƒæ•´å‚æ•°
            print("âš™ï¸ åº”ç”¨ç­–ç•¥è°ƒæ•´...")
            adjusted_params = coordinator.adjust_workflow_params(base_params, strategy)
            
            # æ›´æ–°å®é™…ä½¿ç”¨çš„å‚æ•°
            temperature = adjusted_params["temperature"]
            iteration_num = adjusted_params["iteration_num"]
            model = adjusted_params["model"]
            error_iteration = adjusted_params["error_iteration"]
            FewShot = adjusted_params["FewShot"]
            with_knowledge = adjusted_params["with_knowledge"]
            
            print("âœ… åè°ƒå™¨åˆå§‹åŒ–å®Œæˆ\n")
        else:
            print("âš ï¸ åè°ƒå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°\n")
            coordinator = None
    elif enable_coordinator:
        print("â„¹ï¸ åè°ƒå™¨æœªå¯ç”¨ï¼šéœ€è¦è®¾ç½® QTRAN_USE_MEM0=true")
        coordinator = None

    # æ‰«æè¾“å…¥æ–‡ä»¶ï¼Œè·å–å®é™…éœ€è¦çš„æ•°æ®åº“
    required_dbs = scan_databases_from_input(resolved_input)

    # å¦‚æœæ‰«æåˆ°äº†æ•°æ®åº“ï¼Œåªåˆå§‹åŒ–è¿™äº›æ•°æ®åº“ï¼›å¦åˆ™ä½¿ç”¨é»˜è®¤åˆ—è¡¨
    if required_dbs:
        print(f"æ£€æµ‹åˆ°è¾“å…¥æ–‡ä»¶ä¸­ä½¿ç”¨çš„æ•°æ®åº“: {sorted(required_dbs)}")
        dbs = list(required_dbs)
    else:
        print("æœªæ£€æµ‹åˆ°ç‰¹å®šæ•°æ®åº“ï¼Œä½¿ç”¨é»˜è®¤æ•°æ®åº“åˆ—è¡¨")
        dbs = [
            "clickhouse",
            "duckdb",
            "mariadb",
            "monetdb",
            "mysql",
            "postgres",
            "sqlite",
            "tidb",
            "redis",
            "mongodb",
            "tdsql",
        ]

    fuzzers = ["norec", "tlp", "pinolo", "dqe"]

    # å¯é€‰ï¼šé€šè¿‡ç¯å¢ƒå˜é‡è·³è¿‡ Docker åˆå§‹åŒ–ï¼ˆå¿«é€Ÿæ ¡éªŒæ¨¡å¼ï¼‰
    if os.environ.get("QTRAN_SKIP_DOCKER", "0") != "1":
        print(f"å¼€å§‹åˆå§‹åŒ– {len(dbs)} ä¸ªæ•°æ®åº“...")
        for db in dbs:
            docker_create_databases(tool, "temp", db)
            for fuzzer in fuzzers:
                docker_create_databases(tool, fuzzer, db)
        print("æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
    else:
        print("è·³è¿‡ Docker åˆå§‹åŒ–ï¼ˆQTRAN_SKIP_DOCKER=1ï¼‰")

    if tool.lower() == "sqlancer":
        sqlancer_qtran_run(
            input_filepath=resolved_input,
            tool=tool,
            temperature=temperature,
            model=model,
            error_iteration=error_iteration,
            iteration_num=iteration_num,
            FewShot=FewShot,
            with_knowledge=with_knowledge,
        )
    elif tool.lower() == "pinolo":
        pinolo_qtran_run(
            input_filename=resolved_input,
            tool=tool,
            temperature=temperature,
            model=model,
            error_iteration=error_iteration,
            iteration_num=iteration_num,
            FewShot=FewShot,
            with_knowledge=with_knowledge,
        )
    
    # ğŸ†• è¾“å‡ºåè°ƒå™¨ç»Ÿè®¡æŠ¥å‘Š
    if coordinator:
        coordinator.report_stats()


def main():
    """
    å‘½ä»¤è¡Œå…¥å£ï¼šè§£æå‚æ•°å¹¶è°ƒç”¨ qtran_runã€‚
    ç¤ºä¾‹ï¼špython -m src.main --input_filename Input/demo.jsonl --tool sqlancer
    """
    parser = argparse.ArgumentParser(description="Run QTRAN for SQL translation.")
    parser.add_argument(
        "--input_filename",
        type=str,
        required=True,
        help="Path to the input file (JSONL format).",
    )
    parser.add_argument(
        "--tool",
        type=str,
        required=True,
        choices=["sqlancer", "pinolo"],
        help="Tool to use (sqlancer or pinolo).",
    )
    parser.add_argument(
        "--temperature", type=float, default=0.3, help="Temperature for LLM."
    )
    parser.add_argument(
        "--model", type=str, default="gpt-4o-mini", help="Model to use for LLM."
    )
    parser.add_argument(
        "--error_iteration", type=bool, default=True, help="Enable error iteration."
    )
    parser.add_argument(
        "--iteration_num", type=int, default=4, help="Number of iterations."
    )
    parser.add_argument(
        "--FewShot", type=bool, default=False, help="Enable Few-Shot learning."
    )
    parser.add_argument(
        "--with_knowledge",
        type=bool,
        default=True,
        help="Use knowledge-based processing.",
    )
    parser.add_argument(
        "--enable_coordinator",
        type=bool,
        default=True,
        help="ğŸ†• Enable coordinator mechanism for dynamic workflow adjustment.",
    )

    args = parser.parse_args()

    qtran_run(
        input_filename=args.input_filename,
        tool=args.tool,
        temperature=args.temperature,
        model=args.model,
        error_iteration=args.error_iteration,
        iteration_num=args.iteration_num,
        FewShot=args.FewShot,
        with_knowledge=args.with_knowledge,
        enable_coordinator=args.enable_coordinator,
    )


if __name__ == "__main__":
    main()
