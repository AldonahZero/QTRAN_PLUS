"""
模块：MonetDB 爬虫入口

说明：
- 该模块为 MonetDB 特征知识库构建的入口脚本，负责组织 HTML 列表抓取与信息抽取的流程。
- 职责：
  1) 为不同特征类型（datatype/function/operator）创建本地目录结构；
  2) 调用 HTMLs_Crawler 抓取目标文档页面列表并保存为 JSON；
  3) 调用 Info_Crawler 的爬取与分类函数，抽取函数/操作符/数据类型的描述、示例并按类别写入结果目录；
- 输入/输出：不接收外部参数，直接基于项目相对路径写入 FeatureKnowledgeBase/monetdb 下的文件与子目录。

实现注意：保持原有爬虫逻辑不变，仅在模块层面补充文档说明与用途说明，便于后续维护与关联 abstract.md。
"""

import os
import json
from src.FeatureKnowledgeBaseConstruction.MonetDB.HTMLs_Crawler import htmls_crawler
from src.FeatureKnowledgeBaseConstruction.MonetDB.Info_Crawler import crawler_results
from src.Tools.Crawler.crawler_options import category_classifier

current_file_path = os.path.abspath(__file__)
current_dir = os.path.dirname(current_file_path)


def monetdb_crawler():
    dic_path = os.path.join(current_dir, "..", "..", "..", "FeatureKnowledgeBase", "monetdb")
    feature_types = ["datatype", "function", "operator"]
    sub_dic = ["results", "results_category"]
    htmls_list = {
        "function": "https://www.monetdb.org/documentation-Aug2024/user-guide/sql-functions/",
        "operator": "https://www.monetdb.org/documentation-Aug2024/user-guide/sql-functions/",
        "datatype": "https://www.monetdb.org/documentation-Aug2024/user-guide/sql-manual/data-types/"
    }
    # htmls Crawler
    for feature in feature_types:
        # make dictionaries
        feature_dic = os.path.join(dic_path, feature)
        if not os.path.exists(feature_dic):
            os.makedirs(feature_dic)
        for sub in sub_dic:
            sub_dic_path = os.path.join(feature_dic, sub)
            if not os.path.exists(sub_dic_path):
                os.makedirs(sub_dic_path)
        # crawl the htmls list
        html_path = os.path.join(feature_dic, "HTMLs.json")
        if os.path.exists(html_path):
            print("File " + html_path + " exists！")
            continue
        htmls = htmls_crawler(htmls_list[feature])
        with open(html_path, 'w', encoding='utf-8') as f:
            json.dump(htmls, f, indent=4)


    # information Crawler and classification
    # functions and operators
    htmls_filename = os.path.join(dic_path, "function", "HTMLs.json")
    func_results_dic = os.path.join(dic_path, "function", "results")
    func_results_category_dic = os.path.join(dic_path, "function", "results_category")
    op_results_dic = os.path.join(dic_path, "operator", "results")
    op_results_category_dic = os.path.join(dic_path, "operator", "results_category")
    crawler_results("function", htmls_filename, func_results_dic, op_results_dic)
    category_classifier(func_results_dic, func_results_category_dic)
    category_classifier(op_results_dic, op_results_category_dic)

    # data types
    htmls_filename = os.path.join(dic_path, "datatype", "HTMLs.json")
    data_results_dic = os.path.join(dic_path, "datatype", "results")
    data_results_category_dic = os.path.join(dic_path, "datatype", "results_category")
    crawler_results("datatype", htmls_filename, data_results_dic, "")
