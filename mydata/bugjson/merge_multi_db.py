#!/usr/bin/env python3
"""
åˆå¹¶å¤šæ•°æ®åº“bugsåˆ°ä¸€ä¸ªæ–‡ä»¶

è‡ªåŠ¨æŸ¥æ‰¾æ‰€æœ‰ bugs_*_new.json å’Œ bugs_multi_source.json æ–‡ä»¶ï¼Œ
åˆå¹¶åˆ° bugs_new.json ä¸­ã€‚
"""

import json
import shutil
import glob
from pathlib import Path
from collections import Counter
from datetime import datetime


def find_new_bug_files():
    """æŸ¥æ‰¾æ‰€æœ‰æ–°çˆ¬å–çš„bugæ–‡ä»¶"""
    patterns = [
        "bugs_*_new.json",
        "bugs_multi_source.json"
    ]
    
    files = []
    for pattern in patterns:
        files.extend(glob.glob(pattern))
    
    return sorted(set(files))


def merge_bugs(
    main_file="bugs_new.json",
    new_files=None,
    backup=True
):
    """
    åˆå¹¶æ–°çˆ¬å–çš„bugæ–‡ä»¶åˆ°ä¸»æ–‡ä»¶
    
    Args:
        main_file: ä¸»æ–‡ä»¶ï¼ˆbugs_new.jsonï¼‰
        new_files: æ–°æ–‡ä»¶åˆ—è¡¨ï¼ˆå¦‚æžœä¸ºNoneï¼Œè‡ªåŠ¨æŸ¥æ‰¾ï¼‰
        backup: æ˜¯å¦å¤‡ä»½
    """
    
    print("=" * 70)
    print("ðŸ”„ åˆå¹¶æ–°çˆ¬å–çš„Bugæ•°æ®")
    print("=" * 70)
    
    # è‡ªåŠ¨æŸ¥æ‰¾æ–°æ–‡ä»¶
    if new_files is None:
        new_files = find_new_bug_files()
    
    if not new_files:
        print("âŒ æœªæ‰¾åˆ°æ–°çš„bugæ–‡ä»¶")
        print("ðŸ’¡ æç¤º: æŸ¥æ‰¾ä»¥ä¸‹æ–‡ä»¶:")
        print("   - bugs_*_new.json")
        print("   - bugs_multi_source.json")
        return
    
    print(f"\nðŸ“‚ æ‰¾åˆ° {len(new_files)} ä¸ªæ–°æ–‡ä»¶:")
    for f in new_files:
        size = Path(f).stat().st_size / 1024
        print(f"   âœ“ {f} ({size:.1f}KB)")
    
    # æ£€æŸ¥ä¸»æ–‡ä»¶
    main_path = Path(main_file)
    
    if not main_path.exists():
        print(f"\nâš ï¸  ä¸»æ–‡ä»¶ä¸å­˜åœ¨: {main_file}")
        print(f"ðŸ’¡ å°†åˆ›å»ºæ–°æ–‡ä»¶")
        main_bugs = []
    else:
        # å¤‡ä»½
        if backup:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_file = main_path.with_suffix(f'.json.backup_{timestamp}')
            shutil.copy2(main_path, backup_file)
            print(f"\nðŸ’¾ å¤‡ä»½ä¸»æ–‡ä»¶åˆ°: {backup_file}")
        
        # åŠ è½½ä¸»æ–‡ä»¶
        print(f"\nðŸ“– è¯»å–ä¸»æ–‡ä»¶...")
        with open(main_path, 'r', encoding='utf-8') as f:
            main_bugs = json.load(f)
        print(f"   âœ… {main_file}: {len(main_bugs)} ä¸ªbugs")
    
    
    # ç»Ÿè®¡åŽŸå§‹æ•°æ®
    if main_bugs:
        main_dbms = Counter(bug.get('database', bug.get('dbms', 'Unknown')) for bug in main_bugs)
        print(f"\nðŸ“Š ä¸»æ–‡ä»¶æ•°æ®åº“åˆ†å¸ƒ:")
        for dbms, count in main_dbms.most_common(10):
            print(f"    {dbms:15s} {count:4d} ä¸ª")
    
    # åŠ è½½å¹¶åˆå¹¶æ‰€æœ‰æ–°æ–‡ä»¶
    print(f"\nðŸ”„ åŠ è½½æ–°æ–‡ä»¶...")
    all_new_bugs = []
    
    for new_file in new_files:
        try:
            with open(new_file, 'r', encoding='utf-8') as f:
                new_bugs = json.load(f)
            print(f"   âœ… {new_file}: {len(new_bugs)} ä¸ªbugs")
            all_new_bugs.extend(new_bugs)
        except Exception as e:
            print(f"   âŒ {new_file}: è¯»å–å¤±è´¥ - {e}")
    
    print(f"\nðŸ“¦ æ–°æ•°æ®æ€»è®¡: {len(all_new_bugs)} ä¸ªbugs")
    
    if not all_new_bugs:
        print("âŒ æ²¡æœ‰æ–°æ•°æ®éœ€è¦åˆå¹¶")
        return
    
    # ç»Ÿè®¡æ–°æ•°æ®
    new_dbms = Counter(bug.get('database', bug.get('dbms', 'Unknown')) for bug in all_new_bugs)
    print(f"\nðŸ“Š æ–°æ•°æ®æ•°æ®åº“åˆ†å¸ƒ:")
    for dbms, count in new_dbms.most_common():
        print(f"    {dbms:15s} {count:4d} ä¸ª")
    
    # åŽ»é‡åˆå¹¶ï¼ˆä½¿ç”¨å¤šç§åŽ»é‡ç­–ç•¥ï¼‰
    print(f"\nðŸ”„ åˆå¹¶ä¸­...")
    
    # æž„å»ºå·²å­˜åœ¨çš„æ ‡è¯†é›†åˆ
    existing_ids = set()
    existing_urls = set()
    existing_combos = set()  # (database, date, testå‰50å­—ç¬¦)
    
    for bug in main_bugs:
        # IDåŽ»é‡
        bug_id = bug.get('id')
        if bug_id:
            existing_ids.add(bug_id)
        
        # URLåŽ»é‡
        url = bug.get('url') or bug.get('links', {}).get('bugreport', '')
        if url:
            existing_urls.add(url)
        
        # ç»„åˆåŽ»é‡
        db = bug.get('database', bug.get('dbms', ''))
        date = bug.get('date', '')
        test_val = bug.get('test', '')
        # testå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–åˆ—è¡¨
        if isinstance(test_val, list):
            test = ' '.join(test_val)[:50] if test_val else ''
        else:
            test = str(test_val)[:50] if test_val else ''
        if db and date and test:
            existing_combos.add((db, date, test))
    
    print(f"   å·²æœ‰IDæ•°: {len(existing_ids)}")
    print(f"   å·²æœ‰URLæ•°: {len(existing_urls)}")
    
    added = 0
    skipped = 0
    added_by_db = Counter()
    
    for bug in all_new_bugs:
        # æ£€æŸ¥æ˜¯å¦é‡å¤
        bug_id = bug.get('id')
        url = bug.get('url') or bug.get('links', {}).get('bugreport', '')
        db = bug.get('database', bug.get('dbms', ''))
        date = bug.get('date', '')
        test_val = bug.get('test', '')
        # testå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–åˆ—è¡¨
        if isinstance(test_val, list):
            test = ' '.join(test_val)[:50] if test_val else ''
        else:
            test = str(test_val)[:50] if test_val else ''
        combo = (db, date, test)
        
        is_duplicate = False
        if bug_id and bug_id in existing_ids:
            is_duplicate = True
        elif url and url in existing_urls:
            is_duplicate = True
        elif combo in existing_combos:
            is_duplicate = True
        
        if not is_duplicate:
            main_bugs.append(bug)
            if bug_id:
                existing_ids.add(bug_id)
            if url:
                existing_urls.add(url)
            if combo[0] and combo[1] and combo[2]:
                existing_combos.add(combo)
            added += 1
            added_by_db[db] += 1
        else:
            skipped += 1
    
    print(f"   âœ… æ–°å¢ž: {added} ä¸ª")
    print(f"   âš ï¸  è·³è¿‡: {skipped} ä¸ªï¼ˆé‡å¤ï¼‰")
    
    if added > 0:
        print(f"\nðŸ“ˆ æ–°å¢žæ•°æ®åº“åˆ†å¸ƒ:")
        for dbms, count in added_by_db.most_common():
            print(f"    {dbms:15s} +{count:4d} ä¸ª")
    
    # æŒ‰æ—¥æœŸæŽ’åº
    print(f"\nðŸ”€ æŽ’åº...")
    try:
        main_bugs.sort(key=lambda x: x.get('date', ''), reverse=False)
        print(f"   âœ… å·²æŒ‰æ—¥æœŸæŽ’åº")
    except Exception as e:
        print(f"   âš ï¸  æŽ’åºå¤±è´¥: {e}")
    
    # ä¿å­˜
    print(f"\nðŸ’¾ ä¿å­˜åˆ°: {main_file}")
    with open(main_path, 'w', encoding='utf-8') as f:
        json.dump(main_bugs, f, indent=4, ensure_ascii=False)
    
    # æœ€ç»ˆç»Ÿè®¡
    final_dbms = Counter(bug.get('database', bug.get('dbms', 'Unknown')) for bug in main_bugs)
    
    print("\n" + "=" * 70)
    print("ðŸ“Š åˆå¹¶åŽçš„æ•°æ®åº“åˆ†å¸ƒ")
    print("=" * 70)
    for dbms, count in final_dbms.most_common():
        percentage = count / len(main_bugs) * 100 if main_bugs else 0
        bar = "â–ˆ" * min(int(percentage / 2), 25)
        print(f"  {dbms:15s} {count:4d} ({percentage:5.1f}%) {bar}")
    print("=" * 70)
    print(f"  æ€»è®¡:        {len(main_bugs):4d} ä¸ªbugs")
    print("=" * 70)
    
    # æ£€æŸ¥ç”¨æˆ·æƒ³è¦çš„æ•°æ®åº“
    wanted_dbs = ['SQLite', 'DuckDB', 'MySQL', 'PostgreSQL', 'MonetDB', 'MariaDB']
    print("\nðŸŽ¯ ç”¨æˆ·éœ€è¦çš„æ•°æ®åº“:")
    print("=" * 70)
    all_present = True
    total_wanted = 0
    for db in wanted_dbs:
        count = final_dbms.get(db, 0)
        total_wanted += count
        if count > 0:
            print(f"  âœ… {db:15s} {count:4d} ä¸ª")
        else:
            print(f"  âŒ {db:15s} {count:4d} ä¸ªï¼ˆç¼ºå°‘ï¼‰")
            all_present = False
    print("=" * 70)
    print(f"  éœ€è¦çš„æ€»è®¡:  {total_wanted:4d} ä¸ªbugs")
    print("=" * 70)
    
    if all_present:
        print("\nðŸŽ‰ å¤ªå¥½äº†ï¼æ‰€æœ‰éœ€è¦çš„æ•°æ®åº“éƒ½æœ‰æ•°æ®ï¼")
    else:
        print("\nðŸ’¡ æç¤º: éƒ¨åˆ†æ•°æ®åº“ç¼ºå°‘æ•°æ®ï¼Œå¯ä»¥ç»§ç»­çˆ¬å–")
    
    print(f"\nâœ… åˆå¹¶å®Œæˆï¼")
    print(f"ðŸ’¾ ç»“æžœæ–‡ä»¶: {main_file}")
    print(f"ðŸ“Š æ€»bugæ•°: {len(main_bugs)}")
    print(f"ðŸ“ˆ æœ¬æ¬¡æ–°å¢ž: {added} ä¸ª")


if __name__ == "__main__":
    import sys
    
    # é»˜è®¤åˆå¹¶åˆ° bugs_new.json
    main_file = "bugs_new.json"
    
    # å¯ä»¥é€šè¿‡å‘½ä»¤è¡Œå‚æ•°æŒ‡å®šä¸»æ–‡ä»¶
    if len(sys.argv) > 1:
        main_file = sys.argv[1]
    
    merge_bugs(main_file=main_file)

