# æ•°æ®åº“Bugçˆ¬è™«

è‡ªåŠ¨çˆ¬å–å’Œæ›´æ–°æ•°æ®åº“bugä¿¡æ¯ï¼Œæ‰©å±• `bugs.json` æ•°æ®é›†ã€‚

## ğŸ“ æ–‡ä»¶è¯´æ˜

| æ–‡ä»¶ | è¯´æ˜ |
|------|------|
| `bugs.json` | ä¸»æ•°æ®æ–‡ä»¶ï¼ˆ8943ä¸ªbugï¼Œæˆªæ­¢2020/09/24ï¼‰ |
| `advanced_crawler.py` | ğŸŒŸ å¢å¼ºç‰ˆçˆ¬è™«ï¼ˆæ¨èä½¿ç”¨ï¼‰ |
| `bug_crawler.py` | åŸºç¡€ç‰ˆçˆ¬è™« |
| `crawler_config.py` | é…ç½®æ¨¡æ¿ |
| `crawler_config_local.py` | æœ¬åœ°é…ç½®ï¼ˆéœ€è‡ªè¡Œåˆ›å»ºï¼‰ |

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install requests
```

### 2. è¿è¡Œçˆ¬è™«

```bash
# åŸºç¡€æ¨¡å¼ï¼ˆæ— GitHub Tokenï¼Œ60è¯·æ±‚/å°æ—¶ï¼‰
python advanced_crawler.py

# é«˜çº§æ¨¡å¼ï¼ˆé…ç½®GitHub Tokenåï¼Œ5000è¯·æ±‚/å°æ—¶ï¼‰
# 1) åˆ›å»ºé…ç½®æ–‡ä»¶
cp crawler_config.py crawler_config_local.py

# 2) ç¼–è¾‘é…ç½®ï¼Œæ·»åŠ ä½ çš„GitHub Token
vim crawler_config_local.py

# 3) è¿è¡Œ
python advanced_crawler.py
```

### 3. æŸ¥çœ‹ç»“æœ

```bash
# æŸ¥çœ‹æ–°å¢çš„bug
tail -n 50 bugs.json

# ç»Ÿè®¡
python -c "import json; data=json.load(open('bugs.json')); print(f'æ€»bugæ•°: {len(data)}')"
```

---

## ğŸ”‘ è·å–GitHub Token

**ä¸ºä»€ä¹ˆéœ€è¦ï¼Ÿ**
- æ— Token: 60è¯·æ±‚/å°æ—¶
- æœ‰Token: 5000è¯·æ±‚/å°æ—¶

**è·å–æ­¥éª¤ï¼š**

1. è®¿é—® https://github.com/settings/tokens
2. ç‚¹å‡» "Generate new token" â†’ "Generate new token (classic)"
3. è®¾ç½®ï¼š
   - Note: `QTRAN Bug Crawler`
   - Expiration: `90 days`
   - Scopes: å‹¾é€‰ `public_repo`
4. ç‚¹å‡» "Generate token"
5. **å¤åˆ¶token** (åªæ˜¾ç¤ºä¸€æ¬¡ï¼)
6. ç²˜è´´åˆ° `crawler_config_local.py`:

```python
GITHUB_TOKEN = "ghp_xxxxxxxxxxxxxxxxxxxx"
```

---

## ğŸ“Š æ”¯æŒçš„æ•°æ®æº

### âœ… å·²å®ç°

| æ•°æ®åº“ | æ¥æº | è¯´æ˜ |
|--------|------|------|
| **DuckDB** | GitHub Issues | âœ… å®Œå…¨æ”¯æŒ |
| **ClickHouse** | GitHub Issues | âœ… å®Œå…¨æ”¯æŒ |
| **PostgreSQL** | GitHub é•œåƒ | âœ… éƒ¨åˆ†æ”¯æŒ |

### ğŸš§ è®¡åˆ’ä¸­

| æ•°æ®åº“ | æ¥æº | éš¾åº¦ |
|--------|------|------|
| SQLite | https://www.sqlite.org/src/timeline | ğŸ”´ éœ€è§£æHTML |
| MySQL | https://bugs.mysql.com/ | ğŸŸ¡ éœ€Bugzilla API |
| MongoDB | https://jira.mongodb.org/ | ğŸŸ¡ éœ€Jira API |
| MariaDB | https://jira.mariadb.org/ | ğŸŸ¡ éœ€Jira API |

---

## ğŸ“ˆ çˆ¬è™«ç‰¹æ€§

### advanced_crawler.py (æ¨è)

âœ… **åŠŸèƒ½å¼ºå¤§**
- æ”¯æŒGitHub Tokenè®¤è¯
- è‡ªåŠ¨å»é‡ï¼ˆæ£€æŸ¥å·²æœ‰é“¾æ¥ï¼‰
- è‡ªåŠ¨å¤‡ä»½åŸæ–‡ä»¶
- æ™ºèƒ½æå–SQLä»£ç 
- ç¡®å®šOracleç±»å‹ï¼ˆcrash/error/PQSï¼‰
- æ”¯æŒå¤šæ•°æ®æºå¹¶å‘çˆ¬å–

âœ… **æ™ºèƒ½è§£æ**
- ä»Markdownä»£ç å—æå–SQL
- ä»issue bodyæå–æµ‹è¯•ç”¨ä¾‹
- è‡ªåŠ¨åˆ¤æ–­bugçŠ¶æ€ï¼ˆopen/fixed/closedï¼‰
- æå–reporterå’Œæ—¥æœŸä¿¡æ¯

âœ… **å®‰å…¨å¯é **
- è‡ªåŠ¨é™æµå¤„ç†
- è¯·æ±‚å¤±è´¥é‡è¯•
- æ•°æ®å¤‡ä»½æœºåˆ¶
- è¯¦ç»†çš„æ—¥å¿—è¾“å‡º

---

## ğŸ¯ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1: çˆ¬å–DuckDBæœ€æ–°100ä¸ªbug

```python
from advanced_crawler import GitHubIssueCrawler

crawler = GitHubIssueCrawler(github_token="your_token")
crawler.crawl_repo(
    repo="duckdb/duckdb",
    dbms_name="DuckDB",
    max_issues=100,
    since_date="2020-09-25",
    labels=["bug"]
)
crawler.save_bugs()
```

### ç¤ºä¾‹2: åªçˆ¬å–crashç±»å‹çš„bug

ä¿®æ”¹ `advanced_crawler.py` ä¸­çš„å‚æ•°ï¼š

```python
labels=["bug", "crash"]
```

### ç¤ºä¾‹3: çˆ¬å–æ‰€æœ‰æœªå…³é—­çš„bug

```python
# åœ¨crawl_repoæ–¹æ³•ä¸­æ·»åŠ stateè¿‡æ»¤
params['state'] = 'open'
```

---

## ğŸ“‹ æ•°æ®æ ¼å¼

æ¯ä¸ªbugè®°å½•åŒ…å«ä»¥ä¸‹å­—æ®µï¼š

```json
{
    "date": "24/09/2020",
    "dbms": "DuckDB",
    "links": {
        "bugreport": "https://github.com/..."
    },
    "oracle": "crash",
    "reporter": "username",
    "status": "fixed",
    "title": "Buffer overflow in ...",
    "test": [
        "CREATE TABLE t0(...);",
        "INSERT INTO t0 VALUES(...);",
        "SELECT * FROM t0 WHERE ..."
    ],
    "comment": "Brief description...",
    "severity": "High"  // å¯é€‰
}
```

### Oracleç±»å‹è¯´æ˜

| Type | è¯´æ˜ | ç¤ºä¾‹å…³é”®è¯ |
|------|------|------------|
| `crash` | ç¨‹åºå´©æºƒ | segfault, assertion, panic |
| `error` | é”™è¯¯/å¼‚å¸¸ | error, exception, fails |
| `PQS` | ç»“æœé”™è¯¯ | wrong result, expected, actual |
| `unknown` | æœªçŸ¥ç±»å‹ | - |

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### APIé™æµ

**GitHub APIé™åˆ¶ï¼š**
- æœªè®¤è¯: 60è¯·æ±‚/å°æ—¶
- è®¤è¯: 5000è¯·æ±‚/å°æ—¶

**è§¦å‘é™æµæ—¶ï¼š**
```
â° APIé™æµï¼Œç­‰å¾… 3600ç§’...
```

**è§£å†³æ–¹æ¡ˆï¼š**
1. ç­‰å¾…1å°æ—¶
2. ä½¿ç”¨GitHub Token
3. åˆ†æ‰¹æ¬¡è¿è¡Œ

### æ•°æ®è´¨é‡

**è‡ªåŠ¨è¿‡æ»¤ï¼š**
- âœ… è·³è¿‡Pull Request
- âœ… è·³è¿‡æ— bugæ ‡ç­¾çš„issue
- âœ… å»é‡å·²å­˜åœ¨çš„bug

**éœ€è¦æ‰‹åŠ¨æ£€æŸ¥ï¼š**
- âš ï¸ SQLæå–å¯èƒ½ä¸å®Œæ•´
- âš ï¸ Oracleç±»å‹å¯èƒ½åˆ¤æ–­ä¸å‡†
- âš ï¸ éƒ¨åˆ†issueå¯èƒ½æ˜¯åŠŸèƒ½è¯·æ±‚è€Œébug

---

## ğŸ“Š ç»Ÿè®¡ä¿¡æ¯

### å½“å‰æ•°æ®é›† (bugs.json)

```
æ€»bugæ•°: 8943
æ¥æºåˆ†å¸ƒ:
  - SQLite: ~8000+
  - DuckDB: ~100
  - å…¶ä»–: ~800
  
æ—¶é—´èŒƒå›´: 2019-2020
ä¸»è¦Reporter: Manuel Rigger
```

### çˆ¬å–åé¢„æœŸ

```
é¢„è®¡æ–°å¢: 500-1000ä¸ªbug
æ–°æ•°æ®åº“: ClickHouse, PostgreSQL
æ—¶é—´èŒƒå›´: 2020-2025
```

---

## ğŸ”§ æ•…éšœæ’æŸ¥

### é—®é¢˜1: ModuleNotFoundError: No module named 'requests'

```bash
pip install requests
```

### é—®é¢˜2: GitHub API 403 Forbidden

**åŸå› **: è¶…è¿‡APIé™é¢

**è§£å†³**:
1. ç­‰å¾…é™æµé‡ç½®ï¼ˆæ¯å°æ—¶é‡ç½®ï¼‰
2. æ·»åŠ GitHub Token

### é—®é¢˜3: çˆ¬å–åˆ°çš„bugæ•°é‡ä¸º0

**å¯èƒ½åŸå› **:
1. `since_date` è®¾ç½®è¿‡æ™š
2. æ ‡ç­¾è¿‡æ»¤å¤ªä¸¥æ ¼
3. æ‰€æœ‰bugéƒ½å·²å­˜åœ¨

**è§£å†³**:
```python
# è°ƒæ•´since_date
since_date="2020-01-01"  # æ›´æ—©çš„æ—¥æœŸ

# æ”¾å®½æ ‡ç­¾è¿‡æ»¤
labels=[]  # ä¸è¿‡æ»¤æ ‡ç­¾
```

### é—®é¢˜4: æ— æ³•è§£ææŸäº›issue

**æ­£å¸¸ç°è±¡**: ä¸æ˜¯æ‰€æœ‰issueéƒ½åŒ…å«SQLä»£ç 

**æ”¹è¿›**: æ‰‹åŠ¨æ·»åŠ ç‰¹æ®Šæ ¼å¼çš„bug

---

## ğŸ¯ æœ€ä½³å®è·µ

### 1. å¢é‡çˆ¬å–

```python
# è®¾ç½®since_dateä¸ºbugs.jsonä¸­æœ€æ–°çš„æ—¥æœŸ
since_date="2020-09-25"  # ä¸Šæ¬¡çˆ¬å–çš„æ—¥æœŸ
```

### 2. åˆ†æ‰¹è¿è¡Œ

```python
# æ¯æ¬¡çˆ¬å–100ä¸ªï¼Œé¿å…è¶…æ—¶
max_issues=100
```

### 3. å®šæœŸå¤‡ä»½

```python
# çˆ¬è™«ä¼šè‡ªåŠ¨å¤‡ä»½
# æ‰‹åŠ¨å¤‡ä»½ï¼š
cp bugs.json bugs.json.backup.$(date +%Y%m%d)
```

### 4. è´¨é‡æ£€æŸ¥

```bash
# æ£€æŸ¥æœ€å10ä¸ªbug
python -c "import json; bugs=json.load(open('bugs.json')); \
    for b in bugs[-10:]: print(f'{b[\"date\"]} - {b[\"dbms\"]} - {b[\"title\"]}')"
```

---

## ğŸ“ è´¡çŒ®æŒ‡å—

æ¬¢è¿æ·»åŠ æ–°çš„æ•°æ®æºï¼

### æ·»åŠ æ–°æ•°æ®åº“æ­¥éª¤ï¼š

1. åœ¨ `advanced_crawler.py` ä¸­æ·»åŠ çˆ¬å–é€»è¾‘
2. å®ç° `parse_xxx_issue` æ–¹æ³•
3. æµ‹è¯•å¹¶éªŒè¯æ•°æ®æ ¼å¼
4. æ›´æ–°æœ¬README

### ä»£ç è§„èŒƒï¼š

- éµå¾ªPEP 8
- æ·»åŠ ç±»å‹æ³¨è§£
- ç¼–å†™è¯¦ç»†çš„docstring
- å¤„ç†å¼‚å¸¸æƒ…å†µ

---

## ğŸ“ è”ç³»æ–¹å¼

- Issues: åœ¨GitHubä»“åº“æissue
- Email: é¡¹ç›®ç»´æŠ¤è€…é‚®ç®±

---

## ğŸ“œ è®¸å¯è¯

MIT License

---

**æœ€åæ›´æ–°**: 2025-10-31
**ç»´æŠ¤è€…**: QTRAN Team

