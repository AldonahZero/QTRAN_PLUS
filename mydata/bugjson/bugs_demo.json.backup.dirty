[
    {
        "date": "31/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/89282"
        },
        "oracle": "crash",
        "reporter": "ShoshinNikita",
        "status": "open",
        "title": "Call to `estimateCompressionRatio('DoubleDelta, T64, ZSTD')(...)` leads to a crash",
        "test": [
            "CREATE TABLE compression_estimate_example (",
            "number UInt64",
            ")",
            "ENGINE = MergeTree()",
            "ORDER BY number;",
            "CREATE TABLE compression_estimate_example (",
            "INSERT INTO compression_estimate_example",
            "SELECT number FROM system.numbers LIMIT 100_000;",
            "SELECT estimateCompressionRatio('DoubleDelta, T64, ZSTD')(number) AS estimate FROM compression_estimate_example;"
        ],
        "comment": "### Company or project name"
    },
    {
        "date": "29/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/89200"
        },
        "oracle": "error",
        "reporter": "vitlibar",
        "status": "open",
        "title": "Logical error: 'function_node_type->equals(*removeLowCardinality(node->getResultType()))'"
    },
    {
        "date": "29/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/89178"
        },
        "oracle": "PQS",
        "reporter": "alsugiliazova",
        "status": "open",
        "title": "ORDER BY is ignored in iceberg table on head",
        "test": [
            "SHOW CREATE TABLE `column_rbac_namespace_ebaed36e_b4cc_11f0_af75_e0c26496f172.table_ebaed39f_b4cc_11f0_919a_e0c26496f172`",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩",
            "1. │ CREATE TABLE column_rbac_database_ebaed3bc_b4cc_11f0_8fac_e0c26496f172.`column_rbac_namespace_ebaed36e_b4cc_11f0_af75_e0c26496f172.table_ebaed39f_b4cc_11f0_919a_e0c26496f172`↴│",
            "│↳(                                                                                                                                                                             ↴│",
            "│↳    `boolean_col` Nullable(Bool),                                                                                                                                             ↴│",
            "SELECT *",
            "FROM `column_rbac_namespace_ebaed36e_b4cc_11f0_af75_e0c26496f172.table_ebaed39f_b4cc_11f0_919a_e0c26496f172`",
            "SELECT string_col",
            "FROM `column_rbac_namespace_ebaed36e_b4cc_11f0_af75_e0c26496f172.table_ebaed39f_b4cc_11f0_919a_e0c26496f172`",
            "ORDER BY string_col ASC"
        ],
        "comment": "### Company or project name"
    },
    {
        "date": "29/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/89166"
        },
        "oracle": "error",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "Logical Error: Left and right columns have same names"
    },
    {
        "date": "29/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/89137"
        },
        "oracle": "error",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "Logical error: 'This function cannot be used to construct empty tuple. It is a bug'"
    },
    {
        "date": "28/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/89097"
        },
        "oracle": "unknown",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "Wrong PREWHERE with LEFT JOIN query result"
    },
    {
        "date": "27/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/89075"
        },
        "oracle": "unknown",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "Another bad backup",
        "test": [
            "CREATE TABLE t0 (c1 Map(Int,Int), c2 Int) ENGINE = MergeTree() ORDER BY tuple() PARTITION BY (c1, c2 % 6084);",
            "INSERT INTO TABLE t0 (c1, c2) SELECT map(), 2 FROM numbers(100);",
            "SET min_insert_block_size_rows = 64, optimize_trivial_insert_select = 1;",
            "INSERT INTO TABLE t0 (c1, c2) SELECT c1, c2 FROM generateRandom('c1 Map(Int,Int), c2 Int', 2607967781039168224, 1, 1) LIMIT 400;",
            "BACKUP TABLE t0 TO Disk('default', 'b0.tar');",
            "CREATE TABLE t0 (c1 Map(Int,Int), c2 Int) ENGINE = MergeTree() ORDER BY tuple() PARTITION BY (c1, c2 % 6084);",
            "INSERT INTO TABLE t0 (c1, c2) SELECT map(), 2 FROM numbers(100);",
            "INSERT INTO TABLE t0 (c1, c2) SELECT c1, c2 FROM generateRandom('c1 Map(Int,Int), c2 Int', 2607967781039168224, 1, 1) LIMIT 400;"
        ]
    },
    {
        "date": "27/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/89066"
        },
        "oracle": "error",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "Logical Error: Input nodes size mismatch in dag"
    },
    {
        "date": "27/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/89062"
        },
        "oracle": "crash",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "Logical error: '(isConst() || isSparse()) ? getDataType() == rhs.getDataType() : typeid(*this) == typeid(rhs)' with runtime filters"
    },
    {
        "date": "27/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/89037"
        },
        "oracle": "unknown",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "Iceberg Invalid access: Can not convert empty value",
        "test": [
            "CREATE TABLE t0 ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/t0/test/t0');",
            "OPTIMIZE TABLE t0;",
            "With [spark.py](https://github.com/user-attachments/files/23163459/spark.py) run `spark.py create`. Then in ClickHouse create the table with:",
            "CREATE TABLE t0 ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/t0/test/t0');"
        ]
    },
    {
        "date": "23/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88924"
        },
        "oracle": "error",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "Logical error: Block structure mismatch in Expression for FilterSortedStreamByRange"
    },
    {
        "date": "22/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88913"
        },
        "oracle": "PQS",
        "reporter": "swvooda",
        "status": "closed",
        "title": "reverseUTF8() reverses bytes instead of UTF-8 code points causing corruption",
        "comment": "### Describe what's wrong"
    },
    {
        "date": "22/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88900"
        },
        "oracle": "crash",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "Don't set temporary_files_buffer_size to 0 (SEGV)",
        "test": [
            "CREATE TABLE t0 (c0 Int) ENGINE = Memory();",
            "INSERT INTO TABLE t0 (c0) VALUES (1);",
            "SELECT c0 FROM t0 GROUP BY c0 SETTINGS max_bytes_before_external_group_by = 1, temporary_files_buffer_size = 0, group_by_two_level_threshold = 1;",
            "CREATE TABLE t0 (c0 Int) ENGINE = Memory();",
            "INSERT INTO TABLE t0 (c0) VALUES (1);",
            "SELECT c0 FROM t0 GROUP BY c0 SETTINGS max_bytes_before_external_group_by = 1, temporary_files_buffer_size = 0, group_by_two_level_threshold = 1;"
        ]
    },
    {
        "date": "20/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88819"
        },
        "oracle": "crash",
        "reporter": "alsugiliazova",
        "status": "closed",
        "title": "Crash on SHOW TABLES FROM DataLakeCatalog database if catalog_type is not specified ",
        "test": [
            "CREATE DATABASE datalake",
            "ENGINE = DataLakeCatalog('http://ice-rest-catalog:5000', admin, password)",
            "SETTINGS storage_endpoint = 'http://minio:9000/warehouse', warehouse = 'd'",
            "SHOW TABLES FROM datalake"
        ],
        "comment": "### Company or project name"
    },
    {
        "date": "17/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88756"
        },
        "oracle": "error",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "Logical error: '!table_alias.empty()'",
        "test": [
            "CREATE VIEW v0 AS (SELECT EXISTS (SELECT 1) c0);",
            "SELECT c0 FROM remote('localhost', 'default', 'v0') tx SETTINGS prefer_localhost_replica = 0;",
            "CREATE VIEW v0 AS (SELECT EXISTS (SELECT 1) c0);",
            "SELECT c0 FROM remote('localhost', 'default', 'v0') tx SETTINGS prefer_localhost_replica = 0;"
        ]
    },
    {
        "date": "17/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88722"
        },
        "oracle": "unknown",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "Regression on EXISTS operator with LIMIT and OFFSET"
    },
    {
        "date": "16/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88637"
        },
        "oracle": "error",
        "reporter": "PedroTadim",
        "status": "closed",
        "title": "Logical error: 'Bad cast from type DB::ColumnSparse to DB::ColumnVector<char8_t>'",
        "test": [
            "CREATE OR REPLACE TABLE t0 (c0 Bool) ENGINE = MergeTree() ORDER BY tuple();",
            "INSERT INTO TABLE t0 (c0) VALUES (FALSE);",
            "ALTER TABLE t0 ADD CONSTRAINT c0 CHECK c0;",
            "INSERT INTO TABLE FUNCTION url('http://localhost:8123/?query=INSERT+INTO+t0+(c0)+FORMAT+CSV', 'CSV', 'c0 Bool') VALUES (FALSE);",
            "CREATE OR REPLACE TABLE t0 (c0 Bool) ENGINE = MergeTree() ORDER BY tuple();",
            "INSERT INTO TABLE t0 (c0) VALUES (FALSE);",
            "ALTER TABLE t0 ADD CONSTRAINT c0 CHECK c0;",
            "INSERT INTO TABLE FUNCTION url('http://localhost:8123/?query=INSERT+INTO+t0+(c0)+FORMAT+CSV', 'CSV', 'c0 Bool') VALUES (FALSE);"
        ]
    },
    {
        "date": "16/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88635"
        },
        "oracle": "unknown",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "NOT_FOUND_COLUMN_IN_BLOCK with query_plan_use_new_logical_join_step"
    },
    {
        "date": "16/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88633"
        },
        "oracle": "error",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "Logical error: 'Written 1 elements of column c0, but 0 rows of PK columns'",
        "test": [
            "CREATE TABLE t0 (c0 String) ENGINE = ReplacingMergeTree() PRIMARY KEY tuple() SETTINGS min_bytes_for_wide_part = 0, vertical_merge_algorithm_min_bytes_to_activate = 1, vertical_merge_algorithm_min_rows_to_activate = 0, index_granularity = 1, vertical_merge_algorithm_min_columns_to_activate = 1;",
            "INSERT INTO TABLE t0 (c0) SELECT c0 FROM generateRandom('c0 String', 11534244747785854120, 6119, 2) LIMIT 679;",
            "INSERT INTO TABLE t0 (c0) SELECT 'need' FROM numbers(522);",
            "INSERT INTO TABLE t0 (c0) SELECT c0 FROM generateRandom('c0 String', 17010632438609867543, 501, 10) LIMIT 972;",
            "INSERT INTO TABLE t0 (c0) SELECT '.' FROM numbers(878);",
            "CREATE TABLE t0 (c0 String) ENGINE = ReplacingMergeTree() PRIMARY KEY tuple() SETTINGS min_bytes_for_wide_part = 0, vertical_merge_algorithm_min_bytes_to_activate = 1, vertical_merge_algorithm_min_rows_to_activate = 0, index_granularity = 1, vertical_merge_algorithm_min_columns_to_activate = 1;",
            "INSERT INTO TABLE t0 (c0) SELECT c0 FROM generateRandom('c0 String', 11534244747785854120, 6119, 2) LIMIT 679;",
            "INSERT INTO TABLE t0 (c0) SELECT 'need' FROM numbers(522);",
            "INSERT INTO TABLE t0 (c0) SELECT c0 FROM generateRandom('c0 String', 17010632438609867543, 501, 10) LIMIT 972;",
            "INSERT INTO TABLE t0 (c0) SELECT '.' FROM numbers(878);"
        ]
    },
    {
        "date": "15/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88587"
        },
        "oracle": "crash",
        "reporter": "DColadas",
        "status": "open",
        "title": "SEGV during MV refresh when queried table gets `CREATE OR REPLACE`d",
        "test": [
            "CREATE TABLE t ORDER BY a AS SELECT 1 AS a;",
            "CREATE MATERIALIZED VIEW mv REFRESH EVERY 1 YEAR ENGINE = MergeTree ORDER BY b AS SELECT sleep(3) AS b FROM t;",
            "CREATE TABLE t ORDER BY a AS SELECT 1 AS a;",
            "CREATE MATERIALIZED VIEW mv REFRESH EVERY 1 YEAR ENGINE = MergeTree ORDER BY b AS SELECT sleep(3) AS b FROM t;"
        ],
        "comment": "### Describe what's wrong"
    },
    {
        "date": "15/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88569"
        },
        "oracle": "crash",
        "reporter": "PedroTadim",
        "status": "closed",
        "title": "rewrite_in_to_join SEGV"
    },
    {
        "date": "14/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88536"
        },
        "oracle": "PQS",
        "reporter": "DColadas",
        "status": "open",
        "title": "`NOT field` incorrectly filters when `field` is an expression in a view over a PK field",
        "test": [
            "CREATE TABLE t (val UInt8) ORDER BY (val);",
            "CREATE VIEW v AS SELECT val, val = 0 AS is_zero FROM t;",
            "INSERT INTO t VALUES (0);  -- does not get pruned, but does not pass the \"NOT is_zero\" filter",
            "INSERT INTO t VALUES (1);  -- gets pruned",
            "INSERT INTO t VALUES (0), (2);  -- does not get pruned (as 0 exists in this part), and 2 passes the \"NOT is_zero\" filter: will return 2",
            "CREATE TABLE t (val UInt8) ORDER BY (val);",
            "CREATE VIEW v AS SELECT val, val = 0 AS is_zero FROM t;",
            "INSERT INTO t VALUES (0);  -- does not get pruned, but does not pass the \"NOT is_zero\" filter",
            "INSERT INTO t VALUES (1);  -- gets pruned",
            "INSERT INTO t VALUES (0), (2);  -- does not get pruned (as 0 exists in this part), and 2 passes the \"NOT is_zero\" filter: will return 2"
        ],
        "comment": "### Describe what's wrong"
    },
    {
        "date": "14/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88512"
        },
        "oracle": "error",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "Logical error: 'Intersecting mark ranges are not allowed, it is a bug! First range (0, 11), second range (0, 256)'",
        "test": [
            "CREATE TABLE t0 (c0 Int) ENGINE = MergeTree() ORDER BY (c0 DESC) SETTINGS index_granularity = 1, allow_experimental_reverse_key = 1;",
            "INSERT INTO TABLE t0 (c0) SELECT c0 FROM generateRandom('c0 Int', 7285072819366316109, 1, 1) LIMIT 10;",
            "SELECT 1 FROM t0 JOIN t0 tx USING (c0) SETTINGS query_plan_join_shard_by_pk_ranges = 1;",
            "CREATE TABLE t0 (c0 Int) ENGINE = MergeTree() ORDER BY (c0 DESC) SETTINGS index_granularity = 1, allow_experimental_reverse_key = 1;",
            "INSERT INTO TABLE t0 (c0) SELECT c0 FROM generateRandom('c0 Int', 7285072819366316109, 1, 1) LIMIT 10;",
            "SELECT 1 FROM t0 JOIN t0 tx USING (c0) SETTINGS query_plan_join_shard_by_pk_ranges = 1;"
        ]
    },
    {
        "date": "14/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88499"
        },
        "oracle": "error",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "Logical error: 'row_subgroup.stage == ReadStage::Deliver'.",
        "test": [
            "CREATE OR REPLACE TABLE t0 (c0 UInt64) ENGINE = IcebergS3(s3, filename = 't11', format = 'Parquet') PARTITION BY tuple();",
            "DETACH TABLE t0 PERMANENTLY;",
            "SET input_format_parquet_use_native_reader_v3 = 1, output_format_parquet_row_group_size = 0;",
            "ATTACH TABLE t0;",
            "SET query_plan_enable_optimizations = 0;",
            "CREATE OR REPLACE TABLE t0 (c0 UInt64) ENGINE = IcebergS3(s3, filename = 't11', format = 'Parquet') PARTITION BY tuple();",
            "INSERT INTO TABLE t0 (c0) SELECT CAST(number AS UInt64) FROM numbers(924);",
            "INSERT INTO TABLE t0 (c0) SELECT c0 FROM generateRandom('c0 UInt64', 5445531875995920648, 701, 7) LIMIT 780;",
            "ALTER TABLE t0 (DELETE WHERE c0); --may trigger the logical error"
        ]
    },
    {
        "date": "14/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88496"
        },
        "oracle": "unknown",
        "reporter": "zlareb1",
        "status": "open",
        "title": "LIMIT not pushed down when inject_random_order_for_select_without_order_by = 1",
        "test": [
            "SET inject_random_order_for_select_without_order_by = 0;",
            "functional-tests :) EXPLAIN PLAN SELECT number",
            "FROM system.numbers",
            "LIMIT 1;",
            "┌─explain─────────────────────────────────────────────────────────────────────────────────┐",
            "SET inject_random_order_for_select_without_order_by = 1;",
            "functional-tests :) EXPLAIN PLAN SELECT number",
            "FROM system.numbers",
            "LIMIT 1;",
            "1. │ Expression (Project names)                                                                      │"
        ],
        "comment": "### Describe what's wrong"
    },
    {
        "date": "14/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88489"
        },
        "oracle": "error",
        "reporter": "bingfengfeifei",
        "status": "open",
        "title": "Critical Executor Bug in LTS v25.8.7 (ReplacingMergeTree): Query Fails with ORDER BY + small LIMIT, but Succeeds with larger LIMIT or no ORDER BY",
        "test": [
            "SELECT * FROM default.database_sample WHERE domain = '172.16.96.212:5432' ORDER BY timestamp DESC LIMIT 20;",
            "SELECT * FROM default.database_sample WHERE domain = '172.16.96.212:5432' LIMIT 10;",
            "SELECT * FROM default.database_sample WHERE domain = '172.16.96.212:5432' ORDER BY timestamp DESC LIMIT 10;",
            "SELECT * FROM default.database_sample WHERE domain = '172.16.96.212:5432' ORDER BY timestamp DESC LIMIT 20;",
            "SELECT * FROM default.database_sample WHERE domain = '172.16.96.212:5432' LIMIT 10;",
            "SELECT * FROM default.database_sample WHERE domain = '172.16.96.212:5432' ORDER BY timestamp DESC LIMIT 10;"
        ],
        "comment": "### Company or project name"
    },
    {
        "date": "13/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88469"
        },
        "oracle": "PQS",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "Empty tuples don't work with CoalescingMergeTree"
    },
    {
        "date": "13/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88444"
        },
        "oracle": "unknown",
        "reporter": "PedroTadim",
        "status": "closed",
        "title": "Iceberg wrong total number of rows after two deletes",
        "test": [
            "CREATE TABLE t0 (c0 Int) ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/t0') SETTINGS iceberg_format_version = 1;",
            "INSERT INTO TABLE t0 (c0) VALUES (1);",
            "DELETE FROM t0 WHERE TRUE;",
            "DELETE FROM t0 WHERE TRUE;",
            "SELECT total_rows FROM system.tables WHERE database = 'default' AND table = 't0';",
            "CREATE TABLE t0 (c0 Int) ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/t0') SETTINGS iceberg_format_version = 1;",
            "INSERT INTO TABLE t0 (c0) VALUES (1);",
            "DELETE FROM t0 WHERE TRUE;",
            "DELETE FROM t0 WHERE TRUE;",
            "SELECT total_rows FROM system.tables WHERE database = 'default' AND table = 't0';"
        ]
    },
    {
        "date": "13/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88443"
        },
        "oracle": "crash",
        "reporter": "PedroTadim",
        "status": "closed",
        "title": "Confusing SEGV after restart",
        "test": [
            "CREATE TABLE t0 (c0 Int PRIMARY KEY) ENGINE = EmbeddedRocksDB();",
            "ALTER TABLE t0 MODIFY SETTING output_format_write_statistics = 0, zstd_window_log_max = 18446744073709551516;",
            "SYSTEM SHUTDOWN;",
            "/*",
            "Cannot load data for command line suggestions: Code: 722. DB::Exception: Received from localhost:9000. DB::Exception: Waited job failed: Code: 696. DB::Exception: Load job 'startup table default.t0' -> Code: 695.",
            "DB::Exception: Load job 'load table default.t0' failed: Code: 70.",
            "DB::Exception: Field value 18446744073709551516 is out of range of long type:",
            "Cannot attach table `default`.`t0` from metadata file store/a5f/a5f069db-e7dd-4da7-8449-e38984c34f9b/t0.sql from query ATTACH TABLE default.t0 UUID '80f3eab6-7e3c-42be-9ac1-21ad2042481e' (`c0` Int32)",
            "SYSTEM RELOAD CONFIG; --SEGV",
            "CREATE TABLE t0 (c0 Int PRIMARY KEY) ENGINE = EmbeddedRocksDB();"
        ]
    },
    {
        "date": "13/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88426"
        },
        "oracle": "unknown",
        "reporter": "azat",
        "status": "closed",
        "title": "Block structure mismatch in function connect between RemovingSparseTransform and MergeTreeSink stream: different types (Alias storage)",
        "test": [
            "CREATE TABLE source_table (`id` UInt32, `value` String) ENGINE = MergeTree ORDER BY id;",
            "CREATE TABLE alias_4__fuzz_45 (`id` Array(Int8), `value` Array(Array(UInt256)), `status` UInt32) ENGINE = Alias('source_table');",
            "INSERT INTO alias_4__fuzz_45 FORMAT Values (1, []);"
        ],
        "comment": "CI: https://s3.amazonaws.com/clickhouse-test-reports/json.html?PR=88381&sha=latest&name_0=PR&name_1=AST+fuzzer+%28amd_tsan%29"
    },
    {
        "date": "10/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88362"
        },
        "oracle": "error",
        "reporter": "nickitat",
        "status": "closed",
        "title": "Logical error: 'FUNCTION query tree node does not have valid source node after running L2DistanceTransposedPartialReadsPass'"
    },
    {
        "date": "10/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88349"
        },
        "oracle": "unknown",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "Bad cast from Time to Time64"
    },
    {
        "date": "10/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88343"
        },
        "oracle": "unknown",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "std::out_of_range with IN empty tuple"
    },
    {
        "date": "09/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88294"
        },
        "oracle": "error",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "Iceberg catalog bad error message on CREATE TABLE",
        "test": [
            "CREATE TABLE d0.`test.t41` ENGINE = IcebergS3(s3, url = 'http://minio:9000/warehouse-rest/t41', format = 'ORC') PARTITION BY (farmHash64(`c0`)) SETTINGS storage_catalog_type = 'rest', storage_warehouse = 'd0', object_storage_endpoint = 'http://minio:9000/warehouse-rest', storage_catalog_url = 'http://rest:8181/v1';",
            "CREATE TABLE d0.`test.t41` ENGINE = IcebergS3(s3, url = 'http://minio:9000/warehouse-rest/t41', format = 'ORC') PARTITION BY (farmHash64(`c0`)) SETTINGS storage_catalog_type = 'rest', storage_warehouse = 'd0', object_storage_endpoint = 'http://minio:9000/warehouse-rest', storage_catalog_url = 'http://rest:8181/v1';"
        ]
    },
    {
        "date": "09/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88287"
        },
        "oracle": "PQS",
        "reporter": "PavelkoSemen",
        "status": "open",
        "title": "icebergS3Cluster adds deleted rows",
        "test": [
            "create table test.test.test_ch_cluster(",
            "dataflow_dttm timestamp,",
            "id integer",
            ");",
            "insert into test.test.test_ch_cluster values",
            "SELECT * FROM icebergS3Cluster(standard_cluster,  NAMED_COLLECTION , url='https://s3a', filename ='table')",
            "SELECT * FROM icebergS3(NAMED_COLLECTION , url='https://s3a', filename ='table')",
            "create table test.test.test_ch_cluster(",
            "insert into test.test.test_ch_cluster values",
            "update test.test.test_ch_cluster set dataflow_dttm = current_timestamp;"
        ],
        "comment": "### Company or project name"
    },
    {
        "date": "09/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88280"
        },
        "oracle": "crash",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "Iceberg std::length_error on DROP COLUMN",
        "test": [
            "CREATE TABLE t0 ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/t0/test/t0', format = 'Parquet') SETTINGS iceberg_use_version_hint = 1;",
            "ALTER TABLE t0 DROP COLUMN c1; --std::length_error",
            "CREATE TABLE t0 ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/t0/test/t0', format = 'Parquet') SETTINGS iceberg_use_version_hint = 1;",
            "ALTER TABLE t0 DROP COLUMN c1; --std::length_error"
        ]
    },
    {
        "date": "08/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88238"
        },
        "oracle": "crash",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "Iceberg out-of-bounds access on Avro file",
        "test": [
            "CREATE TABLE t0 (c0 Int) ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/t0');",
            "INSERT INTO TABLE FUNCTION icebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/t0', format = 'Avro', structure = 'c0 Int') (c0) VALUES (1);",
            "SELECT 1 FROM icebergLocal(local, structure = 'c0 Int', path = '/var/lib/clickhouse/user_files/lakehouses/t0') tx JOIN icebergLocal(local, structure = 'c0 Int', format = 'Avro', path = '/var/lib/clickhouse/user_files/lakehouses/t0') ty ON TRUE WHERE tx._row_number SETTINGS input_format_parquet_use_native_reader_v3 = 1, optimize_count_from_files = 0;",
            "CREATE TABLE t0 (c0 Int) ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/t0');",
            "INSERT INTO TABLE FUNCTION icebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/t0', format = 'Avro', structure = 'c0 Int') (c0) VALUES (1);",
            "SELECT 1 FROM icebergLocal(local, structure = 'c0 Int', path = '/var/lib/clickhouse/user_files/lakehouses/t0') tx JOIN icebergLocal(local, structure = 'c0 Int', format = 'Avro', path = '/var/lib/clickhouse/user_files/lakehouses/t0') ty ON TRUE WHERE tx._row_number SETTINGS input_format_parquet_use_native_reader_v3 = 1, optimize_count_from_files = 0;"
        ]
    },
    {
        "date": "08/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88218"
        },
        "oracle": "PQS",
        "reporter": "azat",
        "status": "open",
        "title": "Unexpected return type from replaceRegexpOne. Expected Nullable(String). Got Const(String)",
        "test": [
            "SELECT replaceRegexpOne(identity('abc123'), '^(abc)$', '\\\\1') GROUP BY 1,            toLowCardinality(9), 1 WITH CUBE SETTINGS group_by_use_nulls=1"
        ],
        "comment": "https://s3.amazonaws.com/clickhouse-test-reports/json.html?PR=88112&sha=latest&name_0=PR&name_1=AST+fuzzer+%28amd_ubsan%29"
    },
    {
        "date": "07/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88202"
        },
        "oracle": "error",
        "reporter": "azat",
        "status": "open",
        "title": "LOGICAL_ERROR: Invalid binary search result in MergeTreeSetIndex",
        "comment": "CI: https://s3.amazonaws.com/clickhouse-test-reports/json.html?PR=88164&sha=latest&name_0=PR&name_1=AST+fuzzer+%28amd_debug%29"
    },
    {
        "date": "07/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88191"
        },
        "oracle": "error",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "Logical error: 'rm_entry_res != Coordination::Error::ZNOTEMPTY' on Keeper server check"
    },
    {
        "date": "07/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88180"
        },
        "oracle": "PQS",
        "reporter": "CheSema",
        "status": "open",
        "title": "count() returns wrong result",
        "test": [
            "CREATE TABLE left (g UInt32, i UInt32)",
            "INSERT INTO left VALUES",
            "CREATE TABLE right (g UInt32, i UInt32)",
            "INSERT INTO right VALUES",
            "select '::run';",
            "select g, i from left",
            "select g, i from right",
            "select g, i from right",
            "select g, i from left",
            "select g, count(*) from differences group by g"
        ],
        "comment": "### Company or project name"
    },
    {
        "date": "07/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88167"
        },
        "oracle": "crash",
        "reporter": "PedroTadim",
        "status": "closed",
        "title": "SEGV with `write_marks_for_substreams_in_compact_parts`"
    },
    {
        "date": "06/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88150"
        },
        "oracle": "error",
        "reporter": "PedroTadim",
        "status": "closed",
        "title": "Logical error: 'Cannot add action to empty ExpressionActionsChain'",
        "test": [
            "CREATE TABLE t0 (c0 Nullable(String)) ENGINE = MergeTree() ORDER BY tuple() SETTINGS allow_nullable_key = 1;",
            "INSERT INTO TABLE t0 (c0) VALUES ('a');",
            "ALTER TABLE t0 DELETE WHERE c0.size = 'b'; --bad cast error on mutation",
            "DELETE FROM t0 WHERE _block_number = 1;",
            "ALTER TABLE t0 REWRITE PARTS; --Logical error on server",
            "CREATE TABLE t0 (c0 Nullable(String)) ENGINE = MergeTree() ORDER BY tuple() SETTINGS allow_nullable_key = 1;",
            "INSERT INTO TABLE t0 (c0) VALUES ('a');",
            "ALTER TABLE t0 DELETE WHERE c0.size = 'b'; --bad cast error on mutation",
            "DELETE FROM t0 WHERE _block_number = 1;",
            "ALTER TABLE t0 REWRITE PARTS; --Logical error on server"
        ]
    },
    {
        "date": "06/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88142"
        },
        "oracle": "error",
        "reporter": "vdimir",
        "status": "open",
        "title": "Logical error 'Unexpected return type' in query with tuple with assumeNotNull and tuple",
        "test": [
            "SELECT 1 WHERE (assumeNotNull(materialize(NULL)), 1) = (1, 1)",
            "SELECT 1 WHERE (assumeNotNull(materialize(NULL)), 1) = (1, 1)"
        ],
        "comment": "```SQL\nSELECT 1 WHERE (assumeNotNull(materialize(NULL)), 1) = (1, 1)\n```"
    },
    {
        "date": "06/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88138"
        },
        "oracle": "error",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "Logical error: Sort order of blocks violated for column for floating-points",
        "test": [
            "CREATE TABLE t0 (c0 Int, c1 Float32) ENGINE = SummingMergeTree() ORDER BY (gccMurmurHash(c1));",
            "INSERT INTO TABLE t0 (c1, c0) SELECT 2, CAST(number AS Int) FROM numbers(52);",
            "INSERT INTO TABLE t0 (c1, c0) SELECT c1, c0 FROM generateRandom('c1 Float32, c0 Int', 4471575971265722, 3161, 5) LIMIT 142;",
            "INSERT INTO TABLE t0 (c1, c0) SELECT c1, c0 FROM generateRandom('c1 Float32, c0 Int', 14156128262908154975, 2463, 2) LIMIT 453;",
            "INSERT INTO TABLE t0 (c0, c1) SELECT 1, 3 FROM numbers(68);",
            "CREATE TABLE t0 (c0 Int, c1 Float32) ENGINE = SummingMergeTree() ORDER BY (gccMurmurHash(c1));",
            "INSERT INTO TABLE t0 (c1, c0) SELECT 2, CAST(number AS Int) FROM numbers(52);",
            "INSERT INTO TABLE t0 (c1, c0) SELECT c1, c0 FROM generateRandom('c1 Float32, c0 Int', 4471575971265722, 3161, 5) LIMIT 142;",
            "INSERT INTO TABLE t0 (c1, c0) SELECT c1, c0 FROM generateRandom('c1 Float32, c0 Int', 14156128262908154975, 2463, 2) LIMIT 453;",
            "INSERT INTO TABLE t0 (c0, c1) SELECT 1, 3 FROM numbers(68);"
        ]
    },
    {
        "date": "06/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88126"
        },
        "oracle": "crash",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "Iceberg SEGV with Parquet reader on ORC file?",
        "test": [
            "CREATE TABLE t0 (c0 String) ENGINE = IcebergLocal(local, format = 'ORC', path = '/var/lib/clickhouse/user_files/lakehouse/t0/');",
            "INSERT INTO TABLE FUNCTION icebergLocal(local, structure = 'c0 String', path = '/var/lib/clickhouse/user_files/lakehouse/t0/') (c0) SELECT 'a';",
            "INSERT INTO TABLE t0 (c0) SELECT 'b';",
            "SELECT 1 FROM icebergLocal(local, format = 'ORC', structure = 'c0 String', path = '/var/lib/clickhouse/user_files/lakehouse/t0/') tx SETTINGS input_format_parquet_use_native_reader_v3 = 1; --SEGV",
            "CREATE TABLE t0 (c0 String) ENGINE = IcebergLocal(local, format = 'ORC', path = '/var/lib/clickhouse/user_files/lakehouse/t0/');",
            "INSERT INTO TABLE FUNCTION icebergLocal(local, structure = 'c0 String', path = '/var/lib/clickhouse/user_files/lakehouse/t0/') (c0) SELECT 'a';",
            "INSERT INTO TABLE t0 (c0) SELECT 'b';",
            "SELECT 1 FROM icebergLocal(local, format = 'ORC', structure = 'c0 String', path = '/var/lib/clickhouse/user_files/lakehouse/t0/') tx SETTINGS input_format_parquet_use_native_reader_v3 = 1; --SEGV"
        ]
    },
    {
        "date": "06/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88123"
        },
        "oracle": "error",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "Iceberg Logical error: 'ChunkInfoRowNumbers does not exist'",
        "test": [
            "CREATE TABLE t0 (c0 Int) ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouse/t0/');",
            "INSERT INTO TABLE t0 (c0) VALUES (1)",
            "ALTER TABLE t0 DELETE WHERE c0 == 1;",
            "INSERT INTO TABLE FUNCTION icebergLocal(s3, structure = 'c0 Int', format = 'ORC', path = '/var/lib/clickhouse/user_files/lakehouse/t0/') (c0) VALUES (2);",
            "OPTIMIZE TABLE t0; --Logical error",
            "CREATE TABLE t0 (c0 Int) ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouse/t0/');",
            "INSERT INTO TABLE t0 (c0) VALUES (1)",
            "ALTER TABLE t0 DELETE WHERE c0 == 1;",
            "INSERT INTO TABLE FUNCTION icebergLocal(s3, structure = 'c0 Int', format = 'ORC', path = '/var/lib/clickhouse/user_files/lakehouse/t0/') (c0) VALUES (2);"
        ]
    },
    {
        "date": "06/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88115"
        },
        "oracle": "error",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "Logical error: 'Bad cast from type DB::ASTFunction to DB::ASTLiteral' on GenerateRandom table engine"
    },
    {
        "date": "05/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88103"
        },
        "oracle": "unknown",
        "reporter": "fm4v",
        "status": "closed",
        "title": "25.9 regression: `NOT_FOUND_COLUMN_IN_BLOCK` with `query_plan_use_new_logical_join_step=0`",
        "comment": "### Does it reproduce on the most recent release?"
    },
    {
        "date": "03/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88081"
        },
        "oracle": "crash",
        "reporter": "PedroTadim",
        "status": "closed",
        "title": "Iceberg SEGV on window function as partition function",
        "test": [
            "CREATE TABLE t0 (c0 Int) ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/t0', format = 'Parquet') PARTITION BY (min(c0) OVER ());",
            "CREATE TABLE t0 (c0 Int) ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/t0', format = 'Parquet') PARTITION BY (min(c0) OVER ());"
        ]
    },
    {
        "date": "03/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88080"
        },
        "oracle": "error",
        "reporter": "PedroTadim",
        "status": "closed",
        "title": "Logical error: Bad cast from type DB::ColumnArray to DB::ColumnString with searchAny"
    },
    {
        "date": "03/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88077"
        },
        "oracle": "crash",
        "reporter": "PedroTadim",
        "status": "closed",
        "title": "Assertion `!ddl_worker || !ddl_worker->isCurrentlyActive() || txn' failure",
        "test": [
            "CREATE DATABASE d0 ENGINE = Replicated('/clickhouse/path/d0', '{shard}', '{replica}');",
            "CREATE TABLE d0.t0 (c0 Int) ENGINE = KeeperMap('/k0', 1) PRIMARY KEY (c0);",
            "ALTER TABLE d0.t0 COMMENT COLUMN c0 'a';",
            "/*",
            "src/Databases/DatabaseReplicated.cpp:2109:",
            "With [config.txt](https://github.com/user-attachments/files/22682131/config.txt) for config.xml, run:",
            "CREATE DATABASE d0 ENGINE = Replicated('/clickhouse/path/d0', '{shard}', '{replica}');",
            "CREATE TABLE d0.t0 (c0 Int) ENGINE = KeeperMap('/k0', 1) PRIMARY KEY (c0);",
            "ALTER TABLE d0.t0 COMMENT COLUMN c0 'a';"
        ]
    },
    {
        "date": "03/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88059"
        },
        "oracle": "error",
        "reporter": "PedroTadim",
        "status": "closed",
        "title": "Logical Error: No arrays to join"
    },
    {
        "date": "02/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/88010"
        },
        "oracle": "error",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "Iceberg Logical error: Invalid number of rows in Chunk with background read"
    },
    {
        "date": "01/10/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87972"
        },
        "oracle": "error",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "Column description is empty and it can't be built from sample from table error still happens"
    },
    {
        "date": "30/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87923"
        },
        "oracle": "error",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "Logical error: 'Function node with name 'exists' is not resolved as ordinary function'"
    },
    {
        "date": "30/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87898"
        },
        "oracle": "error",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "Iceberg Logical error: 'Unexpected null _row_number'",
        "test": [
            "CREATE TABLE t0 (c0 Int) ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/t0', format = 'Avro');",
            "INSERT INTO TABLE t0 (c0) VALUES (1);",
            "ALTER TABLE t0 DELETE WHERE c0 != 2; --Logical error",
            "CREATE TABLE t0 (c0 Int) ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/t0', format = 'Avro');",
            "INSERT INTO TABLE t0 (c0) VALUES (1);",
            "ALTER TABLE t0 DELETE WHERE c0 != 2; --Logical error"
        ]
    },
    {
        "date": "30/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87890"
        },
        "oracle": "error",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "Iceberg Logical error: Invalid number of columns in chunk",
        "test": [
            "CREATE TABLE t0 ENGINE = IcebergLocal(local, format = 'Parquet', path = '/var/lib/clickhouse/user_files/lakehouses/t0/test/t0');",
            "SELECT 1 FROM t0 WHERE t0._row_number = 1 AND t0._data_lake_snapshot_version = 1; --logical error",
            "With [spark.py](https://github.com/user-attachments/files/22615855/spark.py). run: `python spark.py create` to create the table, then in ClickHouse run:",
            "CREATE TABLE t0 ENGINE = IcebergLocal(local, format = 'Parquet', path = '/var/lib/clickhouse/user_files/lakehouses/t0/test/t0');",
            "SELECT 1 FROM t0 WHERE t0._row_number = 1 AND t0._data_lake_snapshot_version = 1; --logical error"
        ]
    },
    {
        "date": "30/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87887"
        },
        "oracle": "error",
        "reporter": "PedroTadim",
        "status": "closed",
        "title": "Logical error: 'Column __text_index_i0_hasToken_0 with type LowCardinality(UInt8) should not be filled by text index reader'"
    },
    {
        "date": "30/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87886"
        },
        "oracle": "error",
        "reporter": "Avogar",
        "status": "open",
        "title": "Logical error: 'Statistics 'countmin' does not support estimate data type of LowCardinality(Nullable(Date))'.",
        "test": [
            "SET allow_experimental_statistics=1, optimize_move_to_prewhere=1, move_all_conditions_to_prewhere=1, enable_multiple_prewhere_read_steps=1, move_primary_key_columns_to_end_of_prewhere=1, allow_reorder_prewhere_conditions=1, allow_statistics_optimize=1, allow_suspicious_low_cardinality_types=1;",
            "CREATE TABLE test_improve_prewhere__fuzz_19 (`primary_key` String STATISTICS(CountMin), `normal_column` String STATISTICS(CountMin), `value` LowCardinality(UInt32) STATISTICS(TDigest), `date` LowCardinality(Nullable(Date)) STATISTICS(CountMin)) ENGINE = MergeTree ORDER BY primary_key;",
            "INSERT INTO test_improve_prewhere__fuzz_19 SELECT hex(number % 100) AS primary_key, ['hello', 'world', 'test', 'example', 'sample'][(number % 5) + 1] AS normal_column, (number % 1000) + 1 AS value, toDate('2025-08-01') + number AS date FROM numbers(10);",
            "EXPLAIN SELECT * FROM test_improve_prewhere__fuzz_19 WHERE (date = '2025-08-05') AND (lower(primary_key) = '00') AND (normal_column != 'hello') AND (value < 100);",
            "CREATE TABLE test_improve_prewhere__fuzz_19 (`primary_key` String STATISTICS(CountMin), `normal_column` String STATISTICS(CountMin), `value` LowCardinality(UInt32) STATISTICS(TDigest), `date` LowCardinality(Nullable(Date)) STATISTICS(CountMin)) ENGINE = MergeTree ORDER BY primary_key;",
            "INSERT INTO test_improve_prewhere__fuzz_19 SELECT hex(number % 100) AS primary_key, ['hello', 'world', 'test', 'example', 'sample'][(number % 5) + 1] AS normal_column, (number % 1000) + 1 AS value, toDate('2025-08-01') + number AS date FROM numbers(10);"
        ],
        "comment": "```sql\nSET allow_experimental_statistics=1, optimize_move_to_prewhere=1, move_all_conditions_to_prewhere=1, enable_multiple_prewhere_read_steps=1, move_primary_key_columns_to_end_of_prewhere=1, allow_reorder_prewhere_conditions=1, allow_statistics_optimize=1, allow_suspicious_low_cardinality_types=1..."
    },
    {
        "date": "29/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87840"
        },
        "oracle": "unknown",
        "reporter": "PedroTadim",
        "status": "closed",
        "title": "mortonEncode with empty tuple out-of-bounds",
        "test": [
            "SELECT mortonEncode(());",
            "SELECT mortonEncode(());"
        ]
    },
    {
        "date": "29/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87790"
        },
        "oracle": "error",
        "reporter": "Avogar",
        "status": "open",
        "title": "Logical error: 'Expected the argument №1 ('__table1.constant_null' of type Nullable(Nothing)) to have 1 rows, but it has 0'",
        "test": [
            "CREATE VIEW v",
            "AS SELECT",
            "NULL AS constant_null",
            "FROM system.numbers LIMIT 10;",
            "SELECT constant_null FROM v as l ANY RIGHT JOIN v AS r ON 1 =1  WHERE constant_null = 35;",
            "SELECT constant_null FROM v as l ANY RIGHT JOIN v AS r ON 1 =1  WHERE constant_null = 35;"
        ],
        "comment": "```sql\nCREATE VIEW v\nAS SELECT\n    NULL AS constant_null\nFROM system.numbers LIMIT 10;"
    },
    {
        "date": "26/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87710"
        },
        "oracle": "error",
        "reporter": "PedroTadim",
        "status": "closed",
        "title": "Logical error: 'Bad cast from type DB::ColumnArray to DB::ColumnVector<char8_t>'",
        "test": [
            "With this [users.xml](https://github.com/user-attachments/files/22563550/users.xml), run this script with the client several times to reproduce it [issue.sql](https://github.com/user-attachments/files/22563516/issue.sql)."
        ]
    },
    {
        "date": "26/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87707"
        },
        "oracle": "PQS",
        "reporter": "4ertus2",
        "status": "open",
        "title": "Hanging SHOW TABLES for DatabaseDataLake",
        "test": [
            "DROP DATABASE hms;",
            "CREATE DATABASE hms ENGINE = DataLakeCatalog('thrift://some-url-here:9083', 'user', 'password')"
        ],
        "comment": "### Company or project name"
    },
    {
        "date": "26/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87670"
        },
        "oracle": "error",
        "reporter": "Schum-io",
        "status": "closed",
        "title": "Code: 492 ACCESS_ENTITY_NOT_FOUND after DROP ROLE; error persists after reconnect and any clusterAllReplicas() query fails",
        "test": [
            "DROP USER IF EXISTS test_roles ON CLUSTER '{cluster}';",
            "DROP ROLE IF EXISTS test_roles_dict ON CLUSTER '{cluster}';",
            "SELECT hostName() AS h, count()",
            "SELECT hostName() AS h, count()",
            "SELECT hostName() AS h, count()"
        ],
        "comment": "### Company or project name"
    },
    {
        "date": "25/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87626"
        },
        "oracle": "unknown",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "Bad memory management during backup?",
        "test": [
            "SET memory_tracker_fault_probability = 0.9, max_untracked_memory = 0;",
            "BACKUP ALL TO Memory('backup');"
        ]
    },
    {
        "date": "25/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87619"
        },
        "oracle": "unknown",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "Iceberg out-of-bounds with access to older snapshot",
        "test": [
            "CREATE TABLE t0 (c0 Int, c1 Int) ENGINE = IcebergLocal(local, format = 'Parquet', path = '/var/lib/clickhouse/user_files/lakehouses/t0/');",
            "INSERT INTO t0 VALUES (1,1),(2,2),(3,3);",
            "ALTER TABLE t0 CLEAR COLUMN c0;",
            "INSERT INTO t0 SETTINGS iceberg_snapshot_id = <snapshot id of the first insert>  VALUES (1,1),(2,2),(3,3); --Logical error",
            "CREATE TABLE t0 (c0 Int, c1 Int) ENGINE = IcebergLocal(local, format = 'Parquet', path = '/var/lib/clickhouse/user_files/lakehouses/t0/');",
            "INSERT INTO t0 VALUES (1,1),(2,2),(3,3);",
            "ALTER TABLE t0 CLEAR COLUMN c0;",
            "INSERT INTO t0 SETTINGS iceberg_snapshot_id = <snapshot id of the first insert>  VALUES (1,1),(2,2),(3,3); --Logical error"
        ]
    },
    {
        "date": "24/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87586"
        },
        "oracle": "PQS",
        "reporter": "pkese",
        "status": "open",
        "title": "Prohibited LowCardinality when importing tables with dates",
        "test": [
            "CREATE TABLE pq_test1 ENGINE = MergeTree ORDER BY (year, src, dst)",
            "SETTINGS allow_nullable_key = 1",
            "AS SELECT * FROM url('https://storage.googleapis.com/cliclhouse-bug-repro-42/pq_test.parquet', Parquet)",
            "CREATE TABLE pq_test2 ENGINE = MergeTree ORDER BY (year, src, dst)",
            "SETTINGS allow_nullable_key = 1",
            "AS SELECT * FROM url('https://storage.googleapis.com/cliclhouse-bug-repro-42/hp=2025-09-24/pq_test.parquet', Parquet)",
            "DESCRIBE TABLE url('https://storage.googleapis.com/cliclhouse-bug-repro-42/hp=2025-09-24/pq_test.parquet', Parquet)",
            "┌─name─────────┬─type─────────────────┬─default_type─┬─default_expression─┬─comment─┬─codec_expression─┬─ttl_expression─┐",
            "1. │ year         │ Nullable(Int64)      │              │                    │         │                  │                │",
            "2. │ src          │ Nullable(String)     │              │                    │         │                  │                │"
        ],
        "comment": "### Company or project name"
    },
    {
        "date": "24/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87576"
        },
        "oracle": "error",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "DeltaLake: Logical error: 'Bad cast from type DB::IDataType const* to DB::DataTypeDateTime64 const*'",
        "test": [
            "SELECT * FROM deltaLakeLocal(local, structure = 'c2 Float32, c3 LowCardinality(Time), c4 Bool, c1 Nullable(Time)', path = '/var/lib/clickhouse/user_files/lakehouses/spark_catalog/test/t0', format = 'Parquet') AS tx SETTINGS allow_experimental_delta_kernel_rs = 0 , allow_suspicious_low_cardinality_types = 1, enable_time_time64_type = 1;",
            "SELECT * FROM deltaLakeLocal(local, structure = 'c2 Float32, c3 LowCardinality(Time), c4 Bool, c1 Nullable(Time)', path = '/var/lib/clickhouse/user_files/lakehouses/spark_catalog/test/t0', format = 'Parquet') AS tx SETTINGS allow_experimental_delta_kernel_rs = 0 , allow_suspicious_low_cardinality_types = 1, enable_time_time64_type = 1;"
        ]
    },
    {
        "date": "24/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87575"
        },
        "oracle": "PQS",
        "reporter": "kirilovskiy",
        "status": "open",
        "title": "Lazy materialization: Method deserializeBinaryBulk of SerializationAggregateFunction does not support cases where rows_offset {} is non-zero",
        "test": [
            "DROP TABLE IF EXISTS agg_test;",
            "CREATE TABLE agg_test",
            "(",
            "id UInt32,",
            "accepted_at DateTime64(3),",
            "DROP TABLE IF EXISTS agg_test;",
            "CREATE TABLE agg_test",
            "INSERT INTO agg_test",
            "SELECT id, finalizeAggregation(delivery_report_at) AS delivered_at",
            "SELECT id, finalizeAggregation(delivery_report_at) AS delivered_at"
        ],
        "comment": "### Company or project name"
    },
    {
        "date": "24/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87559"
        },
        "oracle": "error",
        "reporter": "PedroTadim",
        "status": "closed",
        "title": "Logical error: 'Bad cast from type DB::ColumnVector<int> to DB::ColumnVector<char8_t>' with Parquet reader v3",
        "test": [
            "SET enable_time_time64_type= 1;",
            "CREATE TABLE t0 (c0 Int) ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/spark_catalog/test/t0', format = 'Parquet');",
            "INSERT INTO TABLE t0 (c0) VALUES (1);",
            "SELECT c0 FROM icebergLocal(local, structure = 'c0 Int', path = '/var/lib/clickhouse/user_files/lakehouses/spark_catalog/test/t0', format = 'Parquet') x PREWHERE toInt32('256:08:15'::Time) SETTINGS input_format_parquet_use_native_reader_v3 = 1;",
            "CREATE TABLE t0 (c0 Int) ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/spark_catalog/test/t0', format = 'Parquet');",
            "INSERT INTO TABLE t0 (c0) VALUES (1);",
            "SELECT c0 FROM icebergLocal(local, structure = 'c0 Int', path = '/var/lib/clickhouse/user_files/lakehouses/spark_catalog/test/t0', format = 'Parquet') x PREWHERE toInt32('256:08:15'::Time) SETTINGS input_format_parquet_use_native_reader_v3 = 1;"
        ]
    },
    {
        "date": "23/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87527"
        },
        "oracle": "crash",
        "reporter": "sigxcpu76",
        "status": "closed",
        "title": "Crash when reading with parquet reader v3",
        "comment": "### Company or project name"
    },
    {
        "date": "23/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87517"
        },
        "oracle": "error",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "Logical error: Cannot clone block with columns because block...",
        "test": [
            "CREATE TABLE t0 (c0 Int) ENGINE = S3(s3, format = 'CSV', filename = 'file{_partition_id}') PARTITION BY (c0);",
            "ALTER TABLE t0 ADD COLUMN c1 Variant(Int,String);",
            "INSERT INTO TABLE t0 (c0) VALUES (1); ---Logical error",
            "CREATE TABLE t0 (c0 Int) ENGINE = S3(s3, format = 'CSV', filename = 'file{_partition_id}') PARTITION BY (c0);",
            "ALTER TABLE t0 ADD COLUMN c1 Variant(Int,String);",
            "INSERT INTO TABLE t0 (c0) VALUES (1); ---Logical error"
        ]
    },
    {
        "date": "23/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87509"
        },
        "oracle": "crash",
        "reporter": "Selfeer",
        "status": "closed",
        "title": "Segmentation fault when reading from a Parquet file with parquet native reader v3",
        "test": [
            "SELECT * FROM file('boolean_bloom.gz.parquet', 'Parquet') SETTINGS input_format_parquet_use_native_reader_v3 = 1",
            "SELECT * FROM file('boolean_bloom.gz.parquet', 'Parquet') SETTINGS input_format_parquet_use_native_reader_v3 = 1"
        ],
        "comment": "### Company or project name"
    },
    {
        "date": "22/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87417"
        },
        "oracle": "error",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "Strange error on Iceberg insert",
        "test": [
            "CREATE TABLE t0 ENGINE = IcebergS3(s3, filename = 't0/test/t0', format = 'Parquet');",
            "INSERT INTO TABLE t0 (c0) SETTINGS write_full_path_in_iceberg_metadata = 1 VALUES (1);",
            "INSERT INTO TABLE t0 (c0) VALUES (2);",
            "CREATE TABLE t0 ENGINE = IcebergS3(s3, filename = 't0/test/t0', format = 'Parquet');",
            "INSERT INTO TABLE t0 (c0) SETTINGS write_full_path_in_iceberg_metadata = 1 VALUES (1);",
            "INSERT INTO TABLE t0 (c0) VALUES (2);"
        ]
    },
    {
        "date": "22/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87413"
        },
        "oracle": "PQS",
        "reporter": "Selfeer",
        "status": "closed",
        "title": "Different decimal precision value when reading with parquet native reader v3",
        "test": [
            "DESCRIBE TABLE file('int32_decimal_1.parquet')",
            "FORMAT TabSeparated",
            "SETTINGS input_format_parquet_use_native_reader_v3 = 0",
            "value\tNullable(Decimal(4, 2))",
            "DESCRIBE TABLE file('int32_decimal_1.parquet')",
            "FORMAT TabSeparated",
            "SETTINGS input_format_parquet_use_native_reader_v3 = 1",
            "value\tNullable(Decimal(9, 2))"
        ],
        "comment": "### Company or project name"
    },
    {
        "date": "22/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87412"
        },
        "oracle": "PQS",
        "reporter": "Selfeer",
        "status": "closed",
        "title": "BOOL is sometimes true and sometimes false with parquet native reader v3",
        "comment": "### Company or project name"
    },
    {
        "date": "22/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87403"
        },
        "oracle": "PQS",
        "reporter": "peterporserud",
        "status": "open",
        "title": "Dictionary and case statement in query does not return correct rows for distributed table",
        "test": [
            "CREATE TABLE default.t0 ON CLUSTER '{cluster}' (",
            "CREATE TABLE default.t0_d ON CLUSTER '{cluster}'",
            "CREATE DICTIONARY default.d0 ON CLUSTER '{cluster}' (",
            "SELECT toUInt8(1) AS id, ''alpha'' AS d",
            "SELECT toUInt8(2) AS id, ''beta'' AS d",
            "INSERT INTO default.t0_d (id, c) VALUES",
            "SELECT * FROM default.t0_d"
        ],
        "comment": "### Company or project name"
    },
    {
        "date": "22/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87402"
        },
        "oracle": "error",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "DeltaLake Logical error: 'Header does not match write schema. Expected: c0, got: c0.c1'",
        "test": [
            "CREATE TABLE t0 (c0 Nested(c1 Int32)) ENGINE = DeltaLakeLocal(local, format = 'Parquet', path = '/var/lib/clickhouse/user_files/lakehouses/spark_catalog/test/t0');",
            "INSERT INTO TABLE t0 (c0.c1) SELECT c1 FROM generateRandom('c1 Array(Int32)', 1804311225537264571, 1, 9) LIMIT 1; --Logical error",
            "Create the table with [spark.py](https://github.com/user-attachments/files/22467906/spark.py). Then in ClickHouse run:",
            "CREATE TABLE t0 (c0 Nested(c1 Int32)) ENGINE = DeltaLakeLocal(local, format = 'Parquet', path = '/var/lib/clickhouse/user_files/lakehouses/spark_catalog/test/t0');",
            "INSERT INTO TABLE t0 (c0.c1) SELECT c1 FROM generateRandom('c1 Array(Int32)', 1804311225537264571, 1, 9) LIMIT 1; --Logical error"
        ]
    },
    {
        "date": "22/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87401"
        },
        "oracle": "PQS",
        "reporter": "PHaroZ",
        "status": "closed",
        "title": "Invalid number of rows in Chunk with query_plan_join_swap_table=auto",
        "test": [
            "DROP TABLE IF EXISTS b_customers;",
            "CREATE TABLE b_customers (customer_id Int64, first_order_id Int64) ENGINE = MergeTree ORDER BY customer_id;",
            "INSERT INTO b_customers SELECT number, number * 20000000 FROM system.numbers LIMIT 2,100000; -- will work with LIMIT 10000",
            "INSERT INTO b_customers SELECT number * -1, -1 FROM system.numbers LIMIT 2; -- will work without this line or LIMIT 1",
            "DROP TABLE IF EXISTS b_orders;",
            "select count() from viewWithJoin;",
            "set query_plan_join_swap_table=0;",
            "select count() from viewWithJoin;",
            "DROP TABLE IF EXISTS b_customers;",
            "CREATE TABLE b_customers (customer_id Int64, first_order_id Int64) ENGINE = MergeTree ORDER BY customer_id;"
        ],
        "comment": "### Company or project name"
    },
    {
        "date": "22/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87390"
        },
        "oracle": "unknown",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "IS NULL predicate not correctly processed with DeltaLake table",
        "test": [
            "CREATE TABLE t0 (c0 Dynamic) ENGINE = DeltaLakeLocal(local, format = 'Parquet', path = '/var/lib/clickhouse/user_files/lakehouses/spark_catalog/test/t0');",
            "SELECT count() FROM numbers(1) x RIGHT JOIN t0 ON number = c0 WHERE NOT c0 IS NULL;",
            "Create the table with [spark.py](https://github.com/user-attachments/files/22464030/spark.py). Then in ClickHouse run:",
            "CREATE TABLE t0 (c0 Dynamic) ENGINE = DeltaLakeLocal(local, format = 'Parquet', path = '/var/lib/clickhouse/user_files/lakehouses/spark_catalog/test/t0');",
            "SELECT count() FROM numbers(1) x RIGHT JOIN t0 ON number = c0 WHERE NOT c0 IS NULL;"
        ]
    },
    {
        "date": "19/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87336"
        },
        "oracle": "error",
        "reporter": "nickitat",
        "status": "open",
        "title": "Logical error: '(isConst() || isSparse()) ? getDataType() == rhs.getDataType() : typeid(*this) == typeid(rhs)' during TTL merge",
        "test": [
            "CREATE TABLE ttl_group_by__fuzz_13",
            "INSERT INTO ttl_group_by__fuzz_13 SELECT toDate('2000-10-10'), number, number FROM numbers(100);",
            "INSERT INTO ttl_group_by__fuzz_13 SELECT toDate('1970-10-10'), number, number FROM numbers(100);"
        ]
    },
    {
        "date": "19/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87332"
        },
        "oracle": "error",
        "reporter": "PedroTadim",
        "status": "closed",
        "title": "Iceberg Logical error: 'ChunkInfoRowNumOffset does not exist'",
        "test": [
            "CREATE TABLE t0 ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/t0/test/t0', format = 'ORC');",
            "SELECT c0 FROM t0; --Logical error",
            "With the [spark.py](https://github.com/user-attachments/files/22426375/spark.py) script, run `python spark.py create`. Then, in ClickHouse load the table:",
            "CREATE TABLE t0 ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/t0/test/t0', format = 'ORC');",
            "SELECT c0 FROM t0; --Logical error"
        ]
    },
    {
        "date": "19/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87322"
        },
        "oracle": "error",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "DeltaLake Logical error: 'Not found column c1.values in physical names map. There are only columns: c1, c0'",
        "test": [
            "CREATE TABLE t0 ENGINE = DeltaLakeLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/spark_catalog/test/t0', format = 'Parquet');",
            "SELECT c1.values FROM t0; --Logical error",
            "CREATE TABLE t0 ENGINE = DeltaLakeLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/spark_catalog/test/t0', format = 'Parquet');",
            "SELECT c1.values FROM t0; --Logical error"
        ]
    },
    {
        "date": "18/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87293"
        },
        "oracle": "crash",
        "reporter": "jptx1234",
        "status": "closed",
        "title": "Server crashes with segfault during GROUP BY after lightweight UPDATE",
        "test": [
            "CREATE TABLE testa (",
            "x UInt32,",
            "y UInt32",
            ") ENGINE = MergeTree ORDER BY x;",
            "INSERT INTO testa  (x, y) SELECT (number + 1) AS x, (x % 1000) AS y FROM numbers(9999);",
            "CREATE TABLE testa (",
            "INSERT INTO testa  (x, y) SELECT (number + 1) AS x, (x % 1000) AS y FROM numbers(9999);",
            "alter table testa MODIFY SETTING enable_block_offset_column = 1;",
            "alter table testa MODIFY SETTING enable_block_number_column = 1;",
            "alter table testa add column z UInt32 default 0 after y;"
        ],
        "comment": "### Company or project name"
    },
    {
        "date": "18/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87276"
        },
        "oracle": "error",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "Logical error: 'Storage type 'DeltaLakeLocal' is not supported by distributed DDL'",
        "test": [
            "CREATE TABLE t0 ON CLUSTER 'cluster0' (c0 Int) ENGINE = DeltaLakeLocal(local, format = 'Parquet', path = '/var/lib/clickhouse/user_files/spark_catalog/test/t0');",
            "ALTER TABLE t0 ON CLUSTER 'cluster0' MATERIALIZE COLUMN c0;",
            "CREATE TABLE t0 ON CLUSTER 'cluster0' (c0 Int) ENGINE = DeltaLakeLocal(local, format = 'Parquet', path = '/var/lib/clickhouse/user_files/spark_catalog/test/t0');",
            "ALTER TABLE t0 ON CLUSTER 'cluster0' MATERIALIZE COLUMN c0;"
        ]
    },
    {
        "date": "15/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87131"
        },
        "oracle": "crash",
        "reporter": "Avogar",
        "status": "closed",
        "title": "Reading both Array and its size0 subcolumn crashes the server with lazy materialization",
        "test": [
            "create table test (x UInt64, y UInt64, a Array(UInt64)) engine=MergeTree order by x settings min_rows_for_wide_part=1, min_bytes_for_wide_part=1;",
            "insert into test select number, number, range(number) from numbers(10);",
            "select a, a.size0 from test where y > 5 order by y limit 2 settings send_logs_level='debug';",
            "create table test (x UInt64, y UInt64, a Array(UInt64)) engine=MergeTree order by x settings min_rows_for_wide_part=1, min_bytes_for_wide_part=1;",
            "insert into test select number, number, range(number) from numbers(10);",
            "select a, a.size0 from test where y > 5 order by y limit 2 settings send_logs_level='debug';"
        ],
        "comment": "### Company or project name"
    },
    {
        "date": "15/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87118"
        },
        "oracle": "PQS",
        "reporter": "JiaQiTang98",
        "status": "closed",
        "title": "The statistic value of temporary data size always increases",
        "test": [
            "create a table",
            "CREATE TABLE default.t_proj_external",
            "INSERT INTO t_proj_external SELECT 1, number%2, number%4, number FROM numbers(50000);",
            "SELECT k1, k2, k3, sum(value) v FROM t_proj_external GROUP BY k1, k2, k3 ORDER BY k1, k2, k3 SETTINGS optimize_aggregation_in_order = 0, max_bytes_before_external_group_by = 1, max_bytes_ratio_before_external_group_by = 0, group_by_two_level_threshold = 1;"
        ],
        "comment": "### Company or project name"
    },
    {
        "date": "12/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87078"
        },
        "oracle": "error",
        "reporter": "PedroTadim",
        "status": "closed",
        "title": "Logical error: 'false' with Parquet reader v3",
        "test": [
            "SET input_format_parquet_use_native_reader_v3 = 1;",
            "CREATE TABLE t0 ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/t0/test/t0', format = 'Parquet');",
            "INSERT INTO TABLE t0 (c0) VALUES (TRUE);",
            "SELECT t0.c0 FROM t0 WHERE c0 = 3 AND c0 >= 5;",
            "CREATE TABLE t0 ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/t0/test/t0', format = 'Parquet');",
            "INSERT INTO TABLE t0 (c0) VALUES (TRUE);",
            "SELECT t0.c0 FROM t0 WHERE c0 = 3 AND c0 >= 5;"
        ]
    },
    {
        "date": "12/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87059"
        },
        "oracle": "unknown",
        "reporter": "PedroTadim",
        "status": "closed",
        "title": "Is it possible to add an index to a S3 table, making it unusable",
        "test": [
            "CREATE TABLE t0 (c0 Int) ENGINE = S3(s3, filename = 'file1.data', format = 'Avro');",
            "ALTER TABLE t0 ADD INDEX i0 c0 TYPE set(0);",
            "CREATE TABLE t0 (c0 Int) ENGINE = S3(s3, filename = 'file1.data', format = 'Avro');",
            "ALTER TABLE t0 ADD INDEX i0 c0 TYPE set(0);"
        ]
    },
    {
        "date": "11/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87016"
        },
        "oracle": "PQS",
        "reporter": "devcrafter",
        "status": "open",
        "title": "Unexpected return type from concat. Expected String. Got Nullable(String)"
    },
    {
        "date": "11/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/87015"
        },
        "oracle": "PQS",
        "reporter": "Algunenano",
        "status": "closed",
        "title": "Grant ON nonexistent TABLE ENGINE works",
        "test": [
            "CREATE TABLE t111111"
        ],
        "comment": "### Company or project name"
    },
    {
        "date": "10/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/86957"
        },
        "oracle": "error",
        "reporter": "evillique",
        "status": "open",
        "title": "Logical error: Invalid number of columns in chunk pushed to OutputPort with full_sorting_merge",
        "comment": "### Describe what's wrong"
    },
    {
        "date": "09/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/86882"
        },
        "oracle": "crash",
        "reporter": "alsugiliazova",
        "status": "open",
        "title": "Fatal using approx_top_k and finalizeAggregation",
        "comment": "### Company or project name"
    },
    {
        "date": "08/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/86795"
        },
        "oracle": "error",
        "reporter": "PedroTadim",
        "status": "closed",
        "title": "Logical error: 'Some expressions was not applied: [equals(__table4.c0, __table3.c0): {1, 2}]'"
    },
    {
        "date": "06/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/86776"
        },
        "oracle": "error",
        "reporter": "PedroTadim",
        "status": "open",
        "title": "Logical error: 'persistent_components.format_version == metadata_object->getValue<int>(f_format_version)''",
        "test": [
            "CREATE TABLE t0 ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/t0/test/t0', format = 'Parquet');",
            "SELECT c0 FROM t0; --gets 10 random numbers",
            "SELECT c0 FROM t0; --Logical error",
            "CREATE TABLE t0 ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/t0/test/t0', format = 'Parquet');",
            "SELECT c0 FROM t0; --gets 10 random numbers",
            "SELECT c0 FROM t0; --Logical error"
        ]
    },
    {
        "date": "04/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/86681"
        },
        "oracle": "crash",
        "reporter": "PedroTadim",
        "status": "closed",
        "title": "Trivial SEGV with empty Iceberg table",
        "test": [
            "CREATE TABLE t0 (c0 Int) ENGINE = IcebergLocal(local, format = 'Parquet', path = '/var/lib/clickhouse/user_files/t0/');",
            "SELECT 1 FROM t0 SETTINGS iceberg_metadata_log_level = 'metadata'; --SEGV",
            "CREATE TABLE t0 (c0 Int) ENGINE = IcebergLocal(local, format = 'Parquet', path = '/var/lib/clickhouse/user_files/t0/');",
            "SELECT 1 FROM t0 SETTINGS iceberg_metadata_log_level = 'metadata'; --SEGV"
        ]
    },
    {
        "date": "03/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/86642"
        },
        "oracle": "crash",
        "reporter": "robot-clickhouse",
        "status": "closed",
        "title": "[CI crash] ColumnArray conversion failed in ArrayJoin",
        "test": [
            "WITH",
            "(",
            "SELECT groupArrayDistinct(cleanStackTrace(trace_full) AS trace) FROM default.stack_traces",
            "WHERE sipHash64(trace) IN (1478846248164228819, {ANOTHER_TRACE_HASH}) -- FIXME: replace with the known hash",
            ") AS traces,",
            "SELECT groupArrayDistinct(cleanStackTrace(trace_full) AS trace) FROM default.stack_traces",
            "SELECT count()",
            "SELECT arraySimilarity(traces[1], traces[2], get_trace_weights(traces[1]) AS weights1, get_trace_weights(traces[2]) AS weights2) AS similarity,"
        ],
        "comment": "<details><summary>Stack trace details</summary>"
    },
    {
        "date": "03/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/86596"
        },
        "oracle": "crash",
        "reporter": "PedroTadim",
        "status": "closed",
        "title": "Trivial crash with arrowflight"
    },
    {
        "date": "03/09/2025",
        "dbms": "ClickHouse",
        "links": {
            "bugreport": "https://github.com/ClickHouse/ClickHouse/issues/86589"
        },
        "oracle": "unknown",
        "reporter": "crakjie",
        "status": "open",
        "title": "Early range() inlining is breaking distributed table queries",
        "test": [
            "SELECT `__table1`.`a` AS `a`, `__table1`.`b` AS `b` FROM `default`.`shard_Test` AS `__table1` WHERE `__table1`.`b` GLOBAL IN (`_data_13869028487804801089_11035135618929320876` AS `__table2`)",
            "SELECT _CAST([0, 1, 2, 3, 4], 'Array(UInt8)') AS `b` FROM `default`.`shard_Test` AS `__table1` GROUP BY _CAST([0, 1, 2, 3, 4], 'Array(UInt8)')",
            "INSERT INTO default.distributed_Test SETTINGS parallel_distributed_insert_select = 1 SELECT * FROM `default`.`shard_Test` WHERE `b` GLOBAL IN (SELECT range(5) AS `b` FROM `distributed_Test` GROUP BY `b`) SETTINGS parallel_distributed_insert_select = 1",
            "SELECT _CAST([0, 1, 2, 3, 4], 'Array(UInt8)') AS `b` FROM `default`.`shard_Test` AS `__table1` GROUP BY _CAST([0, 1, 2, 3, 4], 'Array(UInt8)')",
            "create table shard_Test on cluster '{cluster}' (a String,  b Array(Int64)) Engine = Memory();",
            "create table distributed_Test on cluster '{cluster}' (a String,  b Array(Int64)) Engine =  Distributed('{cluster}', 'default', 'shard_Test', rand());",
            "insert into distributed_Test Values ('x', [1,2,3,4,5]);",
            "INSERT INTO distributed_Test"
        ],
        "comment": "### Describe what's wrong"
    }
]