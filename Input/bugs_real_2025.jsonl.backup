{"index": 3002, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["CREATE TABLE \"cases\" (caseid varchar(255));", "INSERT INTO \"cases\" (caseid) VALUES ('DL1-1');", "SELECT;", "caseid as caseid,;", "caseid as \"delivery.caseid\";", "CREATE TABLE \"cases\" (caseid varchar(255));", "INSERT INTO \"cases\" (caseid) VALUES ('DL1-1');", "SELECT;", "caseid as caseid,;", "caseid as \"delivery.caseid\";"]}
{"index": 3003, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["CREATE TABLE t0(c0 INT);", "INSERT INTO t0(c0) VALUES(82);", "SELECT * FROM t0 WHERE NOT EXISTS (SELECT 1 FROM (VALUES (t0.c0)) WHERE TRUE);", "CREATE TABLE t0(c0 INT);", "INSERT INTO t0(c0) VALUES(82);", "SELECT * FROM t0 WHERE NOT EXISTS (SELECT 1 FROM (VALUES (t0.c0)) WHERE TRUE);", "CREATE TABLE t0(c0 INT);", "INSERT INTO t0(c0) VALUES(82);", "SELECT * FROM t0 WHERE NOT EXISTS (SELECT 1 FROM (VALUES (t0.c0)) WHERE TRUE);", "CREATE TABLE t0(c0 INT);"]}
{"index": 3004, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["create table test (id integer primary key, value string);", "select id, test.\"some_column_that_does_not_exist\" from test order by id;", "Without the table name as prefix:;"]}
{"index": 3007, "a_db": "duckdb", "b_db": "sqlite", "molt": "error", "sqls": ["COPY (FROM range(1)) TO '/tmp/test.parquet';", "SELECT;", "file_row_number,;", "FROM read_parquet('/tmp/test.parquet') WITH ORDINALITY;"]}
{"index": 3008, "a_db": "duckdb", "b_db": "sqlite", "molt": "pqs", "sqls": ["CREATE OR REPLACE TABLE mytable (id INT, dim__record_date DATE);", "SELECT;", "columns(cy.*) as '\\\\0__current_year',;", "columns(fs.* LIKE 'fct__%') as '\\\\0__previous_year',;", "FROM mytable cy;"]}
{"index": 3009, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["CREATE TABLE tunnd0(c1 int, c2 varchar(9), c3 dec(10,2), UNIQUE NULLS NOT DISTINCT (c1, c2), UNIQUE NULLS NOT DISTINCT (c2, c3));", "CREATE TABLE tunnd0(c1 int, c2 varchar(9), c3 dec(10,2), UNIQUE NULLS NOT DISTINCT (c1, c2), UNIQUE NULLS NOT DISTINCT (c2, c3));", "CREATE TABLE tunnd1l(c1 int, c2 varchar(9), c3 dec(10,2), UNIQUE NULLS NOT DISTINCT (c1, c2), UNIQUE NULLS DISTINCT (c2, c3));", "select id, table_id, type, name from sys.keys where table_id in (select id from sys.tables where not system and name like 'tunnd%');"]}
{"index": 3010, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["CREATE TABLE t0(c0 INT, c1 INT);", "INSERT INTO t0(c0, c1) VALUES(-2, 1);", "SELECT * FROM t0 WHERE NOT EXISTS (SELECT 1 FROM (VALUES (t0.c1)) WHERE (NOT (r'' NOT ILIKE r'')) AND FALSE);", "CREATE TABLE t0(c0 INT, c1 INT);", "INSERT INTO t0(c0, c1) VALUES(-2, 1);", "SELECT * FROM t0 WHERE NOT EXISTS (SELECT 1 FROM (VALUES (t0.c1)) WHERE (NOT (r'' NOT ILIKE r'')) AND FALSE);", "CREATE TABLE t0(c0 INT, c1 INT);", "INSERT INTO t0(c0, c1) VALUES(-2, 1);", "SELECT * FROM t0 WHERE NOT EXISTS (SELECT 1 FROM (VALUES (t0.c1)) WHERE (NOT (r'' NOT ILIKE r'')) AND FALSE);", "CREATE TABLE t0(c0 INT, c1 INT);"]}
{"index": 3014, "a_db": "duckdb", "b_db": "sqlite", "molt": "pqs", "sqls": ["create table tenk1(;", "unique1 int4,;", "unique2 int4,;", "two int4,;", "four int4,;"]}
{"index": 3015, "a_db": "duckdb", "b_db": "sqlite", "molt": "error", "sqls": ["CREATE TABLE df AS SELECT 'aBcaBc' AS name, x FROM range(0, 6) r(x);", "SELECT name, SUM(x) FROM df GROUP BY ALL ORDER BY name;", "SELECT name, SUM(x) FROM df GROUP BY name ORDER BY LOWER(name);", "SELECT name, SUM(x) FROM df GROUP BY name ORDER BY CASE WHEN name ='B' THEN 1 ELSE 0 END;", "SELECT name, SUM(x) FROM df GROUP BY ALL ORDER BY LOWER(name);"]}
{"index": 3016, "a_db": "duckdb", "b_db": "sqlite", "molt": "crash", "sqls": ["ATTACH 'ducklake:metadata.ducklake' AS my_ducklake;", "CREATE TABLE my_ducklake.tablename (;", "id INTEGER,;", "nome VARCHAR,;", "updated_at TIMESTAMPTZ,;"]}
{"index": 3017, "a_db": "duckdb", "b_db": "sqlite", "molt": "norec", "sqls": ["INSTALL shellfs FROM community;", "LOAD shellfs;", "select;", "max(c1) - min(c1);", "from read_csv(;"]}
{"index": 3021, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["CREATE TABLE t0(c0 INT);", "INSERT INTO t0(c0) VALUES(1);", "SELECT t0.c0 FROM t0 WHERE NOT EXISTS (SELECT 1 FROM (VALUES ((SELECT t0.c0)!=NULL)) AS subQuery(c0) WHERE subQuery.c0);", "CREATE TABLE t0(c0 INT);", "INSERT INTO t0(c0) VALUES(1);", "SELECT t0.c0 FROM t0 WHERE NOT EXISTS (SELECT 1 FROM (VALUES ((SELECT t0.c0)!=NULL)) AS subQuery(c0) WHERE subQuery.c0);", "CREATE TABLE t0(c0 INT);", "INSERT INTO t0(c0) VALUES(1);", "SELECT t0.c0 FROM t0 WHERE NOT EXISTS (SELECT 1 FROM (VALUES ((SELECT t0.c0)!=NULL)) AS subQuery(c0) WHERE subQuery.c0);", "CREATE TABLE t0(c0 INT);"]}
{"index": 3022, "a_db": "clickhouse", "b_db": "postgres", "molt": "crash", "sqls": ["WITH;", "SELECT groupArrayDistinct(cleanStackTrace(trace_full) AS trace) FROM default.stack_traces;", "WHERE sipHash64(trace) IN (1478846248164228819, {ANOTHER_TRACE_HASH}) -- FIXME: replace with the known hash;", ") AS traces,;", "1.97 AS alpha,;", "SELECT groupArrayDistinct(cleanStackTrace(trace_full) AS trace) FROM default.stack_traces;", "SELECT count();", "SELECT arraySimilarity(traces[1], traces[2], get_trace_weights(traces[1]) AS weights1, get_trace_weights(traces[2]) AS weights2) AS similarity,;"]}
{"index": 3024, "a_db": "clickhouse", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE t0 (c0 Int) ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/t0', format = 'Parquet') PARTITION BY (min(c0) OVER ());", "CREATE TABLE t0 (c0 Int) ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/t0', format = 'Parquet') PARTITION BY (min(c0) OVER ());"]}
{"index": 3026, "a_db": "clickhouse", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE DATABASE d0 ENGINE = Replicated('/clickhouse/path/d0', '{shard}', '{replica}');", "CREATE TABLE d0.t0 (c0 Int) ENGINE = KeeperMap('/k0', 1) PRIMARY KEY (c0);", "ALTER TABLE d0.t0 COMMENT COLUMN c0 'a';", "/*;", "src/Databases/DatabaseReplicated.cpp:2109:;", "With [config.txt](https://github.com/user-attachments/files/22682131/config.txt) for config.xml, run:;", "CREATE DATABASE d0 ENGINE = Replicated('/clickhouse/path/d0', '{shard}', '{replica}');", "CREATE TABLE d0.t0 (c0 Int) ENGINE = KeeperMap('/k0', 1) PRIMARY KEY (c0);", "ALTER TABLE d0.t0 COMMENT COLUMN c0 'a';"]}
{"index": 3028, "a_db": "duckdb", "b_db": "sqlite", "molt": "crash", "sqls": ["create temp table tbl1 as select unnest(range(1000)) % 10 as x, '2022-01-01'::timestamp + to_days(unnest(range(1000))) as ts;", "create temp table tbl2 as select unnest(range(1000)) % 10 as x, '2022-01-01'::timestamp + to_hours(unnest(range(1000))) as ts;", "from tbl1 asof join tbl2 on tbl1.x = tbl2.x and tbl1.ts >= tbl2.ts and (tbl1.ts - tbl2.ts) < interval '1' hours;", "create temp table prices as (from 'https://duckdb.org/data/prices.csv');", "create temp table holdings as (from 'https://duckdb.org/data/holdings.csv');", "SELECT h.ticker, h.when, price * shares AS value;", "FROM holdings h;", "ASOF JOIN prices p;"]}
{"index": 3029, "a_db": "duckdb", "b_db": "sqlite", "molt": "error", "sqls": ["WITH;", "T0(t00, t01) AS (VALUES(1,1),(1,1)),;", "T1(t10, t11) AS (VALUES(1,1),(1,1)),;", "T2(t20, t21) AS (VALUES(1,1),(1,1));", "SELECT (;"]}
{"index": 3032, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["CREATE TABLE \"FOO\"(x int);", "CREATE TABLE \"sys\".\"FOO\" (;"]}
{"index": 3033, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["CREATE USER test WITH PASSWORD 'me' NAME 'tester' OPTIMIZER 'xyz';", "SELECT name, optimizer FROM sys.users;", "SELECT name, optimizer FROM sys.users;", "SELECT name, optimizer FROM sys.db_user_info;"]}
{"index": 3034, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["CREATE TABLE IF NOT EXISTS t0(c0 INT );", "SET \"sql_optimizer\"='1';", "INSERT INTO t0(c0) VALUES(1);", "SELECT t0.c0 FROM t0 RIGHT JOIN (SELECT DISTINCT (SELECT CASE WHEN TRUE THEN 1 END FROM t0 CROSS JOIN (SELECT 1 WHERE FALSE))) ON JSON.ISVALID((VALUES (TRUE)));", "CREATE TABLE IF NOT EXISTS t0(c0 INT );", "SET \"sql_optimizer\"='1';", "INSERT INTO t0(c0) VALUES(1);", "SELECT t0.c0 FROM t0 RIGHT JOIN (SELECT DISTINCT (SELECT CASE WHEN TRUE THEN 1 END FROM t0 CROSS JOIN (SELECT 1 WHERE FALSE))) ON JSON.ISVALID((VALUES (TRUE)));", "CREATE TABLE IF NOT EXISTS t0(c0 INT );", "INSERT INTO t0(c0) VALUES(1);"]}
{"index": 3035, "a_db": "clickhouse", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE t0 (c0 Int) ENGINE = IcebergLocal(local, format = 'Parquet', path = '/var/lib/clickhouse/user_files/t0/');", "SELECT 1 FROM t0 SETTINGS iceberg_metadata_log_level = 'metadata';", "CREATE TABLE t0 (c0 Int) ENGINE = IcebergLocal(local, format = 'Parquet', path = '/var/lib/clickhouse/user_files/t0/');", "SELECT 1 FROM t0 SETTINGS iceberg_metadata_log_level = 'metadata';"]}
{"index": 3036, "a_db": "duckdb", "b_db": "sqlite", "molt": "pqs", "sqls": ["CREATE OR REPLACE SEQUENCE seq;", "SELECT;", "x,;", "CASE;", "WHEN x THEN;"]}
{"index": 3037, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["CREATE TABLE IF NOT EXISTS t0(c0 INT);", "CREATE TABLE IF NOT EXISTS t1(c0 INT);", "INSERT INTO t1(c0) VALUES(NULL);", "SELECT * FROM t1 LEFT JOIN (VALUES (1), (CASE (SELECT 0) WHEN 0 THEN 1 END)) ON NOT EXISTS (SELECT 1 FROM t0);", "CREATE TABLE IF NOT EXISTS t0(c0 INT);", "CREATE TABLE IF NOT EXISTS t1(c0 INT);", "INSERT INTO t1(c0) VALUES(NULL);", "SELECT * FROM t1 LEFT JOIN (VALUES (1), (CASE (SELECT 0) WHEN 0 THEN 1 END)) ON NOT EXISTS (SELECT 1 FROM t0);", "CREATE TABLE IF NOT EXISTS t0(c0 INT);", "CREATE TABLE IF NOT EXISTS t1(c0 INT);"]}
{"index": 3038, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["create table test(;", "username varchar,;", "inserted timestamp with time zone;", ");", "insert into test values ('user1', '2025-01-21 00:48:02.707000-04:00');", "insert into test values ('Admin', '2025-01-21 00:14:12.201000-04:00');", "insert into test values ('user2', '2025-01-21 00:29:29.896000-04:00');", "insert into test values ('user3', '2025-01-21 03:39:09.373000-04:00');", "Create a test table:;", "create table test(;"]}
{"index": 3043, "a_db": "clickhouse", "b_db": "postgres", "molt": "error", "sqls": ["CREATE TABLE t0 ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/t0/test/t0', format = 'Parquet');", "SELECT c0 FROM t0;", "SELECT c0 FROM t0;", "CREATE TABLE t0 ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/t0/test/t0', format = 'Parquet');", "SELECT c0 FROM t0;", "SELECT c0 FROM t0;"]}
{"index": 3044, "a_db": "clickhouse", "b_db": "postgres", "molt": "error", "sqls": ["CREATE TABLE t0 (c0 Nullable(String)) ENGINE = MergeTree() ORDER BY tuple() SETTINGS allow_nullable_key = 1;", "INSERT INTO TABLE t0 (c0) VALUES ('a');", "ALTER TABLE t0 DELETE WHERE c0.size = 'b';", "DELETE FROM t0 WHERE _block_number = 1;", "ALTER TABLE t0 REWRITE PARTS;", "CREATE TABLE t0 (c0 Nullable(String)) ENGINE = MergeTree() ORDER BY tuple() SETTINGS allow_nullable_key = 1;", "INSERT INTO TABLE t0 (c0) VALUES ('a');", "ALTER TABLE t0 DELETE WHERE c0.size = 'b';", "DELETE FROM t0 WHERE _block_number = 1;", "ALTER TABLE t0 REWRITE PARTS;"]}
{"index": 3045, "a_db": "clickhouse", "b_db": "postgres", "molt": "error", "sqls": ["SELECT 1 WHERE (assumeNotNull(materialize(NULL)), 1) = (1, 1);", "SELECT 1 WHERE (assumeNotNull(materialize(NULL)), 1) = (1, 1);"]}
{"index": 3046, "a_db": "clickhouse", "b_db": "postgres", "molt": "error", "sqls": ["CREATE TABLE t0 (c0 Int, c1 Float32) ENGINE = SummingMergeTree() ORDER BY (gccMurmurHash(c1));", "INSERT INTO TABLE t0 (c1, c0) SELECT 2, CAST(number AS Int) FROM numbers(52);", "INSERT INTO TABLE t0 (c1, c0) SELECT c1, c0 FROM generateRandom('c1 Float32, c0 Int', 4471575971265722, 3161, 5) LIMIT 142;", "INSERT INTO TABLE t0 (c1, c0) SELECT c1, c0 FROM generateRandom('c1 Float32, c0 Int', 14156128262908154975, 2463, 2) LIMIT 453;", "INSERT INTO TABLE t0 (c0, c1) SELECT 1, 3 FROM numbers(68);", "CREATE TABLE t0 (c0 Int, c1 Float32) ENGINE = SummingMergeTree() ORDER BY (gccMurmurHash(c1));", "INSERT INTO TABLE t0 (c1, c0) SELECT 2, CAST(number AS Int) FROM numbers(52);", "INSERT INTO TABLE t0 (c1, c0) SELECT c1, c0 FROM generateRandom('c1 Float32, c0 Int', 4471575971265722, 3161, 5) LIMIT 142;", "INSERT INTO TABLE t0 (c1, c0) SELECT c1, c0 FROM generateRandom('c1 Float32, c0 Int', 14156128262908154975, 2463, 2) LIMIT 453;", "INSERT INTO TABLE t0 (c0, c1) SELECT 1, 3 FROM numbers(68);"]}
{"index": 3047, "a_db": "clickhouse", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE t0 (c0 String) ENGINE = IcebergLocal(local, format = 'ORC', path = '/var/lib/clickhouse/user_files/lakehouse/t0/');", "INSERT INTO TABLE FUNCTION icebergLocal(local, structure = 'c0 String', path = '/var/lib/clickhouse/user_files/lakehouse/t0/') (c0) SELECT 'a';", "INSERT INTO TABLE t0 (c0) SELECT 'b';", "SELECT 1 FROM icebergLocal(local, format = 'ORC', structure = 'c0 String', path = '/var/lib/clickhouse/user_files/lakehouse/t0/') tx SETTINGS input_format_parquet_use_native_reader_v3 = 1;", "CREATE TABLE t0 (c0 String) ENGINE = IcebergLocal(local, format = 'ORC', path = '/var/lib/clickhouse/user_files/lakehouse/t0/');", "INSERT INTO TABLE FUNCTION icebergLocal(local, structure = 'c0 String', path = '/var/lib/clickhouse/user_files/lakehouse/t0/') (c0) SELECT 'a';", "INSERT INTO TABLE t0 (c0) SELECT 'b';", "SELECT 1 FROM icebergLocal(local, format = 'ORC', structure = 'c0 String', path = '/var/lib/clickhouse/user_files/lakehouse/t0/') tx SETTINGS input_format_parquet_use_native_reader_v3 = 1;"]}
{"index": 3048, "a_db": "clickhouse", "b_db": "postgres", "molt": "error", "sqls": ["CREATE TABLE t0 (c0 Int) ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouse/t0/');", "INSERT INTO TABLE t0 (c0) VALUES (1);", "ALTER TABLE t0 DELETE WHERE c0 == 1;", "INSERT INTO TABLE FUNCTION icebergLocal(s3, structure = 'c0 Int', format = 'ORC', path = '/var/lib/clickhouse/user_files/lakehouse/t0/') (c0) VALUES (2);", "OPTIMIZE TABLE t0;", "CREATE TABLE t0 (c0 Int) ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouse/t0/');", "INSERT INTO TABLE t0 (c0) VALUES (1);", "ALTER TABLE t0 DELETE WHERE c0 == 1;", "INSERT INTO TABLE FUNCTION icebergLocal(s3, structure = 'c0 Int', format = 'ORC', path = '/var/lib/clickhouse/user_files/lakehouse/t0/') (c0) VALUES (2);"]}
{"index": 3050, "a_db": "duckdb", "b_db": "sqlite", "molt": "error", "sqls": ["SET THREADS = 1;", "EXPLAIN ANALYZE;", "SELECT * FROM '/tmp/polars.parquet' WHERE sqrt(column_0) < 0.001;", "SET THREADS = 1;", "EXPLAIN ANALYZE;", "SELECT * FROM '/tmp/polars.parquet' WHERE file_row_number IN (SELECT file_row_number FROM '/tmp/polars.parquet' WHERE sqrt(column_0) < 0.001);"]}
{"index": 3053, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE OR REPLACE TRIGGER trigALogin AFTER LOGIN BEGIN ATOMIC SET SCHEMA dwh;", "END;", "select name from sys.triggers where name like 'tri%';", "CREATE OR REPLACE TRIGGER trigALogin AFTER LOGIN BEGIN ATOMIC SET SCHEMA dwh;", "END;"]}
{"index": 3056, "a_db": "clickhouse", "b_db": "postgres", "molt": "pqs", "sqls": ["CREATE TABLE left (g UInt32, i UInt32);", "INSERT INTO left VALUES;", "CREATE TABLE right (g UInt32, i UInt32);", "INSERT INTO right VALUES;", "select '::run';", "select g, i from left;", "select g, i from right;", "select g, i from right;", "select g, i from left;", "select g, count(*) from differences group by g;"]}
{"index": 3059, "a_db": "duckdb", "b_db": "sqlite", "molt": "norec", "sqls": ["create temp table asdf as (select 1);", "create table asdf (a int);", "insert into asdf values (2);", "select * from asdf;"]}
{"index": 3061, "a_db": "duckdb", "b_db": "sqlite", "molt": "error", "sqls": ["CREATE TABLE stops (;", "stop_id TEXT PRIMARY KEY,;", "parent_station TEXT,;", ");", "INSERT INTO stops;"]}
{"index": 3065, "a_db": "clickhouse", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE t0 (c0 Int) ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/t0');", "INSERT INTO TABLE FUNCTION icebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/t0', format = 'Avro', structure = 'c0 Int') (c0) VALUES (1);", "SELECT 1 FROM icebergLocal(local, structure = 'c0 Int', path = '/var/lib/clickhouse/user_files/lakehouses/t0') tx JOIN icebergLocal(local, structure = 'c0 Int', format = 'Avro', path = '/var/lib/clickhouse/user_files/lakehouses/t0') ty ON TRUE WHERE tx._row_number SETTINGS input_format_parquet_use_native_reader_v3 = 1, optimize_count_from_files = 0;", "CREATE TABLE t0 (c0 Int) ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/t0');", "INSERT INTO TABLE FUNCTION icebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/t0', format = 'Avro', structure = 'c0 Int') (c0) VALUES (1);", "SELECT 1 FROM icebergLocal(local, structure = 'c0 Int', path = '/var/lib/clickhouse/user_files/lakehouses/t0') tx JOIN icebergLocal(local, structure = 'c0 Int', format = 'Avro', path = '/var/lib/clickhouse/user_files/lakehouses/t0') ty ON TRUE WHERE tx._row_number SETTINGS input_format_parquet_use_native_reader_v3 = 1, optimize_count_from_files = 0;"]}
{"index": 3066, "a_db": "clickhouse", "b_db": "postgres", "molt": "pqs", "sqls": ["SELECT replaceRegexpOne(identity('abc123'), '^(abc)$', '\\\\1') GROUP BY 1,            toLowCardinality(9), 1 WITH CUBE SETTINGS group_by_use_nulls=1;"]}
{"index": 3071, "a_db": "duckdb", "b_db": "sqlite", "molt": "crash", "sqls": ["CREATE OR REPLACE PERSISTENT SECRET minio (TYPE s3, PROVIDER config, KEY_ID 'redacted', SECRET 'redacted');", "FROM read_json([;", "printf('https://community-extensions.duckdb.org/download-stats-weekly/2025-%s.json', x);", "FOR x IN ['09-22', '09-29'];", "]);", "DROP SECRET minio;"]}
{"index": 3073, "a_db": "duckdb", "b_db": "sqlite", "molt": "norec", "sqls": ["SELECT size, pg_size_pretty(size), pg_size_pretty(-1 * size) FROM;", "(VALUES (10::bigint), (1000::bigint), (1000000::bigint),;", "(1000000000::bigint), (1000000000000::bigint),;", "(1000000000000000::bigint)) x(size);", "SELECT size, pg_size_pretty(size), pg_size_pretty(-1 * size) FROM;", "(VALUES (10::bigint), (1000::bigint), (1000000::bigint),;", "(1000000000::bigint), (1000000000000::bigint),;", "(1000000000000000::bigint)) x(size);"]}
{"index": 3074, "a_db": "duckdb", "b_db": "sqlite", "molt": "error", "sqls": ["with stage as (;", "select;", "[1,2,3] as c1,;", "[4,5,6] as c2;", ");"]}
{"index": 3075, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["create table a(id int);", "insert into a values (1);", "alter table a add primary key(id);", "create table b(i int);", "insert into b values (1);", "sql>select * from sys.keys where startswith(name, 'a_') or startswith(name, 'b_');", "+---------+----------+------+-----------+---------+--------+-------+;", "| id      | table_id | type | name      | rkey    | action | check |;", "+=========+==========+======+===========+=========+========+=======+;", "| 3373818 |  3373817 |    0 | a_id_pkey |      -1 |     -1 | null  |;"]}
{"index": 3077, "a_db": "clickhouse", "b_db": "postgres", "molt": "error", "sqls": ["CREATE TABLE d0.`test.t41` ENGINE = IcebergS3(s3, url = 'http://minio:9000/warehouse-rest/t41', format = 'ORC') PARTITION BY (farmHash64(`c0`)) SETTINGS storage_catalog_type = 'rest', storage_warehouse = 'd0', object_storage_endpoint = 'http://minio:9000/warehouse-rest', storage_catalog_url = 'http://rest:8181/v1';", "CREATE TABLE d0.`test.t41` ENGINE = IcebergS3(s3, url = 'http://minio:9000/warehouse-rest/t41', format = 'ORC') PARTITION BY (farmHash64(`c0`)) SETTINGS storage_catalog_type = 'rest', storage_warehouse = 'd0', object_storage_endpoint = 'http://minio:9000/warehouse-rest', storage_catalog_url = 'http://rest:8181/v1';"]}
{"index": 3078, "a_db": "clickhouse", "b_db": "postgres", "molt": "pqs", "sqls": ["create table test.test.test_ch_cluster(;", "dataflow_dttm timestamp,;", "id integer;", ");", "insert into test.test.test_ch_cluster values;", "SELECT * FROM icebergS3Cluster(standard_cluster,  NAMED_COLLECTION , url='https://s3a', filename ='table');", "SELECT * FROM icebergS3(NAMED_COLLECTION , url='https://s3a', filename ='table');", "create table test.test.test_ch_cluster(;", "insert into test.test.test_ch_cluster values;", "update test.test.test_ch_cluster set dataflow_dttm = current_timestamp;"]}
{"index": 3079, "a_db": "clickhouse", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE t0 ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/t0/test/t0', format = 'Parquet') SETTINGS iceberg_use_version_hint = 1;", "ALTER TABLE t0 DROP COLUMN c1;", "CREATE TABLE t0 ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/t0/test/t0', format = 'Parquet') SETTINGS iceberg_use_version_hint = 1;", "ALTER TABLE t0 DROP COLUMN c1;"]}
{"index": 3090, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["create table count_case_crash(id int, key int);", "SELECT count(*),;"]}
{"index": 3091, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE table1(column1 INT, column2 INT);", "CREATE TRIGGER trigger6 AFTER UPDATE ON table1 REFERENCING OLD TABLE AS old_table NEW TABLE AS new_table FOR EACH STATEMENT SELECT * FROM sys.triggers;", "CREATE TABLE table1(column1 INT, column2 INT);", "CREATE TRIGGER trigger6 AFTER UPDATE ON table1 REFERENCING OLD TABLE AS old_table NEW TABLE AS new_table FOR EACH STATEMENT SELECT * FROM sys.triggers;"]}
{"index": 3092, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE table1(column1 INT, column2 INT);", "COPY SELECT * FROM table1 INTO BINARY '/x.bin';", "CREATE TABLE table1(column1 INT, column2 INT);"]}
{"index": 3093, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE table1(column1 INT, column2 INT);", "CREATE TABLE table2(column1 INT, column2 INT);", "CREATE TRIGGER trigger_truncate_conditional AFTER TRUNCATE ON table1 FOR EACH STATEMENT WHEN (EXISTS (SELECT 1 FROM table2)) CALL procedure2();", "CREATE TABLE table1(column1 INT, column2 INT);", "CREATE TABLE table2(column1 INT, column2 INT);", "CREATE TRIGGER trigger_truncate_conditional AFTER TRUNCATE ON table1 FOR EACH STATEMENT WHEN (EXISTS (SELECT 1 FROM table2)) CALL procedure2();"]}
{"index": 3094, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["MERGE INTO table1 T USING (SELECT column1, column2 FROM (SELECT column1, column2 FROM table2 UNION SELECT column1, column2 FROM view1)) AS S ON T.column1 = S.column1 WHEN MATCHED THEN UPDATE SET T.column2 = S.column2;"]}
{"index": 3096, "a_db": "clickhouse", "b_db": "postgres", "molt": "pqs", "sqls": ["CREATE TABLE t111111;"]}
{"index": 3102, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["SELECT acol1, acol2, SPLIT_PART(bcol4, '|', 4) as rate;", "FROM (;", "SELECT a.col1 as acol1,;", "a.col2 as acol2,;", "a.col3 as acol3,;", "SELECT acol1, acol2, SPLIT_PART(bcol4, '|', 4) as rate;"]}
{"index": 3103, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["CREATE USER \"bob\" WITH UNENCRYPTED PASSWORD 'bob' NAME 'Bob user' SCHEMA \"sys\";", "SET USER \"bob\";", "create role \"bob\";", "CREATE USER \"bob\" WITH UNENCRYPTED PASSWORD 'bob' NAME 'Bob user' SCHEMA \"sys\";", "create role \"bob\";"]}
{"index": 3104, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["CREATE TABLE IF NOT EXISTS t0(c0 INT);", "INSERT INTO t0(c0) VALUES(1);", "SELECT * FROM t0 WHERE NOT EXISTS (SELECT 1 FROM (VALUES (t0.c0)) WHERE (((SELECT FALSE FROM t0)) = FALSE) = TRUE);", "CREATE TABLE IF NOT EXISTS t0(c0 INT);", "INSERT INTO t0(c0) VALUES(1);", "SELECT * FROM t0 WHERE NOT EXISTS (SELECT 1 FROM (VALUES (t0.c0)) WHERE (((SELECT FALSE FROM t0)) = FALSE) = TRUE);", "CREATE TABLE IF NOT EXISTS t0(c0 INT);", "INSERT INTO t0(c0) VALUES(1);", "SELECT * FROM t0 WHERE NOT EXISTS (SELECT 1 FROM (VALUES (t0.c0)) WHERE (((SELECT FALSE FROM t0)) = FALSE) = TRUE);", "CREATE TABLE IF NOT EXISTS t0(c0 INT);"]}
{"index": 3105, "a_db": "clickhouse", "b_db": "postgres", "molt": "error", "sqls": ["SET input_format_parquet_use_native_reader_v3 = 1;", "CREATE TABLE t0 ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/t0/test/t0', format = 'Parquet');", "INSERT INTO TABLE t0 (c0) VALUES (TRUE);", "SELECT t0.c0 FROM t0 WHERE c0 = 3 AND c0 >= 5;", "CREATE TABLE t0 ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/t0/test/t0', format = 'Parquet');", "INSERT INTO TABLE t0 (c0) VALUES (TRUE);", "SELECT t0.c0 FROM t0 WHERE c0 = 3 AND c0 >= 5;"]}
{"index": 3106, "a_db": "clickhouse", "b_db": "postgres", "molt": "norec", "sqls": ["CREATE TABLE t0 (c0 Int) ENGINE = S3(s3, filename = 'file1.data', format = 'Avro');", "ALTER TABLE t0 ADD INDEX i0 c0 TYPE set(0);", "CREATE TABLE t0 (c0 Int) ENGINE = S3(s3, filename = 'file1.data', format = 'Avro');", "ALTER TABLE t0 ADD INDEX i0 c0 TYPE set(0);"]}
{"index": 3107, "a_db": "duckdb", "b_db": "sqlite", "molt": "norec", "sqls": ["select row('a', 5)::json;", "select row('a', 5)::json;"]}
{"index": 3108, "a_db": "duckdb", "b_db": "sqlite", "molt": "crash", "sqls": ["SELECT json_object(NULL, 'two') AS KEEP_NULL_2;", "SELECT TO_JSON({'key_1': 'one'}) AS WITHOUT_KEEP_NULL, JSON_OBJECT('key_1', 'one', 'key_2', NULL) AS KEEP_NULL_1, JSON_OBJECT('key_1', 'one', NULL, 'two') AS KEEP_NULL_2;"]}
{"index": 3109, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE t1(c0 INT);", "SELECT * FROM t1 LEFT JOIN (SELECT 1) ON EXISTS (SELECT (VALUES (1)));", "CREATE TABLE t1(c0 INT);", "SELECT * FROM t1 LEFT JOIN (SELECT 1) ON EXISTS (SELECT (VALUES (1)));", "CREATE TABLE t1(c0 INT);", "SELECT * FROM t1 LEFT JOIN (SELECT 1) ON EXISTS (SELECT (VALUES (1)));", "CREATE TABLE t1(c0 INT);", "SELECT * FROM t1 LEFT JOIN (SELECT 1) ON EXISTS (SELECT (VALUES (1)));"]}
{"index": 3110, "a_db": "monetdb", "b_db": "postgres", "molt": "error", "sqls": ["CREATE TABLE IF NOT EXISTS database0_t2(c2 STRING);", "SELECT * FROM database0_t2 JOIN (VALUES (INTERVAL '18115' MONTH)) ON (( (database0_t2.c2 NOT LIKE CAST(INTERVAL '20039' MONTH AS STRING(909))) OR (database0_t2.c2 LIKE database0_t2.c2) ));", "CREATE TABLE IF NOT EXISTS database0_t2(c2 STRING);", "SELECT * FROM database0_t2 JOIN (VALUES (INTERVAL '18115' MONTH)) ON (( (database0_t2.c2 NOT LIKE CAST(INTERVAL '20039' MONTH AS STRING(909))) OR (database0_t2.c2 LIKE database0_t2.c2) ));", "CREATE TABLE IF NOT EXISTS database0_t2(c2 STRING);", "SELECT * FROM database0_t2 JOIN (VALUES (INTERVAL '18115' MONTH)) ON (( (database0_t2.c2 NOT LIKE CAST(INTERVAL '20039' MONTH AS STRING(909))) OR (database0_t2.c2 LIKE database0_t2.c2) ));", "CREATE TABLE IF NOT EXISTS database0_t2(c2 STRING);", "SELECT * FROM database0_t2 JOIN (VALUES (INTERVAL '18115' MONTH)) ON (( (database0_t2.c2 NOT LIKE CAST(INTERVAL '20039' MONTH AS STRING(909))) OR (database0_t2.c2 LIKE database0_t2.c2) ));"]}
{"index": 3111, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE database0_t2(c0 DOUBLE);", "CREATE TABLE database0_t4(c0 DOUBLE);", "INSERT INTO database0_t2 VALUES(1.0);", "INSERT INTO database0_t4 VALUES(1.0);", "SELECT * FROM database0_t2 WHERE NOT EXISTS(SELECT 1 FROM database0_t4 WHERE (database0_t2.c0) IN (database0_t4.c0, database0_t2.c0));", "CREATE TABLE database0_t2(c0 DOUBLE);", "CREATE TABLE database0_t4(c0 DOUBLE);", "INSERT INTO database0_t2 VALUES(1.0);", "INSERT INTO database0_t4 VALUES(1.0);", "SELECT * FROM database0_t2 WHERE NOT EXISTS(SELECT 1 FROM database0_t4 WHERE (database0_t2.c0) IN (database0_t4.c0, database0_t2.c0));"]}
{"index": 3112, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["CREATE USER test WITH PASSWORD 'test' NAME 'test';", "CREATE USER alice WITH PASSWORD 'alice' NAME 'alice' SCHEMA sys;", "DROP ROLE alice;", "DROP USER alice;", "SQLException:sql.initClient:42000!The user was not found in the database, this session is going to terminate;", "sql> CREATE USER test WITH PASSWORD 'test' NAME 'test';", "operation successful;", "sql> CREATE USER alice WITH PASSWORD 'alice' NAME 'alice' SCHEMA sys;", "operation successful;", "sql> drop role alice;"]}
{"index": 3113, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["CREATE TABLE t0(c0 INT);", "CREATE TABLE t1(c0 TIMESTAMP );", "INSERT INTO t0(c0) VALUES(1);", "SELECT * FROM t0 RIGHT JOIN (VALUES(1)) ON ((SELECT t1.c0 FROM t1 WHERE t0.c0)) NOT IN (SQL_ADD(TIMESTAMP '2000-12-03', INTERVAL '1' SECOND));", "CREATE TABLE t0(c0 INT);", "CREATE TABLE t1(c0 TIMESTAMP );", "INSERT INTO t0(c0) VALUES(1);", "SELECT * FROM t0 RIGHT JOIN (VALUES(1)) ON ((SELECT t1.c0 FROM t1 WHERE t0.c0)) NOT IN (SQL_ADD(TIMESTAMP '2000-12-03', INTERVAL '1' SECOND));", "CREATE TABLE t0(c0 INT);", "CREATE TABLE t1(c0 TIMESTAMP );"]}
{"index": 3115, "a_db": "clickhouse", "b_db": "postgres", "molt": "norec", "sqls": ["CREATE TABLE t0 (c0 Int) ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/t0') SETTINGS iceberg_format_version = 1;", "INSERT INTO TABLE t0 (c0) VALUES (1);", "DELETE FROM t0 WHERE TRUE;", "DELETE FROM t0 WHERE TRUE;", "SELECT total_rows FROM system.tables WHERE database = 'default' AND table = 't0';", "CREATE TABLE t0 (c0 Int) ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/t0') SETTINGS iceberg_format_version = 1;", "INSERT INTO TABLE t0 (c0) VALUES (1);", "DELETE FROM t0 WHERE TRUE;", "DELETE FROM t0 WHERE TRUE;", "SELECT total_rows FROM system.tables WHERE database = 'default' AND table = 't0';"]}
{"index": 3116, "a_db": "clickhouse", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE t0 (c0 Int PRIMARY KEY) ENGINE = EmbeddedRocksDB();", "ALTER TABLE t0 MODIFY SETTING output_format_write_statistics = 0, zstd_window_log_max = 18446744073709551516;", "SYSTEM SHUTDOWN;", "/*;", "Cannot load data for command line suggestions: Code: 722. DB::Exception: Received from localhost:9000. DB::Exception: Waited job failed: Code: 696. DB::Exception: Load job 'startup table default.t0' -> Code: 695.;", "DB::Exception: Load job 'load table default.t0' failed: Code: 70.;", "DB::Exception: Field value 18446744073709551516 is out of range of long type:;", "Cannot attach table `default`.`t0` from metadata file store/a5f/a5f069db-e7dd-4da7-8449-e38984c34f9b/t0.sql from query ATTACH TABLE default.t0 UUID '80f3eab6-7e3c-42be-9ac1-21ad2042481e' (`c0` Int32);", "SYSTEM RELOAD CONFIG;", "CREATE TABLE t0 (c0 Int PRIMARY KEY) ENGINE = EmbeddedRocksDB();"]}
{"index": 3117, "a_db": "clickhouse", "b_db": "postgres", "molt": "norec", "sqls": ["CREATE TABLE source_table (`id` UInt32, `value` String) ENGINE = MergeTree ORDER BY id;", "CREATE TABLE alias_4__fuzz_45 (`id` Array(Int8), `value` Array(Array(UInt256)), `status` UInt32) ENGINE = Alias('source_table');", "INSERT INTO alias_4__fuzz_45 FORMAT Values (1, []);"]}
{"index": 3118, "a_db": "duckdb", "b_db": "sqlite", "molt": "pqs", "sqls": ["select accession, esm_embed;", "from (select accession, esm_embed from embeddings);", "limit 50 offset 110;", "select accession, esm_embed;", "from embeddings;", "where accession in (select accession from embeddings limit 50 offset 110);"]}
{"index": 3119, "a_db": "duckdb", "b_db": "sqlite", "molt": "crash", "sqls": ["FROM read_parquet('ducklake-0199c969-939e-7614-9a4e-7f9ff71064b9.txt');", "FROM read_parquet('ducklake-0199ca6e-e95d-77a0-b7f0-b89838f53744.txt');"]}
{"index": 3121, "a_db": "duckdb", "b_db": "sqlite", "molt": "error", "sqls": ["create or replace view test_malformed_json as;", "select * from '/workspaces/hosts_inventory.parquet';", "select;", "key,;", "unnest(;", "describe from test_malformed_json;", "describe from '/workspaces/hosts_inventory.parquet';"]}
{"index": 3122, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["CREATE USER test WITH PASSWORD 'test' NAME 'test';", "ALTER USER monetdb MAX_WORKERS 10;", "SET SESSION AUTHORIZATION monetdb;", "ALTER USER monetdb MAX_WORKERS 10;", "CREATE USER test WITH PASSWORD 'test' NAME 'test';", "ALTER USER monetdb MAX_WORKERS 10;"]}
{"index": 3123, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["CREATE USER test WITH PASSWORD 'test' NAME 'test';", "SET SCHEMA sys;", "CREATE TABLE x (y INT);", "ALTER USER test DEFAULT ROLE monetdb;", "SET SCHEMA sys;", "CREATE TABLE x (y INT);", "CREATE USER test WITH PASSWORD 'test' NAME 'test';", "CREATE TABLE x (y INT);", "ALTER USER test DEFAULT ROLE monetdb;", "CREATE TABLE x (y INT);"]}
{"index": 3124, "a_db": "clickhouse", "b_db": "postgres", "molt": "pqs", "sqls": ["CREATE TABLE t (val UInt8) ORDER BY (val);", "CREATE VIEW v AS SELECT val, val = 0 AS is_zero FROM t;", "INSERT INTO t VALUES (0);", "INSERT INTO t VALUES (1);", "INSERT INTO t VALUES (0), (2);", "CREATE TABLE t (val UInt8) ORDER BY (val);", "CREATE VIEW v AS SELECT val, val = 0 AS is_zero FROM t;", "INSERT INTO t VALUES (0);", "INSERT INTO t VALUES (1);", "INSERT INTO t VALUES (0), (2);"]}
{"index": 3125, "a_db": "clickhouse", "b_db": "postgres", "molt": "error", "sqls": ["CREATE TABLE t0 (c0 Int) ENGINE = MergeTree() ORDER BY (c0 DESC) SETTINGS index_granularity = 1, allow_experimental_reverse_key = 1;", "INSERT INTO TABLE t0 (c0) SELECT c0 FROM generateRandom('c0 Int', 7285072819366316109, 1, 1) LIMIT 10;", "SELECT 1 FROM t0 JOIN t0 tx USING (c0) SETTINGS query_plan_join_shard_by_pk_ranges = 1;", "CREATE TABLE t0 (c0 Int) ENGINE = MergeTree() ORDER BY (c0 DESC) SETTINGS index_granularity = 1, allow_experimental_reverse_key = 1;", "INSERT INTO TABLE t0 (c0) SELECT c0 FROM generateRandom('c0 Int', 7285072819366316109, 1, 1) LIMIT 10;", "SELECT 1 FROM t0 JOIN t0 tx USING (c0) SETTINGS query_plan_join_shard_by_pk_ranges = 1;"]}
{"index": 3126, "a_db": "clickhouse", "b_db": "postgres", "molt": "error", "sqls": ["CREATE OR REPLACE TABLE t0 (c0 UInt64) ENGINE = IcebergS3(s3, filename = 't11', format = 'Parquet') PARTITION BY tuple();", "DETACH TABLE t0 PERMANENTLY;", "SET input_format_parquet_use_native_reader_v3 = 1, output_format_parquet_row_group_size = 0;", "ATTACH TABLE t0;", "SET query_plan_enable_optimizations = 0;", "CREATE OR REPLACE TABLE t0 (c0 UInt64) ENGINE = IcebergS3(s3, filename = 't11', format = 'Parquet') PARTITION BY tuple();", "INSERT INTO TABLE t0 (c0) SELECT CAST(number AS UInt64) FROM numbers(924);", "INSERT INTO TABLE t0 (c0) SELECT c0 FROM generateRandom('c0 UInt64', 5445531875995920648, 701, 7) LIMIT 780;", "ALTER TABLE t0 (DELETE WHERE c0);"]}
{"index": 3127, "a_db": "clickhouse", "b_db": "postgres", "molt": "norec", "sqls": ["SET inject_random_order_for_select_without_order_by = 0;", "functional-tests :) EXPLAIN PLAN SELECT number;", "FROM system.numbers;", "LIMIT 1;", "┌─explain─────────────────────────────────────────────────────────────────────────────────┐;", "SET inject_random_order_for_select_without_order_by = 1;", "functional-tests :) EXPLAIN PLAN SELECT number;", "FROM system.numbers;", "LIMIT 1;", "└─────────────────────────────────────────────────────────────────────────────────────────────────┘;"]}
{"index": 3128, "a_db": "clickhouse", "b_db": "postgres", "molt": "error", "sqls": ["SELECT * FROM default.database_sample WHERE domain = '172.16.96.212:5432' ORDER BY timestamp DESC LIMIT 20;", "SELECT * FROM default.database_sample WHERE domain = '172.16.96.212:5432' LIMIT 10;", "SELECT * FROM default.database_sample WHERE domain = '172.16.96.212:5432' ORDER BY timestamp DESC LIMIT 10;", "SELECT * FROM default.database_sample WHERE domain = '172.16.96.212:5432' ORDER BY timestamp DESC LIMIT 20;", "SELECT * FROM default.database_sample WHERE domain = '172.16.96.212:5432' LIMIT 10;", "SELECT * FROM default.database_sample WHERE domain = '172.16.96.212:5432' ORDER BY timestamp DESC LIMIT 10;"]}
{"index": 3130, "a_db": "duckdb", "b_db": "sqlite", "molt": "crash", "sqls": ["set memory_limit = '6.4g';", "copy (;", "with;", "dates as (select unnest(generate_series(date '2010-01-01', date '2010-8-01', interval '1 day')) as day),;", "ids   as (select unnest(generate_series(1, 150_000)) as id);"]}
{"index": 3131, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE SCHEMA IF NOT EXISTS schema1;", "CREATE TABLE table1 (column1 NUMERIC(10, 2), column2 VARCHAR(100));", "CREATE INDEX index1 ON table1 (column1);", "ALTER TABLE table1 SET SCHEMA schema1;", "ALTER TABLE table1 SET ACCESS READ ONLY;", "CREATE SCHEMA IF NOT EXISTS schema1;", "CREATE TABLE table1 (column1 NUMERIC(10, 2), column2 VARCHAR(100));", "CREATE INDEX index1 ON table1 (column1);", "ALTER TABLE table1 SET SCHEMA schema1;", "ALTER TABLE table1 SET ACCESS READ ONLY;"]}
{"index": 3132, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE AGGREGATE function1() RETURNS bigint EXTERNAL NAME \"aggr\".\"count\";", "SELECT function1();", "CREATE AGGREGATE function1() RETURNS bigint EXTERNAL NAME \"aggr\".\"count\";", "SELECT function1();"]}
{"index": 3133, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE table1 (column1 INT);", "CREATE SCHEMA schema1;", "CREATE UNIQUE INDEX index1 ON table1(column1);", "ALTER TABLE table1 SET SCHEMA schema1;", "DROP INDEX index1;", "CREATE TABLE table1 (column1 INT);", "CREATE SCHEMA schema1;", "CREATE UNIQUE INDEX index1 ON table1(column1);", "ALTER TABLE table1 SET SCHEMA schema1;", "DROP INDEX index1;"]}
{"index": 3134, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE table1 (column1 INT, column2 BLOB);", "SELECT LAG(column2, 1, column2) OVER () FROM table1;", "CREATE TABLE table1 (column1 INT, column2 BLOB);", "SELECT LAG(column2, 1, column2) OVER () FROM table1;"]}
{"index": 3135, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE table1 (column1 STRING, column2 INT);", "CREATE MERGE TABLE table2 (column3 INT, column4 VARCHAR(100)) PARTITION BY VALUES USING (UPPER(column4));", "ALTER TABLE table2 SET TABLE table1 AS PARTITION IN (4, 5, 6);", "CREATE TABLE table1 (column1 STRING, column2 INT);", "CREATE MERGE TABLE table2 (column3 INT, column4 VARCHAR(100)) PARTITION BY VALUES USING (UPPER(column4));", "ALTER TABLE table2 SET TABLE table1 AS PARTITION IN (4, 5, 6);"]}
{"index": 3136, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["SET SESSION_USER = non_exist_user;", "CREATE REMOTE TABLE table1 (column1 INT, column2 VARCHAR(100)) ON 'mapi:monetdb://localhost:50000/monetdb';", "CREATE REMOTE TABLE table1 (column1 INT, column2 VARCHAR(100)) ON 'mapi:monetdb://localhost:50000/monetdb';"]}
{"index": 3137, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE table1 (column1 INT, column2 INT, CONSTRAINT constraint1 UNIQUE NULLS NOT DISTINCT (column1, column2));", "ALTER TABLE table1 DROP COLUMN column2 CASCADE;", "ALTER TABLE table1 DROP CONSTRAINT constraint1 CASCADE;", "CREATE TABLE table1 (column1 INT, column2 INT, CONSTRAINT constraint1 UNIQUE NULLS NOT DISTINCT (column1, column2));", "ALTER TABLE table1 DROP COLUMN column2 CASCADE;", "ALTER TABLE table1 DROP CONSTRAINT constraint1 CASCADE;"]}
{"index": 3138, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TEMP VIEW view1 AS SELECT 1;", "CREATE OR REPLACE VIEW view1 AS SELECT * FROM view1;", "SELECT * FROM view1;", "CREATE TEMP VIEW view1 AS SELECT 1;", "CREATE OR REPLACE VIEW view1 AS SELECT * FROM view1;", "SELECT * FROM view1;"]}
{"index": 3139, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["CREATE GLOBAL TEMPORARY TABLE table1 (column1 INT) ON COMMIT PRESERVE ROWS;", "ALTER TABLE table1 RENAME COLUMN column1 TO column2;", "CREATE GLOBAL TEMPORARY TABLE table1 (column1 INT) ON COMMIT PRESERVE ROWS;", "ALTER TABLE table1 RENAME COLUMN column1 TO column2;"]}
{"index": 3140, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE table1 (column1 INT, column2 VARCHAR(255));", "CREATE TABLE table2 (column1 INT, column2 VARCHAR(255));", "DROP TABLE table1;", "DROP TABLE table2;", "CREATE TABLE table1 (column1 INT, column2 VARCHAR(255));", "CREATE TABLE table1 (column1 INT, column2 VARCHAR(255));", "CREATE TABLE table2 (column1 INT, column2 VARCHAR(255));", "DROP TABLE table1;", "DROP TABLE table2;", "CREATE TABLE table1 (column1 INT, column2 VARCHAR(255));"]}
{"index": 3141, "a_db": "clickhouse", "b_db": "postgres", "molt": "crash", "sqls": ["create table test (x UInt64, y UInt64, a Array(UInt64)) engine=MergeTree order by x settings min_rows_for_wide_part=1, min_bytes_for_wide_part=1;", "insert into test select number, number, range(number) from numbers(10);", "select a, a.size0 from test where y > 5 order by y limit 2 settings send_logs_level='debug';", "create table test (x UInt64, y UInt64, a Array(UInt64)) engine=MergeTree order by x settings min_rows_for_wide_part=1, min_bytes_for_wide_part=1;", "insert into test select number, number, range(number) from numbers(10);", "select a, a.size0 from test where y > 5 order by y limit 2 settings send_logs_level='debug';"]}
{"index": 3142, "a_db": "clickhouse", "b_db": "postgres", "molt": "pqs", "sqls": ["create a table;", "CREATE TABLE default.t_proj_external;", "INSERT INTO t_proj_external SELECT 1, number%2, number%4, number FROM numbers(50000);", "SELECT k1, k2, k3, sum(value) v FROM t_proj_external GROUP BY k1, k2, k3 ORDER BY k1, k2, k3 SETTINGS optimize_aggregation_in_order = 0, max_bytes_before_external_group_by = 1, max_bytes_ratio_before_external_group_by = 0, group_by_two_level_threshold = 1;"]}
{"index": 3143, "a_db": "clickhouse", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE t ORDER BY a AS SELECT 1 AS a;", "CREATE MATERIALIZED VIEW mv REFRESH EVERY 1 YEAR ENGINE = MergeTree ORDER BY b AS SELECT sleep(3) AS b FROM t;", "CREATE TABLE t ORDER BY a AS SELECT 1 AS a;", "CREATE MATERIALIZED VIEW mv REFRESH EVERY 1 YEAR ENGINE = MergeTree ORDER BY b AS SELECT sleep(3) AS b FROM t;"]}
{"index": 3146, "a_db": "duckdb", "b_db": "sqlite", "molt": "pqs", "sqls": ["INSTALL SPATIAL;", "LOAD SPATIAL;", "COPY (;", "SELECT * FROM (;", "SELECT;"]}
{"index": 3149, "a_db": "clickhouse", "b_db": "postgres", "molt": "error", "sqls": ["CREATE OR REPLACE TABLE t0 (c0 Bool) ENGINE = MergeTree() ORDER BY tuple();", "INSERT INTO TABLE t0 (c0) VALUES (FALSE);", "ALTER TABLE t0 ADD CONSTRAINT c0 CHECK c0;", "INSERT INTO TABLE FUNCTION url('http://localhost:8123/?query=INSERT+INTO+t0+(c0)+FORMAT+CSV', 'CSV', 'c0 Bool') VALUES (FALSE);", "CREATE OR REPLACE TABLE t0 (c0 Bool) ENGINE = MergeTree() ORDER BY tuple();", "INSERT INTO TABLE t0 (c0) VALUES (FALSE);", "ALTER TABLE t0 ADD CONSTRAINT c0 CHECK c0;", "INSERT INTO TABLE FUNCTION url('http://localhost:8123/?query=INSERT+INTO+t0+(c0)+FORMAT+CSV', 'CSV', 'c0 Bool') VALUES (FALSE);"]}
{"index": 3151, "a_db": "clickhouse", "b_db": "postgres", "molt": "error", "sqls": ["CREATE TABLE t0 (c0 String) ENGINE = ReplacingMergeTree() PRIMARY KEY tuple() SETTINGS min_bytes_for_wide_part = 0, vertical_merge_algorithm_min_bytes_to_activate = 1, vertical_merge_algorithm_min_rows_to_activate = 0, index_granularity = 1, vertical_merge_algorithm_min_columns_to_activate = 1;", "INSERT INTO TABLE t0 (c0) SELECT c0 FROM generateRandom('c0 String', 11534244747785854120, 6119, 2) LIMIT 679;", "INSERT INTO TABLE t0 (c0) SELECT 'need' FROM numbers(522);", "INSERT INTO TABLE t0 (c0) SELECT c0 FROM generateRandom('c0 String', 17010632438609867543, 501, 10) LIMIT 972;", "INSERT INTO TABLE t0 (c0) SELECT '.' FROM numbers(878);", "CREATE TABLE t0 (c0 String) ENGINE = ReplacingMergeTree() PRIMARY KEY tuple() SETTINGS min_bytes_for_wide_part = 0, vertical_merge_algorithm_min_bytes_to_activate = 1, vertical_merge_algorithm_min_rows_to_activate = 0, index_granularity = 1, vertical_merge_algorithm_min_columns_to_activate = 1;", "INSERT INTO TABLE t0 (c0) SELECT c0 FROM generateRandom('c0 String', 11534244747785854120, 6119, 2) LIMIT 679;", "INSERT INTO TABLE t0 (c0) SELECT 'need' FROM numbers(522);", "INSERT INTO TABLE t0 (c0) SELECT c0 FROM generateRandom('c0 String', 17010632438609867543, 501, 10) LIMIT 972;", "INSERT INTO TABLE t0 (c0) SELECT '.' FROM numbers(878);"]}
{"index": 3156, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["CREATE TABLE t0(c2 INT );", "INSERT INTO t0(c2) VALUES(NULL);", "SELECT * FROM t0 INNER JOIN LATERAL (SELECT t0.c2) AS subQuery0(c0) ON NOT EXISTS (VALUES (1), (subQuery0.c0));", "CREATE TABLE t0(c2 INT );", "INSERT INTO t0(c2) VALUES(NULL);", "SELECT * FROM t0 INNER JOIN LATERAL (SELECT t0.c2) AS subQuery0(c0) ON NOT EXISTS (VALUES (1), (subQuery0.c0));", "CREATE TABLE t0(c2 INT );", "INSERT INTO t0(c2) VALUES(NULL);", "SELECT * FROM t0 INNER JOIN LATERAL (SELECT t0.c2) AS subQuery0(c0) ON NOT EXISTS (VALUES (1), (subQuery0.c0));", "CREATE TABLE t0(c2 INT );"]}
{"index": 3157, "a_db": "clickhouse", "b_db": "postgres", "molt": "error", "sqls": ["CREATE VIEW v0 AS (SELECT EXISTS (SELECT 1) c0);", "SELECT c0 FROM remote('localhost', 'default', 'v0') tx SETTINGS prefer_localhost_replica = 0;", "CREATE VIEW v0 AS (SELECT EXISTS (SELECT 1) c0);", "SELECT c0 FROM remote('localhost', 'default', 'v0') tx SETTINGS prefer_localhost_replica = 0;"]}
{"index": 3160, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE \"sys\".\"emp\" (;"]}
{"index": 3161, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["CREATE TABLE IF NOT EXISTS t0(c0 INT);", "CREATE TABLE t1(LIKE t0);", "INSERT INTO t0 VALUES(1);", "INSERT INTO t1 VALUES(1);", "SELECT *;", "CREATE TABLE IF NOT EXISTS t0(c0 INT);", "CREATE TABLE t1(LIKE t0);", "INSERT INTO t0 VALUES(1);", "INSERT INTO t1 VALUES(1);"]}
{"index": 3162, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE t0(c0 INT);", "SELECT * FROM t0 LEFT JOIN (VALUES (1)) ON EXISTS (SELECT ALL * FROM t0);", "CREATE TABLE t0(c0 INT);", "SELECT * FROM t0 LEFT JOIN (VALUES (1)) ON EXISTS (SELECT ALL * FROM t0);"]}
{"index": 3163, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["CREATE TABLE t1(c0 boolean);", "SELECT * FROM t1 WHERE (((SELECT listagg('1') WHERE t1.c0)));", "CREATE TABLE t1(c0 boolean);", "SELECT * FROM t1 WHERE (((SELECT listagg('1') WHERE t1.c0)));", "CREATE TABLE t1(c0 boolean);", "SELECT * FROM t1 WHERE (((SELECT listagg('1') WHERE t1.c0)));", "CREATE TABLE t1(c0 boolean);", "SELECT * FROM t1 WHERE (((SELECT listagg('1') WHERE t1.c0)));"]}
{"index": 3164, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["SELECT (COALESCE(((VALUES (1)))));", "SELECT (COALESCE(((VALUES (1)))));", "SELECT (COALESCE(((VALUES (1)))));", "SELECT (COALESCE(((VALUES (1)))));"]}
{"index": 3165, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE char_test_long (id INT, name CHAR(2147483647));", "INSERT INTO char_test_long VALUES (1, RPAD('X', 2147483647, ' '));", "CREATE TABLE char_test_long (id INT, name CHAR(2147483647));", "INSERT INTO char_test_long VALUES (1, RPAD('X', 2147483647, ' '));", "CREATE TABLE char_test_long (id INT, name CHAR(2147483647));", "INSERT INTO char_test_long VALUES (1, RPAD('X', 2147483647, ' '));", "CREATE TABLE char_test_long (id INT, name CHAR(2147483647));", "INSERT INTO char_test_long VALUES (1, RPAD('X', 2147483647, ' '));"]}
{"index": 3166, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE test_fields (id INT, name VARCHAR(50));", "INSERT INTO test_fields VALUES (1, 'foo'), (2, 'bar'), (3, 'baz'), (4, 'qux');", "SELECT field('bar', (SELECT name FROM test_fields WHERE id = 2)) AS index_in_subquery;", "CREATE TABLE test_fields (id INT, name VARCHAR(50));", "INSERT INTO test_fields VALUES (1, 'foo'), (2, 'bar'), (3, 'baz'), (4, 'qux');", "SELECT field('bar', (SELECT name FROM test_fields WHERE id = 2)) AS index_in_subquery;"]}
{"index": 3167, "a_db": "clickhouse", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE testa (;", "x UInt32,;", "y UInt32;", ") ENGINE = MergeTree ORDER BY x;", "INSERT INTO testa  (x, y) SELECT (number + 1) AS x, (x % 1000) AS y FROM numbers(9999);", "CREATE TABLE testa (;", "INSERT INTO testa  (x, y) SELECT (number + 1) AS x, (x % 1000) AS y FROM numbers(9999);", "alter table testa MODIFY SETTING enable_block_offset_column = 1;", "alter table testa MODIFY SETTING enable_block_number_column = 1;", "alter table testa add column z UInt32 default 0 after y;"]}
{"index": 3168, "a_db": "clickhouse", "b_db": "postgres", "molt": "error", "sqls": ["CREATE TABLE t0 ON CLUSTER 'cluster0' (c0 Int) ENGINE = DeltaLakeLocal(local, format = 'Parquet', path = '/var/lib/clickhouse/user_files/spark_catalog/test/t0');", "ALTER TABLE t0 ON CLUSTER 'cluster0' MATERIALIZE COLUMN c0;", "CREATE TABLE t0 ON CLUSTER 'cluster0' (c0 Int) ENGINE = DeltaLakeLocal(local, format = 'Parquet', path = '/var/lib/clickhouse/user_files/spark_catalog/test/t0');", "ALTER TABLE t0 ON CLUSTER 'cluster0' MATERIALIZE COLUMN c0;"]}
{"index": 3169, "a_db": "duckdb", "b_db": "sqlite", "molt": "error", "sqls": ["CREATE OR REPLACE TEMPORARY MACRO cin() AS TABLE FROM read_csv('/dev/stdin');"]}
{"index": 3170, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE t0(c0 INT);", "CREATE TABLE t1(c0 INT);", "INSERT INTO t0 VALUES(0);", "INSERT INTO t1 VALUES(1);", "SELECT *;", "CREATE TABLE t0(c0 INT);", "CREATE TABLE t1(c0 INT);", "INSERT INTO t0 VALUES(0);", "INSERT INTO t1 VALUES(1);"]}
{"index": 3171, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE t0(c0 INT);", "INSERT INTO t0 VALUES (1);", "SELECT * FROM t0 INNER JOIN (SELECT (1 = ANY(VALUES (1)))) AS sub ON TRUE;", "SELECT * FROM t0 INNER JOIN (SELECT (1 = ANY(VALUES (1)) = TRUE)) AS sub ON TRUE;", "CREATE TABLE t0(c0 INT);", "INSERT INTO t0 VALUES (1);", "SELECT * FROM t0 INNER JOIN (SELECT (1 = ANY(VALUES (1)))) AS sub ON TRUE;", "SELECT * FROM t0 INNER JOIN (SELECT (1 = ANY(VALUES (1)) = TRUE)) AS sub ON TRUE;"]}
{"index": 3172, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE t0(c0 INT);", "INSERT INTO t0 VALUES (1);", "SELECT * FROM t0,(SELECT 1);", "SELECT * FROM t0 CROSS JOIN (SELECT 1);", "CREATE TABLE t0(c0 INT);", "INSERT INTO t0 VALUES (1);", "SELECT * FROM t0,(SELECT 1);", "SELECT * FROM t0 CROSS JOIN (SELECT 1);"]}
{"index": 3173, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE IF NOT EXISTS t1(c0 INTERVAL DAY,c2 DOUBLE);", "SELECT ALL * FROM t1 RIGHT JOIN (VALUES (0)) AS subQuery1(col_1) ON ( t1.c0 < ANY(VALUES (t1.c0+t1.c0)) ) AND (VALUES (subQuery1.col_1), (EXISTS (VALUES (t1.c2))) );", "CREATE TABLE IF NOT EXISTS t1(c0 INTERVAL DAY,c2 DOUBLE);", "SELECT ALL * FROM t1 RIGHT JOIN (VALUES (0)) AS subQuery1(col_1) ON ( t1.c0 < ANY(VALUES (t1.c0+t1.c0)) ) AND (VALUES (subQuery1.col_1), (EXISTS (VALUES (t1.c2))) );", "CREATE TABLE IF NOT EXISTS t1(c0 INTERVAL DAY,c2 DOUBLE);", "SELECT ALL * FROM t1 RIGHT JOIN (VALUES (0)) AS subQuery1(col_1) ON ( t1.c0 < ANY(VALUES (t1.c0+t1.c0)) ) AND (VALUES (subQuery1.col_1), (EXISTS (VALUES (t1.c2))) );", "CREATE TABLE IF NOT EXISTS t1(c0 INTERVAL DAY,c2 DOUBLE);", "SELECT ALL * FROM t1 RIGHT JOIN (VALUES (0)) AS subQuery1(col_1) ON ( t1.c0 < ANY(VALUES (t1.c0+t1.c0)) ) AND (VALUES (subQuery1.col_1), (EXISTS (VALUES (t1.c2))) );"]}
{"index": 3174, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE IF NOT EXISTS t1(c0 DOUBLE );", "CREATE TABLE IF NOT EXISTS t2(c0 DOUBLE );", "SELECT * FROM t1 INNER JOIN t2 ON (NOT EXISTS (VALUES (((t1.c0)+(t2.c0))))) IS NULL;", "CREATE TABLE IF NOT EXISTS t1(c0 DOUBLE );", "CREATE TABLE IF NOT EXISTS t2(c0 DOUBLE );", "SELECT * FROM t1 INNER JOIN t2 ON (NOT EXISTS (VALUES (((t1.c0)+(t2.c0))))) IS NULL;", "CREATE TABLE IF NOT EXISTS t1(c0 DOUBLE );", "CREATE TABLE IF NOT EXISTS t2(c0 DOUBLE );", "SELECT * FROM t1 INNER JOIN t2 ON (NOT EXISTS (VALUES (((t1.c0)+(t2.c0))))) IS NULL;", "CREATE TABLE IF NOT EXISTS t1(c0 DOUBLE );"]}
{"index": 3175, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE IF NOT EXISTS t0(c0 INT);", "SELECT *;", "FROM t0;", "RIGHT JOIN (VALUES (1)) AS subQuery1(col_1) ON EXISTS (VALUES (CASE subQuery1.col_1 WHEN subQuery1.col_1 THEN 1 END));", "CREATE TABLE IF NOT EXISTS t0(c0 INT);", "SELECT *;", "FROM t0;", "RIGHT JOIN (VALUES (1)) AS subQuery1(col_1) ON EXISTS (VALUES (CASE subQuery1.col_1 WHEN subQuery1.col_1 THEN 1 END));", "CREATE TABLE IF NOT EXISTS t0(c0 INT);", "CREATE TABLE IF NOT EXISTS t0(c0 INT);"]}
{"index": 3176, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE v0 ( v1 INT , v2 VARCHAR ( 37 ) NOT NULL CHECK ( CAST ( DENSE_RANK ( v1 ) OVER ( PARTITION BY ( CASE WHEN v2 > 8 THEN 'x' ELSE 'x' END ) ORDER BY v2 ) AS INTEGER ) ) );", "CREATE TABLE v0 ( v1 INT , v2 VARCHAR ( 37 ) NOT NULL CHECK ( CAST ( count ( v1 ) OVER ( PARTITION BY ( CASE WHEN v2 > 8 THEN 'x' ELSE 'x' END ) ORDER BY v2 ) AS INTEGER ) ) );", "CREATE TABLE v0 ( v1 INT , v2 VARCHAR ( 37 ) NOT NULL CHECK ( CAST ( DENSE_RANK ( v1 ) OVER ( PARTITION BY ( CASE WHEN v2 > 8 THEN 'x' ELSE 'x' END ) ORDER BY v2 ) AS INTEGER ) ) );", "CREATE TABLE v0 ( v1 INT , v2 VARCHAR ( 37 ) NOT NULL CHECK ( CAST ( count ( v1 ) OVER ( PARTITION BY ( CASE WHEN v2 > 8 THEN 'x' ELSE 'x' END ) ORDER BY v2 ) AS INTEGER ) ) );", "CREATE TABLE v0 ( v1 INT , v2 VARCHAR ( 37 ) NOT NULL CHECK ( CAST ( DENSE_RANK ( v1 ) OVER ( PARTITION BY ( CASE WHEN v2 > 8 THEN 'x' ELSE 'x' END ) ORDER BY v2 ) AS INTEGER ) ) );", "CREATE TABLE v0 ( v1 INT , v2 VARCHAR ( 37 ) NOT NULL CHECK ( CAST ( count ( v1 ) OVER ( PARTITION BY ( CASE WHEN v2 > 8 THEN 'x' ELSE 'x' END ) ORDER BY v2 ) AS INTEGER ) ) );", "CREATE TABLE v0 ( v1 INT , v2 VARCHAR ( 37 ) NOT NULL CHECK ( CAST ( DENSE_RANK ( v1 ) OVER ( PARTITION BY ( CASE WHEN v2 > 8 THEN 'x' ELSE 'x' END ) ORDER BY v2 ) AS INTEGER ) ) );", "CREATE TABLE v0 ( v1 INT , v2 VARCHAR ( 37 ) NOT NULL CHECK ( CAST ( count ( v1 ) OVER ( PARTITION BY ( CASE WHEN v2 > 8 THEN 'x' ELSE 'x' END ) ORDER BY v2 ) AS INTEGER ) ) );"]}
{"index": 3177, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE v0 ( v1 FLOAT );", "SELECT count ( * ) FROM v0 GROUP BY v1 + 1 , v1;", "CREATE TABLE v0 ( v1 FLOAT );", "SELECT count ( * ) FROM v0 GROUP BY v1 + 1 , v1;", "CREATE TABLE v0 ( v1 FLOAT );", "SELECT count ( * ) FROM v0 GROUP BY v1 + 1 , v1;", "CREATE TABLE v0 ( v1 FLOAT );", "SELECT count ( * ) FROM v0 GROUP BY v1 + 1 , v1;"]}
{"index": 3178, "a_db": "clickhouse", "b_db": "postgres", "molt": "error", "sqls": ["CREATE TABLE ttl_group_by__fuzz_13;", "INSERT INTO ttl_group_by__fuzz_13 SELECT toDate('2000-10-10'), number, number FROM numbers(100);", "INSERT INTO ttl_group_by__fuzz_13 SELECT toDate('1970-10-10'), number, number FROM numbers(100);"]}
{"index": 3179, "a_db": "clickhouse", "b_db": "postgres", "molt": "error", "sqls": ["CREATE TABLE t0 ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/t0/test/t0', format = 'ORC');", "SELECT c0 FROM t0;", "With the [spark.py](https://github.com/user-attachments/files/22426375/spark.py) script, run `python spark.py create`. Then, in ClickHouse load the table:;", "CREATE TABLE t0 ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/t0/test/t0', format = 'ORC');", "SELECT c0 FROM t0;"]}
{"index": 3180, "a_db": "clickhouse", "b_db": "postgres", "molt": "error", "sqls": ["CREATE TABLE t0 ENGINE = DeltaLakeLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/spark_catalog/test/t0', format = 'Parquet');", "SELECT c1.values FROM t0;", "CREATE TABLE t0 ENGINE = DeltaLakeLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/spark_catalog/test/t0', format = 'Parquet');", "SELECT c1.values FROM t0;"]}
{"index": 3181, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["CREATE TABLE x (a1 INTEGER, a2 INTEGER, a3 CHARACTER LARGE OBJECT, a4 CHARACTER LARGE OBJECT, p DOUBLE);", "CREATE TABLE y (a1 INTEGER, p DOUBLE);"]}
{"index": 3182, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["CREATE OR REPLACE FILTER FUNCTION maxlevhelper(a1 INTEGER, a2 INTEGER, a3 INTEGER, a4 INTEGER, a5 DOUBLE) EXTERNAL NAME txtsim.maxlevenshtein;", "CREATE TABLE x1 (a1 INTEGER, a2 INTEGER, p DOUBLE);", "CREATE TABLE x2 (a1 INTEGER, a2 INTEGER, p DOUBLE);", "CREATE TABLE x3 (a1 INTEGER, a2 INTEGER, p DOUBLE);", "CREATE TABLE x4 (a1 INTEGER, a2 INTEGER, a3 DOUBLE, p DOUBLE);", "CREATE VIEW x5 AS SELECT x4.a1 AS a1, x4.a2 as a2, x4.a3 as a3, x4.p as p from x4, (select case when a1 = a2 then 1 else 0 end as a1, 1.0e0 as p from (select foox0.a1 as a1, foox1.a1 as a2, foox0.p * foox1.p as p from (select count(a1) as a1, max(p) as p from x3) as foox0, (select count(a1) as a1, max(p) as p from x4) as foox1) as foox2) as foox3 where foox3.a1 = 1;", "CREATE VIEW result AS SELECT x1.a1 AS a1, x1.a2 AS a2, x5.a1 AS a3, x5.a2 AS a4, x5.a3 AS a5, x1.p * x5.p as p from x1, x5 where [x1.a1,x1.a2] maxlevhelper [x5.a1,x5.a2,x5.a3];"]}
{"index": 3183, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["CREATE OR REPLACE FILTER FUNCTION maxlev_helper(a1 INTEGER, a2 INTEGER, a3 INTEGER, a4 INTEGER, a5 DOUBLE) EXTERNAL NAME txtsim.maxlevenshtein;", "CREATE TABLE t1 (a1 INTEGER, a2 INTEGER, p DOUBLE);", "CREATE TABLE t2 (a1 INTEGER, p DOUBLE);", "CREATE TABLE t3 (a1 INTEGER, a2 INTEGER, p DOUBLE);", "CREATE VIEW t4 AS SELECT t3.a1 AS a1, t3.a2 AS a2, t2.p AS a3, t2.p AS p FROM t3, t2 WHERE t3.a2 = t2.a1;", "SELECT COUNT(*);"]}
{"index": 3184, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["create table a (i int, j int);", "insert into a values(0, 1), (2, 4);", "select * from (select cast(null as int), 0 ) b(i,j) where not exists (select 1 from a where a.i = b.i and a.j = b.j);"]}
{"index": 3185, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["CREATE TABLE IF NOT EXISTS t0(c0 INT);", "INSERT INTO t0(c0) VALUES(1);", "SELECT t0.c0 FROM t0 WHERE NOT EXISTS (SELECT 1 FROM (VALUES (1)) AS subQuery0(c0) WHERE substr(r'1', 2) NOT LIKE (CASE t0.c0 WHEN subQuery0.c0 THEN 1 ELSE 0 END));", "CREATE TABLE IF NOT EXISTS t0(c0 INT);", "INSERT INTO t0(c0) VALUES(1);", "SELECT t0.c0 FROM t0 WHERE NOT EXISTS (SELECT 1 FROM (VALUES (1)) AS subQuery0(c0) WHERE substr(r'1', 2) NOT LIKE (CASE t0.c0 WHEN subQuery0.c0 THEN 1 ELSE 0 END));", "CREATE TABLE IF NOT EXISTS t0(c0 INT);", "INSERT INTO t0(c0) VALUES(1);", "SELECT t0.c0 FROM t0 WHERE NOT EXISTS (SELECT 1 FROM (VALUES (1)) AS subQuery0(c0) WHERE substr(r'1', 2) NOT LIKE (CASE t0.c0 WHEN subQuery0.c0 THEN 1 ELSE 0 END));", "CREATE TABLE IF NOT EXISTS t0(c0 INT);"]}
{"index": 3186, "a_db": "clickhouse", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE DATABASE datalake;", "ENGINE = DataLakeCatalog('http://ice-rest-catalog:5000', admin, password);", "SETTINGS storage_endpoint = 'http://minio:9000/warehouse', warehouse = 'd';", "SHOW TABLES FROM datalake;"]}
{"index": 3187, "a_db": "duckdb", "b_db": "sqlite", "molt": "crash", "sqls": ["create or replace table aaa (id int, status varchar, flag int, starttime datetime, endtime datetime);", "merge into aaa;", "using (;", "select \t1 as id, 'xx' as status, 1 as flag, now() as starttime, null as endtime;", ") as upserts;"]}
{"index": 3189, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE v0 ( v1 INT , v2 VARCHAR ( 255 ) );", "INSERT INTO v0 VALUES ( 6249863.000000 , 34483237.000000 );", "INSERT INTO v0 VALUES ( 6314442.000000 , 45506563.000000 );", "INSERT INTO v0 VALUES ( NULL , 26065318.000000 );", "INSERT INTO v0 VALUES ( 58834911.000000 , NULL );", "INSERT INTO v0 VALUES ( NULL , NULL );", "SELECT DISTINCT 75472850.000000 * v1 , v1 + v1 FROM v0;", "SELECT ROW_NUMBER ( JSON_ARRAYAGG ( v1 , v2 ) , -1 ) FROM v0;", "SELECT FIRST_VALUE ( 27113735.000000 , AVG ( 85800881.000000 , 31070441.000000 ) ) AS v3 FROM v0;", "SELECT v2 , JSON_ARRAYAGG ( v1 , v1 ) AS v4 FROM v0 GROUP BY v1;"]}
{"index": 3190, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE v0 ( v1 INT , v2 VARCHAR ( 4 ) );", "INSERT INTO v0 DEFAULT VALUES;", "INSERT INTO v0 VALUES ( 7 , 'x' );", "INSERT INTO v0 VALUES ( 18 , 'x' );", "INSERT INTO v0 VALUES ( 90 , NULL );", "UPDATE v0 SET ( v2 , v1 ) = ( SELECT v1 + 90 , v1 FROM v0 );", "SELECT MAX ( v1 ) FROM v0 WHERE v2 = 255;", "SELECT COUNT ( v2 ) FROM v0 WHERE v1 IS NOT NULL;", "CREATE TABLE v3 ( v4 INT , v5 VARCHAR ( -128 ) );", "INSERT INTO v0 VALUES ( 44 , 'x' );"]}
{"index": 3191, "a_db": "duckdb", "b_db": "sqlite", "molt": "crash", "sqls": ["select * from client_asset_dsmock_gj_client_asset_networkcard;"]}
{"index": 3192, "a_db": "duckdb", "b_db": "sqlite", "molt": "norec", "sqls": ["SELECT round_even(4.025::NUMERIC, 2);", "select roundBankers(cast(4.025 as decimal(4, 3)), 2);", "select roundBankers(4.025, 2);"]}
{"index": 3193, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["select cast(99999999909999999990999999999012345678.0 as decimal(38,0)) as val1, cast(-99999999909999999990999999999012345678.0 as decimal(38,0)) as val2;", "select cast(0.99999999909999999990999999999012345678 as decimal(38,38)) as val1, cast(-0.99999999909999999990999999999012345678 as decimal(38,38)) as val2;", "select cast(99999999909999999990999999999012345678.0 as decimal(38,0)) as val1, cast(-99999999909999999990999999999012345678.0 as decimal(38,0)) as val2;", "select cast(0.99999999909999999990999999999012345678 as decimal(38,38)) as val1, cast(-0.99999999909999999990999999999012345678 as decimal(38,38)) as val2;"]}
{"index": 3194, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["create table test(name string, inserted timestamp);", "insert into test values('qqq', '1970-01-01');", "select;", "timestamp_to_str(inserted, '%Y-%m-%d'),;", "(select 1);", "from test;", "order by 1;", "Create a table:;", "create table test(name string, inserted timestamp);", "Insert a row (not necessary, just for clarity):;"]}
{"index": 3195, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["CREATE TABLE t0(c0 INT);", "INSERT INTO t0(c0) VALUES(1);", "SELECT * FROM t0 WHERE NOT EXISTS (SELECT 1 FROM (VALUES (t0.c0)) AS subQuery0(c0) WHERE NULL);", "CREATE TABLE t0(c0 INT);", "INSERT INTO t0(c0) VALUES(1);", "SELECT * FROM t0 WHERE NOT EXISTS (SELECT 1 FROM (VALUES (t0.c0)) AS subQuery0(c0) WHERE NULL);", "CREATE TABLE t0(c0 INT);", "INSERT INTO t0(c0) VALUES(1);", "SELECT * FROM t0 WHERE NOT EXISTS (SELECT 1 FROM (VALUES (t0.c0)) AS subQuery0(c0) WHERE NULL);", "CREATE TABLE t0(c0 INT);"]}
{"index": 3196, "a_db": "clickhouse", "b_db": "postgres", "molt": "error", "sqls": ["CREATE TABLE t0 ENGINE = IcebergS3(s3, filename = 't0/test/t0', format = 'Parquet');", "INSERT INTO TABLE t0 (c0) SETTINGS write_full_path_in_iceberg_metadata = 1 VALUES (1);", "INSERT INTO TABLE t0 (c0) VALUES (2);", "CREATE TABLE t0 ENGINE = IcebergS3(s3, filename = 't0/test/t0', format = 'Parquet');", "INSERT INTO TABLE t0 (c0) SETTINGS write_full_path_in_iceberg_metadata = 1 VALUES (1);", "INSERT INTO TABLE t0 (c0) VALUES (2);"]}
{"index": 3197, "a_db": "clickhouse", "b_db": "postgres", "molt": "pqs", "sqls": ["DESCRIBE TABLE file('int32_decimal_1.parquet');", "FORMAT TabSeparated;", "SETTINGS input_format_parquet_use_native_reader_v3 = 0;", "value\tNullable(Decimal(4, 2));", "DESCRIBE TABLE file('int32_decimal_1.parquet');", "FORMAT TabSeparated;", "SETTINGS input_format_parquet_use_native_reader_v3 = 1;", "value\tNullable(Decimal(9, 2));"]}
{"index": 3199, "a_db": "clickhouse", "b_db": "postgres", "molt": "pqs", "sqls": ["CREATE TABLE default.t0 ON CLUSTER '{cluster}' (;", "CREATE TABLE default.t0_d ON CLUSTER '{cluster}';", "CREATE DICTIONARY default.d0 ON CLUSTER '{cluster}' (;", "SELECT toUInt8(1) AS id, ''alpha'' AS d;", "SELECT toUInt8(2) AS id, ''beta'' AS d;", "INSERT INTO default.t0_d (id, c) VALUES;", "SELECT * FROM default.t0_d;"]}
{"index": 3200, "a_db": "clickhouse", "b_db": "postgres", "molt": "error", "sqls": ["CREATE TABLE t0 (c0 Nested(c1 Int32)) ENGINE = DeltaLakeLocal(local, format = 'Parquet', path = '/var/lib/clickhouse/user_files/lakehouses/spark_catalog/test/t0');", "INSERT INTO TABLE t0 (c0.c1) SELECT c1 FROM generateRandom('c1 Array(Int32)', 1804311225537264571, 1, 9) LIMIT 1;", "Create the table with [spark.py](https://github.com/user-attachments/files/22467906/spark.py). Then in ClickHouse run:;", "CREATE TABLE t0 (c0 Nested(c1 Int32)) ENGINE = DeltaLakeLocal(local, format = 'Parquet', path = '/var/lib/clickhouse/user_files/lakehouses/spark_catalog/test/t0');", "INSERT INTO TABLE t0 (c0.c1) SELECT c1 FROM generateRandom('c1 Array(Int32)', 1804311225537264571, 1, 9) LIMIT 1;"]}
{"index": 3201, "a_db": "clickhouse", "b_db": "postgres", "molt": "pqs", "sqls": ["DROP TABLE IF EXISTS b_customers;", "CREATE TABLE b_customers (customer_id Int64, first_order_id Int64) ENGINE = MergeTree ORDER BY customer_id;", "INSERT INTO b_customers SELECT number, number * 20000000 FROM system.numbers LIMIT 2,100000;", "INSERT INTO b_customers SELECT number * -1, -1 FROM system.numbers LIMIT 2;", "DROP TABLE IF EXISTS b_orders;", "select count() from viewWithJoin;", "set query_plan_join_swap_table=0;", "select count() from viewWithJoin;", "DROP TABLE IF EXISTS b_customers;", "CREATE TABLE b_customers (customer_id Int64, first_order_id Int64) ENGINE = MergeTree ORDER BY customer_id;"]}
{"index": 3202, "a_db": "clickhouse", "b_db": "postgres", "molt": "norec", "sqls": ["CREATE TABLE t0 (c0 Dynamic) ENGINE = DeltaLakeLocal(local, format = 'Parquet', path = '/var/lib/clickhouse/user_files/lakehouses/spark_catalog/test/t0');", "SELECT count() FROM numbers(1) x RIGHT JOIN t0 ON number = c0 WHERE NOT c0 IS NULL;", "Create the table with [spark.py](https://github.com/user-attachments/files/22464030/spark.py). Then in ClickHouse run:;", "CREATE TABLE t0 (c0 Dynamic) ENGINE = DeltaLakeLocal(local, format = 'Parquet', path = '/var/lib/clickhouse/user_files/lakehouses/spark_catalog/test/t0');", "SELECT count() FROM numbers(1) x RIGHT JOIN t0 ON number = c0 WHERE NOT c0 IS NULL;"]}
{"index": 3205, "a_db": "clickhouse", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE t0 (c0 Int) ENGINE = Memory();", "INSERT INTO TABLE t0 (c0) VALUES (1);", "SELECT c0 FROM t0 GROUP BY c0 SETTINGS max_bytes_before_external_group_by = 1, temporary_files_buffer_size = 0, group_by_two_level_threshold = 1;", "CREATE TABLE t0 (c0 Int) ENGINE = Memory();", "INSERT INTO TABLE t0 (c0) VALUES (1);", "SELECT c0 FROM t0 GROUP BY c0 SETTINGS max_bytes_before_external_group_by = 1, temporary_files_buffer_size = 0, group_by_two_level_threshold = 1;"]}
{"index": 3210, "a_db": "clickhouse", "b_db": "postgres", "molt": "error", "sqls": ["CREATE TABLE t0 (c0 Int) ENGINE = S3(s3, format = 'CSV', filename = 'file{_partition_id}') PARTITION BY (c0);", "ALTER TABLE t0 ADD COLUMN c1 Variant(Int,String);", "INSERT INTO TABLE t0 (c0) VALUES (1);", "CREATE TABLE t0 (c0 Int) ENGINE = S3(s3, format = 'CSV', filename = 'file{_partition_id}') PARTITION BY (c0);", "ALTER TABLE t0 ADD COLUMN c1 Variant(Int,String);", "INSERT INTO TABLE t0 (c0) VALUES (1);"]}
{"index": 3211, "a_db": "clickhouse", "b_db": "postgres", "molt": "crash", "sqls": ["SELECT * FROM file('boolean_bloom.gz.parquet', 'Parquet') SETTINGS input_format_parquet_use_native_reader_v3 = 1;", "SELECT * FROM file('boolean_bloom.gz.parquet', 'Parquet') SETTINGS input_format_parquet_use_native_reader_v3 = 1;"]}
{"index": 3212, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE v0 ( v1 BOOLEAN , v2 DOUBLE );", "WITH RECURSIVE v0 AS ( SELECT v2 , ( v1 ) FROM v0 WHERE v2 > 72 UNION ALL SELECT v1 , ( v2 ) FROM v0 WHERE v1 > 19 ) INSERT INTO v0 VALUES ( 16 , 18981070.000000 ) , ( -1 , 48981446.000000 ) , ( 49 , 56166811.000000 ) , ( -1 , NULL ) , ( 80 , 81429797.000000 );", "SELECT ( SELECT 11 FROM v0 t1 , v0 t2 JOIN v0 USING ( v1 , v2 ) ) = 'x' FROM v0;", "CREATE TABLE v3 ( v4 INT , v5 FLOAT );", "INSERT INTO v0 VALUES ( 8 , 78482300.000000 ) , ( -32768 , 97463370.000000 ) , ( -128 , 98961168.000000 ) , ( -1 , NULL ) , ( -1 , 96006176.000000 );", "SELECT COUNT ( DISTINCT v1 ) FROM v0 WHERE v2 = 58;", "SELECT PERCENT_RANK ( DISTINCT v2 ) FROM v0 WHERE v2 IN ( -32768 , -128 );", "CREATE TABLE v6 ( v7 DOUBLE );", "INSERT INTO v6 VALUES ( NULL ) , ( 59162491.000000 ) , ( 25001794.000000 ) , ( 91582435.000000 ) , ( 86978172.000000 );", "SELECT STDDEV_POP ( DISTINCT v1 ) FROM v0;"]}
{"index": 3213, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE v0 ( v1 INT , v2 DOUBLE );", "INSERT INTO v0 VALUES ( 127 , 75766173.000000 ) , ( -1 , 59557838.000000 ) , ( 16 , 98271205.000000 ) , ( 35 , NULL ) , ( 13 , 93747801.000000 );", "SELECT 0 FROM ( SELECT v1 AS v4 FROM v0 AS v3 ORDER BY v1 NULLS LAST , v1 ) JOIN v0 USING ( v1 , v2 ) GROUP BY v1 HAVING v2 > 'x';", "CREATE TABLE v5 ( v6 INT , v7 FLOAT );", "INSERT INTO v0 VALUES ( 127 , 76594699.000000 ) , ( -32768 , 70257697.000000 ) , ( 36 , 65888462.000000 ) , ( 62 , NULL ) , ( 2147483647 , 55975338.000000 );", "SELECT LAST_VALUE ( DISTINCT v1 ) FROM v0 WHERE v1 = -1;", "SELECT LEAD ( DISTINCT v6 ) FROM WHERE FIRST_VALUE IN ( -1 , 31 );", "CREATE TABLE v8 ( v9 DOUBLE );", "INSERT INTO v0 VALUES ( NULL ) , ( 787917.000000 ) , ( 11605603.000000 ) , ( 76476943.000000 ) , ( 90397286.000000 );", "SELECT ROW_NUMBER ( DISTINCT v7 ) FROM v5;"]}
{"index": 3218, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["CREATE TABLE IF NOT EXISTS t0(c0 INT , c1 INT);", "INSERT INTO t0(c1) VALUES(1), (2), (3);", "SELECT * FROM t0 JOIN LATERAL (SELECT CASE WHEN 0.7 <> ALL(SELECT t0.c1 FROM t0 AS sub1) THEN 2 ELSE 1 END FROM t0 AS sub2) AS subQuery(col_1) ON NOT (( EXISTS (SELECT 1)) AND 0);", "SELECT t0.c1 FROM t0 JOIN LATERAL (SELECT CASE WHEN 0.7 <> ALL(SELECT t0.c1 FROM t0 AS sub1) THEN 2 ELSE 1 END FROM t0 AS sub2) AS subQuery(col_1) ON NOT (( EXISTS (SELECT 1)) AND 0);", "CREATE TABLE IF NOT EXISTS t0(c0 INT , c1 INT);", "INSERT INTO t0(c1) VALUES(1), (2), (3);", "SELECT * FROM t0 JOIN LATERAL (SELECT CASE WHEN 0.7 <> ALL(SELECT t0.c1 FROM t0 AS sub1) THEN 2 ELSE 1 END FROM t0 AS sub2) AS subQuery(col_1) ON NOT (( EXISTS (SELECT 1)) AND 0);", "SELECT t0.c1 FROM t0 JOIN LATERAL (SELECT CASE WHEN 0.7 <> ALL(SELECT t0.c1 FROM t0 AS sub1) THEN 2 ELSE 1 END FROM t0 AS sub2) AS subQuery(col_1) ON NOT (( EXISTS (SELECT 1)) AND 0);", "CREATE TABLE IF NOT EXISTS t0(c0 INT , c1 INT);", "INSERT INTO t0(c1) VALUES(1), (2), (3);"]}
{"index": 3219, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["CREATE TABLE t0(c0 INT , c1 INT , c2 INT);", "SET \"sql_optimizer\"='0';", "INSERT INTO t0(c2, c0, c1) VALUES(45, 1, 1);", "SELECT t0.c0, t0.c2 FROM t0 WHERE NOT EXISTS (SELECT 1 FROM (SELECT t0.c0) AS subQuery(col_1) WHERE ( 1 AND ((t0.c0) IS NOT NULL)) );", "CREATE TABLE t0(c0 INT , c1 INT , c2 INT);", "SET \"sql_optimizer\"='0';", "INSERT INTO t0(c2, c0, c1) VALUES(45, 1, 1);", "SELECT t0.c0, t0.c2 FROM t0 WHERE NOT EXISTS (SELECT 1 FROM (SELECT t0.c0) AS subQuery(col_1) WHERE ( 1 AND ((t0.c0) IS NOT NULL)) );", "MonetDB 5 server 11.54.0 (hg id: 47c9357) (64-bit, 128-bit integers);", "This is an unreleased version;"]}
{"index": 3220, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["CREATE TABLE t0(c0 INT, c1 INT);", "CREATE TABLE t1(c0 INT);", "INSERT INTO t0(c0) VALUES(1);", "INSERT INTO t1(c0) VALUES(1);", "SELECT t0.c0 FROM t0 WHERE NOT EXISTS (SELECT 1 FROM t1 WHERE t0.c1);", "CREATE TABLE t0(c0 INT, c1 INT);", "CREATE TABLE t1(c0 INT);", "INSERT INTO t0(c0) VALUES(1);", "INSERT INTO t1(c0) VALUES(1);", "SELECT t0.c0 FROM t0 WHERE NOT EXISTS (SELECT 1 FROM t1 WHERE t0.c1);"]}
{"index": 3221, "a_db": "clickhouse", "b_db": "postgres", "molt": "pqs", "sqls": ["CREATE TABLE pq_test1 ENGINE = MergeTree ORDER BY (year, src, dst);", "SETTINGS allow_nullable_key = 1;", "AS SELECT * FROM url('https://storage.googleapis.com/cliclhouse-bug-repro-42/pq_test.parquet', Parquet);", "CREATE TABLE pq_test2 ENGINE = MergeTree ORDER BY (year, src, dst);", "SETTINGS allow_nullable_key = 1;", "AS SELECT * FROM url('https://storage.googleapis.com/cliclhouse-bug-repro-42/hp=2025-09-24/pq_test.parquet', Parquet);", "DESCRIBE TABLE url('https://storage.googleapis.com/cliclhouse-bug-repro-42/hp=2025-09-24/pq_test.parquet', Parquet);", "┌─name─────────┬─type─────────────────┬─default_type─┬─default_expression─┬─comment─┬─codec_expression─┬─ttl_expression─┐;", "└──────────────┴──────────────────────┴──────────────┴────────────────────┴─────────┴──────────────────┴────────────────┘;", "6 rows in set. Elapsed: 0.072 sec.;"]}
{"index": 3222, "a_db": "clickhouse", "b_db": "postgres", "molt": "error", "sqls": ["SELECT * FROM deltaLakeLocal(local, structure = 'c2 Float32, c3 LowCardinality(Time), c4 Bool, c1 Nullable(Time)', path = '/var/lib/clickhouse/user_files/lakehouses/spark_catalog/test/t0', format = 'Parquet') AS tx SETTINGS allow_experimental_delta_kernel_rs = 0 , allow_suspicious_low_cardinality_types = 1, enable_time_time64_type = 1;", "SELECT * FROM deltaLakeLocal(local, structure = 'c2 Float32, c3 LowCardinality(Time), c4 Bool, c1 Nullable(Time)', path = '/var/lib/clickhouse/user_files/lakehouses/spark_catalog/test/t0', format = 'Parquet') AS tx SETTINGS allow_experimental_delta_kernel_rs = 0 , allow_suspicious_low_cardinality_types = 1, enable_time_time64_type = 1;"]}
{"index": 3223, "a_db": "clickhouse", "b_db": "postgres", "molt": "pqs", "sqls": ["DROP TABLE IF EXISTS agg_test;", "CREATE TABLE agg_test;", "id UInt32,;", "accepted_at DateTime64(3),;", "delivery_report_at AggregateFunction(maxIf, DateTime64(3), UInt8);", "DROP TABLE IF EXISTS agg_test;", "CREATE TABLE agg_test;", "INSERT INTO agg_test;", "SELECT id, finalizeAggregation(delivery_report_at) AS delivered_at;", "SELECT id, finalizeAggregation(delivery_report_at) AS delivered_at;"]}
{"index": 3224, "a_db": "clickhouse", "b_db": "postgres", "molt": "error", "sqls": ["SET enable_time_time64_type= 1;", "CREATE TABLE t0 (c0 Int) ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/spark_catalog/test/t0', format = 'Parquet');", "INSERT INTO TABLE t0 (c0) VALUES (1);", "SELECT c0 FROM icebergLocal(local, structure = 'c0 Int', path = '/var/lib/clickhouse/user_files/lakehouses/spark_catalog/test/t0', format = 'Parquet') x PREWHERE toInt32('256:08:15'::Time) SETTINGS input_format_parquet_use_native_reader_v3 = 1;", "CREATE TABLE t0 (c0 Int) ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/spark_catalog/test/t0', format = 'Parquet');", "INSERT INTO TABLE t0 (c0) VALUES (1);", "SELECT c0 FROM icebergLocal(local, structure = 'c0 Int', path = '/var/lib/clickhouse/user_files/lakehouses/spark_catalog/test/t0', format = 'Parquet') x PREWHERE toInt32('256:08:15'::Time) SETTINGS input_format_parquet_use_native_reader_v3 = 1;"]}
{"index": 3225, "a_db": "monetdb", "b_db": "postgres", "molt": "error", "sqls": ["CREATE TABLE IF NOT EXISTS t0(c0 INT);", "SELECT * FROM t0 JOIN (VALUES (1)) AS subQuery0(c0) ON NOT EXISTS (SELECT 1 WHERE subQuery0.c0 > NULL);", "CREATE TABLE IF NOT EXISTS t0(c0 INT);", "SELECT * FROM t0 JOIN (VALUES (1)) AS subQuery0(c0) ON NOT EXISTS (SELECT 1 WHERE subQuery0.c0 > NULL);", "CREATE TABLE IF NOT EXISTS t0(c0 INT);", "SELECT * FROM t0 JOIN (VALUES (1)) AS subQuery0(c0) ON NOT EXISTS (SELECT 1 WHERE subQuery0.c0 > NULL);", "CREATE TABLE IF NOT EXISTS t0(c0 INT);", "SELECT * FROM t0 JOIN (VALUES (1)) AS subQuery0(c0) ON NOT EXISTS (SELECT 1 WHERE subQuery0.c0 > NULL);"]}
{"index": 3227, "a_db": "duckdb", "b_db": "sqlite", "molt": "norec", "sqls": ["CREATE OR REPLACE TABLE t1 AS;", "SELECT;", "*,;", "COUNT(*) OVER w AS nbDupExactComm;", "FROM read_parquet('2025-09-27_123.parquet');"]}
{"index": 3228, "a_db": "duckdb", "b_db": "sqlite", "molt": "error", "sqls": ["D select partition, unnest(json_transform(value, '{\"action\":\"VARCHAR\",\"name\":\"VARCHAR\"}')) from tributary_scan_topic('topic_json_1', \"bootstrap.servers\" := 'pkc-921jm.us-east-2.aws.confluent.cloud:9092', \"schema.registry.url\" := 'https://psrc-1ry6vno.us-east-2.aws.confluent.cloud');", "100% ▕██████████████████████████████████████▏ (00:00:04.05 elapsed);", "┌───────────┬─────────┬─────────┐;", "│ partition │ action  │  name   │;", "│   int32   │ varchar │ varchar │;", "create table bar (v text);", "insert into bar values ('{\"action\":\"VARCHAR\",\"name\":\"VARCHAR\"}');", "select json_transform('{\"action\": \"bounce\", \"name\": \"Rusty\"}', (select v from bar));"]}
{"index": 3241, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE v0 ( v1 INT , v2 VARCHAR ( 71 ) );", "SELECT v1 , v1 , v2 , LAST_VALUE ( v2 ) OVER ( PARTITION BY v1 RANGE BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING ) FROM v0;", "CREATE TABLE v0 ( v1 INT , v2 VARCHAR ( 71 ) );", "SELECT v1 , v1 , v2 , LAST_VALUE ( v2 ) OVER ( PARTITION BY v1 RANGE BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING ) FROM v0;", "CREATE TABLE v0 ( v1 INT , v2 VARCHAR ( 71 ) );", "SELECT v1 , v1 , v2 , LAST_VALUE ( v2 ) OVER ( PARTITION BY v1 RANGE BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING ) FROM v0;", "CREATE TABLE v0 ( v1 INT , v2 VARCHAR ( 71 ) );", "SELECT v1 , v1 , v2 , LAST_VALUE ( v2 ) OVER ( PARTITION BY v1 RANGE BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING ) FROM v0;"]}
{"index": 3242, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE v0 ( v1 INT , v2 VARCHAR ( 77 ) NOT NULL CHECK ( CAST ( STDDEV_SAMP ( v1 / -1 ) OVER ( ORDER BY 15933342.000000 DESC ) AS INTEGER ) ) );", "INSERT INTO v0 VALUES ( 83 , 27 ) , ( 96 , 2147483647 ) , ( -2147483648 , 76773466.000000 ) , ( 127 , 48396681.000000 ) , ( 0 , 16496086.000000 );", "CREATE TABLE v0 ( v1 INT , v2 VARCHAR ( 77 ) NOT NULL CHECK ( CAST ( STDDEV_SAMP ( v1 / -1 ) OVER ( ORDER BY 15933342.000000 DESC ) AS INTEGER ) ) );", "INSERT INTO v0 VALUES ( 83 , 27 ) , ( 96 , 2147483647 ) , ( -2147483648 , 76773466.000000 ) , ( 127 , 48396681.000000 ) , ( 0 , 16496086.000000 );", "CREATE TABLE v0 ( v1 INT , v2 VARCHAR ( 77 ) NOT NULL CHECK ( CAST ( STDDEV_SAMP ( v1 / -1 ) OVER ( ORDER BY 15933342.000000 DESC ) AS INTEGER ) ) );", "INSERT INTO v0 VALUES ( 83 , 27 ) , ( 96 , 2147483647 ) , ( -2147483648 , 76773466.000000 ) , ( 127 , 48396681.000000 ) , ( 0 , 16496086.000000 );", "CREATE TABLE v0 ( v1 INT , v2 VARCHAR ( 77 ) NOT NULL CHECK ( CAST ( STDDEV_SAMP ( v1 / -1 ) OVER ( ORDER BY 15933342.000000 DESC ) AS INTEGER ) ) );", "INSERT INTO v0 VALUES ( 83 , 27 ) , ( 96 , 2147483647 ) , ( -2147483648 , 76773466.000000 ) , ( 127 , 48396681.000000 ) , ( 0 , 16496086.000000 );"]}
{"index": 3243, "a_db": "clickhouse", "b_db": "postgres", "molt": "norec", "sqls": ["SET memory_tracker_fault_probability = 0.9, max_untracked_memory = 0;", "BACKUP ALL TO Memory('backup');"]}
{"index": 3244, "a_db": "clickhouse", "b_db": "postgres", "molt": "norec", "sqls": ["CREATE TABLE t0 (c0 Int, c1 Int) ENGINE = IcebergLocal(local, format = 'Parquet', path = '/var/lib/clickhouse/user_files/lakehouses/t0/');", "INSERT INTO t0 VALUES (1,1),(2,2),(3,3);", "ALTER TABLE t0 CLEAR COLUMN c0;", "INSERT INTO t0 SETTINGS iceberg_snapshot_id = <snapshot id of the first insert>  VALUES (1,1),(2,2),(3,3);", "CREATE TABLE t0 (c0 Int, c1 Int) ENGINE = IcebergLocal(local, format = 'Parquet', path = '/var/lib/clickhouse/user_files/lakehouses/t0/');", "INSERT INTO t0 VALUES (1,1),(2,2),(3,3);", "ALTER TABLE t0 CLEAR COLUMN c0;", "INSERT INTO t0 SETTINGS iceberg_snapshot_id = <snapshot id of the first insert>  VALUES (1,1),(2,2),(3,3);"]}
{"index": 3245, "a_db": "duckdb", "b_db": "sqlite", "molt": "pqs", "sqls": ["SELECT round_even(2.675::DOUBLE, 2);"]}
{"index": 3246, "a_db": "duckdb", "b_db": "sqlite", "molt": "error", "sqls": ["CREATE OR REPLACE TEMP MACRO err_repro() AS TABLE (;", "FROM named_cte;", "SELECT 1;", ");", "CREATE OR REPLACE TEMP MACRO indirection_fix(tbl_name) AS TABLE (;", "FROM query_table(tbl_name);", "SELECT new_val: val + 1;", ");", "WITH named_cte AS ( SELECT val: 2 );"]}
{"index": 3253, "a_db": "clickhouse", "b_db": "postgres", "molt": "error", "sqls": ["With this [users.xml](https://github.com/user-attachments/files/22563550/users.xml), run this script with the client several times to reproduce it [issue.sql](https://github.com/user-attachments/files/22563516/issue.sql).;"]}
{"index": 3254, "a_db": "clickhouse", "b_db": "postgres", "molt": "pqs", "sqls": ["DROP DATABASE hms;", "CREATE DATABASE hms ENGINE = DataLakeCatalog('thrift://some-url-here:9083', 'user', 'password');"]}
{"index": 3255, "a_db": "clickhouse", "b_db": "postgres", "molt": "error", "sqls": ["DROP USER IF EXISTS test_roles ON CLUSTER '{cluster}';", "DROP ROLE IF EXISTS test_roles_dict ON CLUSTER '{cluster}';", "SELECT hostName() AS h, count();", "SELECT hostName() AS h, count();", "SELECT hostName() AS h, count();"]}
{"index": 3258, "a_db": "duckdb", "b_db": "sqlite", "molt": "error", "sqls": ["FROM (VALUES(1,1,2),(1,1,3)) AS t(key1,key2,v);", "SELECT DISTINCT ON(key1,key2) *;", "FROM (VALUES(1,1,2),(1,1,3)) AS t(key1,key2,v);", "SELECT DISTINCT columns('key');", "FROM (VALUES(1,1,2),(1,1,3)) AS t(key1,key2,v);", "SELECT DISTINCT ON(columns('key')) *;"]}
{"index": 3259, "a_db": "duckdb", "b_db": "sqlite", "molt": "norec", "sqls": ["FORCE INSTALL shellfs FROM community;", "INSTALL shellfs;", "select;", "max(c1) - min(c1);", "from read_csv(;"]}
{"index": 3262, "a_db": "clickhouse", "b_db": "postgres", "molt": "norec", "sqls": ["CREATE TABLE t0 (c1 Map(Int,Int), c2 Int) ENGINE = MergeTree() ORDER BY tuple() PARTITION BY (c1, c2 % 6084);", "INSERT INTO TABLE t0 (c1, c2) SELECT map(), 2 FROM numbers(100);", "SET min_insert_block_size_rows = 64, optimize_trivial_insert_select = 1;", "INSERT INTO TABLE t0 (c1, c2) SELECT c1, c2 FROM generateRandom('c1 Map(Int,Int), c2 Int', 2607967781039168224, 1, 1) LIMIT 400;", "BACKUP TABLE t0 TO Disk('default', 'b0.tar');", "CREATE TABLE t0 (c1 Map(Int,Int), c2 Int) ENGINE = MergeTree() ORDER BY tuple() PARTITION BY (c1, c2 % 6084);", "INSERT INTO TABLE t0 (c1, c2) SELECT map(), 2 FROM numbers(100);", "INSERT INTO TABLE t0 (c1, c2) SELECT c1, c2 FROM generateRandom('c1 Map(Int,Int), c2 Int', 2607967781039168224, 1, 1) LIMIT 400;"]}
{"index": 3265, "a_db": "clickhouse", "b_db": "postgres", "molt": "norec", "sqls": ["CREATE TABLE t0 ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/t0/test/t0');", "OPTIMIZE TABLE t0;", "With [spark.py](https://github.com/user-attachments/files/23163459/spark.py) run `spark.py create`. Then in ClickHouse create the table with:;", "CREATE TABLE t0 ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/t0/test/t0');"]}
{"index": 3266, "a_db": "duckdb", "b_db": "sqlite", "molt": "crash", "sqls": ["SELECT pg_typeof(#1) FROM (SELECT 1);"]}
{"index": 3270, "a_db": "duckdb", "b_db": "sqlite", "molt": "pqs", "sqls": ["SET errors_as_json = true;", "COPY (;", "SELECT * FROM json_execute_serialized_sql(;", "json_serialize_sql('SELECT * FROM foo.bar');", ");", "json_serialize_sql('SELECT * FROM foo.bar');", "json_serialize_sql('SELECT 1,2,3,4,5,6,7,8,* FROM foo.bar');"]}
{"index": 3271, "a_db": "duckdb", "b_db": "sqlite", "molt": "pqs", "sqls": ["CREATE TABLE arrtest_s (;", "a    int2[],;", "b    int2[][];", ");", "INSERT INTO arrtest_s VALUES ('{1,2,3,4,5}', '{{1,2,3}, {4,5,6}, {7,8,9}}');", "CREATE TABLE arrtest_s (;", "a    int2[],;", "b    int2[][];", ");", "INSERT INTO arrtest_s VALUES ([1,2,3,4,5], [[1,2,3],[4,5,6],[7,8,9]]);"]}
{"index": 3272, "a_db": "duckdb", "b_db": "sqlite", "molt": "pqs", "sqls": ["CREATE TABLE documents (;", "document_identifier VARCHAR,;", "text_content VARCHAR,;", "author VARCHAR,;", "doc_version INTEGER;"]}
{"index": 3273, "a_db": "duckdb", "b_db": "sqlite", "molt": "pqs", "sqls": ["SELECT round(2.675::DOUBLE, 2);"]}
{"index": 3275, "a_db": "duckdb", "b_db": "sqlite", "molt": "error", "sqls": ["SET memory_limit = '16GB';", "SET preserve_insertion_order = FALSE;", "CREATE OR REPLACE TABLE t1 AS (;", "SELECT * FROM 't1.parquet';", ");"]}
{"index": 3290, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["select * from sys.tables where not system;", "select * from sys.table_types;", "CREATE VIEW v AS select * from sys.tables where not system;", "select * from v;", "CREATE TEMPORARY VIEW tv AS select * from sys.tables where not system;", "select * from tv;", "CREATE GLOBAL TEMPORARY VIEW gtv AS select * from sys.tables where not system;", "select * from gtv;", "CREATE LOCAL TEMPORARY VIEW ltv AS select * from sys.tables where not system;", "select * from ltv;"]}
{"index": 3291, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["SELECT ( WITH x ( x ) AS ( SELECT DISTINCT 1 ) SELECT ( SELECT x FROM x WHERE x = ( SELECT ( SELECT x FROM x WHERE EXISTS ( SELECT - x , x FROM x ) ) WHERE ( WITH x AS ( SELECT * FROM generate_series ( 8888 , 8100 ) EXCEPT SELECT * FROM generate_series ( 44 , 3 ) ) SELECT 2 WHERE FALSE ) > ANY ( 'EUROPE' ) GROUP BY 1 ) ) FROM x );", "SELECT ( WITH x ( x ) AS ( SELECT DISTINCT 1 ) SELECT ( SELECT x FROM x WHERE x = ( SELECT ( SELECT x FROM x WHERE EXISTS ( SELECT - x , x FROM x ) ) WHERE ( WITH x AS ( SELECT * FROM generate_series ( 8888 , 8100 ) EXCEPT SELECT * FROM generate_series ( 44 , 3 ) ) SELECT 2 WHERE FALSE ) > ANY ( 'EUROPE' ) GROUP BY 1 ) ) FROM x );"]}
{"index": 3292, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["SELECT ( WITH RECURSIVE x AS ( SELECT 1 UNION SELECT str_to_date ( 'int' , 'X2014-10-25 UTC' ) ) SELECT ( 3 ) );", "SELECT ( WITH RECURSIVE x AS ( SELECT 1 UNION SELECT str_to_date ( 'int' , 'X2014-10-25 UTC' ) ) SELECT ( 3 ) );"]}
{"index": 3294, "a_db": "duckdb", "b_db": "sqlite", "molt": "crash", "sqls": ["SELECT datasketch_quantiles(16, 5.0::float);"]}
{"index": 3295, "a_db": "duckdb", "b_db": "sqlite", "molt": "error", "sqls": ["duckdb test2.db < dump.sql;"]}
{"index": 3297, "a_db": "duckdb", "b_db": "sqlite", "molt": "norec", "sqls": ["SELECT  data.* not LIKE '%学时'  , data.* like '%学时'  from data;", "SELECT  data.* not LIKE '%学时'  , data.* like '%学时'  from data,   dgjs;", "CREATE TABLE \"data\"(\"学期\" DOUBLE,\"教学班名称\" VARCHAR,\"课程号\" VARCHAR,\"课程名称\" VARCHAR,\"课程性质\" VARCHAR,\"教师信息\" VARCHAR,;", "\"任务总学时\" DOUBLE,\"课程总学时\" DOUBLE,\"讲课学时\" DOUBLE,\"实验学时\" DOUBLE,\"实践学时\" VARCHAR);", "CREATE TABLE dgjs(\"课程名称\" VARCHAR, \"教学班\" VARCHAR, \"课程代码\" VARCHAR, \"学年\" VARCHAR, \"学期\" VARCHAR, \"教师名称\" VARCHAR, \"课程课外指导总学时\" VARCHAR, \"课程实验总学时\" VARCHAR, \"课程上机总学时\" VARCHAR, \"课程实践总学时\" VARCHAR, \"课程总学时\" VARCHAR);", "SELECT  data.* not LIKE '%学时'  , data.* like '%学时'  from data;", "SELECT  data.* not LIKE '%学时'  , data.* like '%学时'  from data, dgjs;"]}
{"index": 3308, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["WITH ranked AS (SELECT row_number() OVER(ORDER BY name) AS rownum FROM sys.functions);", "SELECT * FROM ranked;", "WHERE rownum > 0 AND rownum <= 5;", "WITH ranked AS (SELECT row_number() OVER(ORDER BY name) AS rownum FROM sys.functions);", "SELECT * FROM ranked;", "WHERE rownum > 0 AND rownum < 5;", "WITH ranked AS (SELECT row_number() OVER(ORDER BY name) AS rownum FROM sys.functions);", "SELECT * FROM ranked;", "WITH ranked AS (SELECT row_number() OVER(ORDER BY name) AS rownum FROM sys.functions);", "SELECT * FROM ranked;"]}
{"index": 3309, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["sql>SELECT *;", "FROM generate_series(;", "'2025-03-01',;", "'2025-04-25',;", "INTERVAL '1' MONTH;", "sql>SELECT *;", "FROM generate_series(;", "'2025-03-01',;", "'2025-04-25',;", "INTERVAL '1' MONTH;"]}
{"index": 3310, "a_db": "clickhouse", "b_db": "postgres", "molt": "norec", "sqls": ["SELECT mortonEncode(());", "SELECT mortonEncode(());"]}
{"index": 3311, "a_db": "clickhouse", "b_db": "postgres", "molt": "error", "sqls": ["CREATE VIEW v;", "AS SELECT;", "NULL AS constant_null;", "FROM system.numbers LIMIT 10;", "SELECT constant_null FROM v as l ANY RIGHT JOIN v AS r ON 1 =1  WHERE constant_null = 35;", "SELECT constant_null FROM v as l ANY RIGHT JOIN v AS r ON 1 =1  WHERE constant_null = 35;"]}
{"index": 3312, "a_db": "duckdb", "b_db": "sqlite", "molt": "norec", "sqls": ["CREATE TABLE comment AS SELECT id, replyOf FROM 'comment.parquet';", "CREATE INDEX idx_comment_replyOf ON comment(replyOf);", "SELECT id FROM comment WHERE replyOf = 687195512455;"]}
{"index": 3314, "a_db": "duckdb", "b_db": "sqlite", "molt": "norec", "sqls": ["CREATE TABLE outer_tab (f1 int4, f2 int4);", "INSERT INTO outer_tab VALUES (0, 0);", "INSERT INTO outer_tab VALUES (1, 0);", "CREATE TABLE inner_tab(c1 int8, c2 int8);", "INSERT INTO inner_tab VALUES(0, null);", "SELECT * FROM outer_tab WHERE (f1, f2) NOT IN (SELECT * FROM inner_tab);", "SELECT * FROM outer_tab WHERE (f1, f2) NOT IN (SELECT * FROM inner_tab);"]}
{"index": 3318, "a_db": "clickhouse", "b_db": "postgres", "molt": "pqs", "sqls": ["SHOW CREATE TABLE `column_rbac_namespace_ebaed36e_b4cc_11f0_af75_e0c26496f172.table_ebaed39f_b4cc_11f0_919a_e0c26496f172`;", "└────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘;", "1 row in set. Elapsed: 0.010 sec.;", "SELECT *;", "FROM `column_rbac_namespace_ebaed36e_b4cc_11f0_af75_e0c26496f172.table_ebaed39f_b4cc_11f0_919a_e0c26496f172`;", "SELECT string_col;", "FROM `column_rbac_namespace_ebaed36e_b4cc_11f0_af75_e0c26496f172.table_ebaed39f_b4cc_11f0_919a_e0c26496f172`;", "ORDER BY string_col ASC;", "┌─string_col─┐;", "└─string_col─┘;"]}
{"index": 3322, "a_db": "duckdb", "b_db": "sqlite", "molt": "norec", "sqls": ["SELECT unnest(a), unnest(b);", "FROM;", "(SELECT {'fruit': 'apple'} AS a),;", "(SELECT {'fruit': 'banana'} AS b);", "SELECT unnest(a, prefix := 'a_'), unnest(b, prefix := 'b_');", "FROM;", "(SELECT {'fruit': 'apple'} AS a),;", "(SELECT {'fruit': 'banana'} AS b);"]}
{"index": 3325, "a_db": "monetdb", "b_db": "postgres", "molt": "pqs", "sqls": ["CREATE TABLE t0(c0 INT);", "INSERT INTO t0(c0) VALUES(60);", "CREATE TABLE t1(c0 INT);", "INSERT INTO t1(c0) VALUES(0);", "SELECT * FROM t0 WHERE NOT EXISTS (SELECT 1 FROM t1 WHERE t1.c0 LIKE t0.c0);", "CREATE TABLE t0(c0 INT);", "INSERT INTO t0(c0) VALUES(60);", "CREATE TABLE t1(c0 INT);", "INSERT INTO t1(c0) VALUES(0);", "SELECT * FROM t0 WHERE NOT EXISTS (SELECT 1 FROM t1 WHERE t1.c0 LIKE t0.c0);"]}
{"index": 3327, "a_db": "clickhouse", "b_db": "postgres", "molt": "error", "sqls": ["CREATE TABLE t0 (c0 Int) ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/t0', format = 'Avro');", "INSERT INTO TABLE t0 (c0) VALUES (1);", "ALTER TABLE t0 DELETE WHERE c0 != 2;", "CREATE TABLE t0 (c0 Int) ENGINE = IcebergLocal(local, path = '/var/lib/clickhouse/user_files/lakehouses/t0', format = 'Avro');", "INSERT INTO TABLE t0 (c0) VALUES (1);", "ALTER TABLE t0 DELETE WHERE c0 != 2;"]}
{"index": 3328, "a_db": "clickhouse", "b_db": "postgres", "molt": "error", "sqls": ["CREATE TABLE t0 ENGINE = IcebergLocal(local, format = 'Parquet', path = '/var/lib/clickhouse/user_files/lakehouses/t0/test/t0');", "SELECT 1 FROM t0 WHERE t0._row_number = 1 AND t0._data_lake_snapshot_version = 1;", "With [spark.py](https://github.com/user-attachments/files/22615855/spark.py). run: `python spark.py create` to create the table, then in ClickHouse run:;", "CREATE TABLE t0 ENGINE = IcebergLocal(local, format = 'Parquet', path = '/var/lib/clickhouse/user_files/lakehouses/t0/test/t0');", "SELECT 1 FROM t0 WHERE t0._row_number = 1 AND t0._data_lake_snapshot_version = 1;"]}
{"index": 3330, "a_db": "clickhouse", "b_db": "postgres", "molt": "error", "sqls": ["SET allow_experimental_statistics=1, optimize_move_to_prewhere=1, move_all_conditions_to_prewhere=1, enable_multiple_prewhere_read_steps=1, move_primary_key_columns_to_end_of_prewhere=1, allow_reorder_prewhere_conditions=1, allow_statistics_optimize=1, allow_suspicious_low_cardinality_types=1;", "CREATE TABLE test_improve_prewhere__fuzz_19 (`primary_key` String STATISTICS(CountMin), `normal_column` String STATISTICS(CountMin), `value` LowCardinality(UInt32) STATISTICS(TDigest), `date` LowCardinality(Nullable(Date)) STATISTICS(CountMin)) ENGINE = MergeTree ORDER BY primary_key;", "INSERT INTO test_improve_prewhere__fuzz_19 SELECT hex(number % 100) AS primary_key, ['hello', 'world', 'test', 'example', 'sample'][(number % 5) + 1] AS normal_column, (number % 1000) + 1 AS value, toDate('2025-08-01') + number AS date FROM numbers(10);", "EXPLAIN SELECT * FROM test_improve_prewhere__fuzz_19 WHERE (date = '2025-08-05') AND (lower(primary_key) = '00') AND (normal_column != 'hello') AND (value < 100);", "CREATE TABLE test_improve_prewhere__fuzz_19 (`primary_key` String STATISTICS(CountMin), `normal_column` String STATISTICS(CountMin), `value` LowCardinality(UInt32) STATISTICS(TDigest), `date` LowCardinality(Nullable(Date)) STATISTICS(CountMin)) ENGINE = MergeTree ORDER BY primary_key;", "INSERT INTO test_improve_prewhere__fuzz_19 SELECT hex(number % 100) AS primary_key, ['hello', 'world', 'test', 'example', 'sample'][(number % 5) + 1] AS normal_column, (number % 1000) + 1 AS value, toDate('2025-08-01') + number AS date FROM numbers(10);"]}
{"index": 3333, "a_db": "duckdb", "b_db": "sqlite", "molt": "norec", "sqls": ["COPY (;", "WITH n AS (;", "SELECT 4230875 AS nrows;", ");", "SELECT;", "COPY 'combined_synthetic.parquet' TO 'output.parquet' (FILE_SIZE_BYTES '16MB');"]}
{"index": 3340, "a_db": "monetdb", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE VIEW v0 AS SELECT CAST ( NULL AS INT ) INTERSECT SELECT CAST ( NULL AS INT );", "SELECT DISTINCT SUM ( max ( ( SELECT NULL AS v2 GROUP BY v2 ) ) ) OVER( ORDER BY '013' ) FROM v0;"]}
{"index": 3341, "a_db": "clickhouse", "b_db": "postgres", "molt": "error", "sqls": ["CREATE TABLE t0 ENGINE = IcebergS3(s3, format = 'Parquet', filename = 't0/test/t0');", "SELECT 1 FROM icebergS3(s3, format = 'Parquet', filename = 't0/test/t0', structure = 'c0 Int', SETTINGS disk = 'disk0') tx;", "Create the table in Spark with: [spark.py](https://github.com/user-attachments/files/23262383/spark.py);", "CREATE TABLE t0 ENGINE = IcebergS3(s3, format = 'Parquet', filename = 't0/test/t0');", "SELECT 1 FROM icebergS3(s3, format = 'Parquet', filename = 't0/test/t0', structure = 'c0 Int', SETTINGS disk = 'disk0') tx;"]}
{"index": 3342, "a_db": "clickhouse", "b_db": "postgres", "molt": "crash", "sqls": ["CREATE TABLE compression_estimate_example (;", "number UInt64;", "ENGINE = MergeTree();", "ORDER BY number;", "INSERT INTO compression_estimate_example;", "CREATE TABLE compression_estimate_example (;", "INSERT INTO compression_estimate_example;", "SELECT number FROM system.numbers LIMIT 100_000;", "SELECT estimateCompressionRatio('DoubleDelta, T64, ZSTD')(number) AS estimate FROM compression_estimate_example;"]}
{"index": 3343, "a_db": "duckdb", "b_db": "sqlite", "molt": "pqs", "sqls": ["SELECT Delimiter, Quote, Escape, HasHeader, Columns FROM sniff_csv(\"repro.csv\", strict_mode=false);"]}
